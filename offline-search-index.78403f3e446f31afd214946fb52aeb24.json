[{"body":"Default Storage Layer of Clusterpedia supports two storage components: MySQL and PostgreSQL.\nWhen installing Clusterpedia, you can use existing storage component and create Default Storage Layer(ConfigMap) and Secret of storage component.\nConfigure the Default Storage Layer You shall create clusterpedia-internalstorage ConfigMap in the clusterpedia-system namespace.\n# internalstorage configmap exampleapiVersion:v1kind:ConfigMapmetadata:name:clusterpedia-internalstoragenamespace:clusterpedia-systemdata:internalstorage-config.yaml:|type: \"mysql\" host: \"clusterpedia-internalstorage-mysql\" port: 3306 user: root database: \"clusterpedia\" connPool: maxIdleConns: 10 maxOpenConns: 100 connMaxLifetime: 1h log: slowThreshold: \"100ms\" logger: filename: /var/log/clusterpedia/internalstorage.log maxbackups: 3Default Storage Layer config supports the following fields:\n   field description     type type of storage component such as “postgres” and “mysql”   host host for storage component such as IP address or Service Name   port port for storage component   user user for storage component   password password for storage component   database the database used by Clusterpedia    It is a good choice to store the access password to Secret. For details see Configure Secret of storage component\nConnection Pool    field description default value     connPool.maxIdleConns the maximum number of connections in the idle connection pool. 10   connPool.maxOpenConns the maximum number of open connections to the database. 100   connPool.connMaxLifetime the maximum amount of time a connection may be reused. 1h    Set up the database connection pool according to the user’s current environment.\nConfigure log Clusterpedia supports to configure logs for storage layer, enabling the log to record slow SQL queries and errors via the log field.\n   field description     log.stdout Output log to standard device   log.colorful Enable color print or not   log.slowThreshold Set threshold for slow SQL queries such as “100ms”   log.level Set the severity level such as Slient, Error, Warn, Info   log.logger configure rolling logger    After enabling log, if log.stdout is not set to true, the log will be output to /var/log/clusterpedia/internalstorage.log\nRolling logger Write storage lay logs to file, and configure log file rotation\n   field description     log.logger.filename the file to write logs to, backup log files will be retained in the same directory, default is /var/log/clusterpedia/internalstorage.log   log.logger.maxsize the maximum size in megabytes of the log file before it gets rotated. default is 100 MB.   log.logger.maxage the maximum number of days to retain old log files based on the timestamp encoded in their filename.   log.logger.maxbackups the maximum number of old log files to retain.   log.logger.localtime whether it is local time, default is to use UTC time   log.logger.compress compress determines if the rotated log files should be compressed using gzip.    Disable log If the log field is not filled in the internalstorage config, log will be ignored, for example:\ntype:\"mysql\"host:\"clusterpedia-internalstorage-mysql\"port:3306user:rootdatabase:\"clusterpedia\"More configuration The default storage layer also provides more configurations about MySQL and PostgreSQL. Refer to internalstorage/config.go.\nConfigure Secret The yaml file that is used to install Clusterpedia may get the password from internalstroage-password Secret.\nConfigure the storage component password to Secret\nkubectl -n clusterpedia-system create secret generic \\  internalstorage-password --from-literal=password=\u003cpassword to access storage components\u003e ","categories":"","description":"","excerpt":"Default Storage Layer of Clusterpedia supports two storage components: …","ref":"/docs/installation/configuration/configure-internalstorage/","tags":"","title":"Configure Storage Layer"},{"body":"Clusterpedia uses the custom resource - PediaCluster to represent the imported cluster.\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:cluster-examplespec:apiserver:\"https://10.30.43.43:6443\"kubeconfig:caData:tokenData:certData:keyData:syncResources:[]There are two ways for users to configure the imported clusters:\n Configure base64-encoded kube config directly to the spec.kubeconfig field for cluster connectivity and authentication. Configure the address for the imported cluster and the authentication information.  When using the apiserver field to set address for the imported cluster, there are several options for configure the authentication fields:\n caData + tokenData caData + certData + keyData   caData can be left blank if the cluster APIServer allows Insecure connections\n All these authentication fields need to be encoded by base64. If the field values are obtained directly from ConfigMap or Secret, they have already been encoded by base64.\nUse the Kube Config to import a cluster One of the easiest ways to connect and authenticate to a cluster is to use the kube config.\nFirst you need to base64 encode the kube config for the imported cluster.\n# mac cat ./kubeconfig | base64 # linux cat ./kubeconfig | base64 -w 0 # Output: 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  If the output contains newlines, then you can use base64 -w 0 ./kubeconfig\n Set the content after the base64 to PediaCluster spec.kubeconfig, in addition spec.apiserver and other authentication fields don’t need to set.\nHowever, since the cluster address is configured in kube config, the APIServer URL is empty when you use kubectl get pediacluster.\nkubectl get pediacluster # Output: NAME APISERVER URL VERSION STATUS cluster-1 v1.22.2 Healthy Mutating addmission webhooks will be added in the future to automatically set spec.apiserver, currently if you want to show the cluster apiserver address when kubectl get pediacluster, then you need to manually configure the spec.apiserver field additionally.\nUse ServiceAccount to import a cluster You can also choose to create a ServiceAccount in the Imported Cluster and configure the proper RBAC to import the cluster.\n# Connect the current kubectl to the imported cluster kubectl apply -f https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/main/examples/clusterpedia_synchro_rbac.yaml # Get CA and Token for Service Account SYNCHRO_CA=$(kubectl -n default get secret $(kubectl -n default get serviceaccount clusterpedia-synchro -o jsonpath='{.secrets[0].name}') -o jsonpath='{.data.ca\\.crt}') SYNCHRO_TOKEN=$(kubectl -n default get secret $(kubectl -n default get serviceaccount clusterpedia-synchro -o jsonpath='{.secrets[0].name}') -o jsonpath='{.data.token}') Fill $SYNCHRO_CA and SYNCHRO_TOKEN into spec.caData and spec.tokenData fields for the PediaCluster resource.\nCreate PediaCluster After completing the cluster authentication fields, you can get a complete PediaCluster resource and can directly use kubectl apply -f to create it.\neg.\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:cluster-examplespec:apiserver:https://10.6.100.10:6443caData:LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeE1Ea3lOREV3TVRNeU5Gb1hEVE14TURreU1qRXdNVE15TkZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTy9TCnZta1U5bk1uUlRIT3lvK3hjdFRJY0lPYnMzc0F5cTI2djRQYkVtb3ZWM2xPOVQwMTF2cE96S0pyOUFxeVZMRnYKVXFBRHBTakM3WXd3MnZwSld3bDEySlBvUm1xZ1FBSFNkYlJpU3BDTDRudjlvR25VOWI2dllWSy9iRitkUVFCSApnQ1h6NnZoTGY4Wmd2N2tUQ2JBdkFPaE9OSlU3MllYTE8zT0lZQjJva1NCRGFVUjNvNnpwZGVWTkt5V0EyNVA3CkRobk8yTk01QzlpRERqTTRLY2FTa3JPSkJvbUlsSHFZRjRwVXdTTlFvcGVGRVRyZ3ZzcTkwSks2YUJVS0t5ajYKK2NGdjI3S0k4K1ZMUEtaSTE2c25Mbng2RXRTazZtZjJXTHdJZlhyQlgwREsvYXBEQ015R2pEb2dCaGpJSVhoVAp2bjVQZndFWUNsdGZFTEhKSkdVQ0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZJVDhLRHdCbUVvMHladUFEZkhkKzQ1L3ZFYzdNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBT0F5VHQ4S3ZFN0dvREhQT09pdgoyR2I2WWVsUU5KcUMza1dIOXc1NTFNaGZvS3ZiM21VaUV6ZVMwOUNwZUQrTFh5ZnlqQzhZYkJxQjZXSFhNZWMrCnpPdDNPazRYV0FmZVVZTXhOQ1FJblc4cjI4cmZnblErc1NCdHQyeERQN1RZY09oNVZGZkI2K3JtTmFTblZ1NjgKSFFxdlFMNEFXbVhkR09jRWNBRThYdkdiOWhwSjVNckRHdzQ0UTYyOG9YazZ0N01aWTFOMUNQdW9HZ1VmS1N3bgo1MUFWRTFOVVdNV0tEQXhaa2I4bEhvR3VWaDFzWmd3SnJRQjR5clh1cmxGN0Y2bVRlYm4rcDVKM0toT0V4KzlsCjFXdkwwbWkxL1J2bVJKNm11YmtjWUwzN1FJWjI1YXdyaEZMN0Z1ejNRSTFqTTdYMHZET2VUM2VuVUFCZW5SMS8KUnlnPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==tokenData:ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklrMHRSalJtZGpSdVgxcFljMGxsU1ZneFlXMHpPSFZOY0Zwbk1UTkhiVFpsVFZwQ2JIWk9SbU5XYW5NaWZRLmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUprWldaaGRXeDBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpXTnlaWFF1Ym1GdFpTSTZJbU5zZFhOMFpYSndaV1JwWVMxemVXNWphSEp2TFhSdmEyVnVMVGsxYTJSNElpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVibUZ0WlNJNkltTnNkWE4wWlhKd1pXUnBZUzF6ZVc1amFISnZJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpYSjJhV05sTFdGalkyOTFiblF1ZFdsa0lqb2lNREl5WXpNMk5USXRPR1k0WkMwME5qSmtMV0l6TnpFdFpUVXhPREF3TnpFeE9HUTBJaXdpYzNWaUlqb2ljM2x6ZEdWdE9uTmxjblpwWTJWaFkyTnZkVzUwT21SbFptRjFiSFE2WTJ4MWMzUmxjbkJsWkdsaExYTjVibU5vY204aWZRLkF4ZjhmbG5oR0lDYjJaMDdkT0FKUW11aHVIX0ZzRzZRSVY5Sm5sSmtPUnF5aGpWSDMyMkVqWDk1bVhoZ2RVQ2RfZXphRFJ1RFFpLTBOWDFseGc5OXpYRks1MC10ZzNfYlh5NFA1QnRFOUpRNnNraUt4dDFBZVJHVUF4bG5fVFU3SHozLTU5Vnl5Q3NwckFZczlsQWQwRFB6bTRqb1dyS1lKUXpPaGl5VjkzOWpaX2ZkS1BVUmNaMVVKVGpXUTlvNEFFY0hMdDlyTEJNMTk2eDRkbzA4ZHFaUnVtTzJZRXFkQTB3ZnRxZ2NGQzdtTGlSVVhkWElkYW9CY1BuWXBwM01MU3B5QjJQMV9vSlRFNS1nd3k4N2Jwb3U1RXo2TElSSExIeW5NWXAtWVRLR2hBbDJwMXdJb0tDZUNnQng4RlRfdzM4Rnh1TnE0UDRoQW5RUUh6bU9Ndw==syncResources:[]View Cluster After a cluster is successfully imported, you can use kubectl get pediacluster to view the imported clusters and check its status\nkubectl get pediacluster # Output: NAME APISERVER URL VERSION STATUS cluster-1 https://10.6.100.10:6443 v1.22.2 Healthy cluster-2 https://10.50.10.11:16443 v1.10.11 Healthy Next See Synchronize Cluster Resources\n","categories":"","description":"","excerpt":"Clusterpedia uses the custom resource - PediaCluster to represent the …","ref":"/docs/usage/import-clusters/","tags":"","title":"Import Clusters"},{"body":"Clusterpedia uses the PediaCluster resource to represent a cluster that needs to synchronize and retrieve resources.\n Clusterpedia needs to be very friendly to other multi-cloud platforms that may use Cluster resource to represent managed clusters, to avoid conflicts Clusterpedia uses PediaCluster.\n $ kubectl get pediacluster NAME APISERVER VERSION STATUS demo1 https://10.6.101.100:6443 v1.22.3-aliyun.1 Healthy demo2 https://10.6.101.100:6443 v1.21.0 Healthy apiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:demo1spec:apiserver:https://10.6.101.100:6443kubeconfig:caData:tokenData:certData:keyData:syncResources:[]syncAllCustomResources:falsesyncResourcesRefName:\"\"PediaCluster has two uses:\n Configure authentication information for the cluster Configure resources for synchronization  Configuring cluster authentication information can be found in Import Clusters\nThere are three fields to configure the resources to be synchronized.\n spec.syncResources configures the resources that need to be synchronized for this cluster spec.syncAllCustomResources synchronizes all custom resources spec.syncResourcesRefName references Public Configuration of Cluster Sync Resources  For details on configuring synchronization resources, see Synchronize Cluster Resources\n","categories":"","description":"","excerpt":"Clusterpedia uses the PediaCluster resource to represent a cluster …","ref":"/docs/concepts/pediacluster/","tags":"","title":"PediaCluster"},{"body":"Clusterpedia 中使用 PediaCluster 资源来代表一个需要同步资源的集群。\n Clusterpedia 需要非常友好的对接到其他多云平台中，而多云平台可能会使用 Cluster 资源来代表纳管的集群，为了避免冲突 Clusterpedia 使用 PediaCluster。\n $ kubectl get pediacluster NAME APISERVER VERSION STATUS demo1 https://10.6.101.100:6443 v1.22.3-aliyun.1 Healthy demo2 https://10.6.101.100:6443 v1.21.0 Healthy apiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:demo1spec:apiserver:https://10.6.101.100:6443kubeconfig:caData:tokenData:certData:keyData:syncResources:[]syncAllCustomResources:falsesyncResourcesRefName:\"\"PediaCluster 有两个作用\n 配置集群的认证信息 配置同步的资源  配置集群认证信息可以参考 集群接入\n有三个字段可以配置同步的资源：\n spec.syncResources 配置该集群需要同步的资源 spec.syncAllCustomResources 同步所有的自定义资源 spec.syncResourcesRefName 引用 公共的集群资源同步配置  具体配置同步资源，可以参考 同步集群资源\n","categories":"","description":"","excerpt":"Clusterpedia 中使用 PediaCluster 资源来代表一个需要同步资源的集群。\n Clusterpedia 需要非常友好的对 …","ref":"/zh-cn/docs/concepts/pediacluster/","tags":"","title":"PediaCluster"},{"body":"We can require the number of remaining resources to be included in the response by search label or url query when querying.\n   search label url query     search.clusterpedia.io/with-remaining-count withRemainingCount     Detailed use can be referred to Response With Remaining Count\n You can set the number of remaining resources to be returned by default via Feature Gates – RemainingItemCount, so that the user does not need to use a search label or url query to display the request at each request.\nWhen the remaining item count is returned by default, you can still request that the remaining item count not be returned via search label or url query.\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?withRemainingCount=false\u0026limit=1\" | jq Feature Gate dedicated to clusterpedia apiserver\n   desc feature gate default     Set whether to return the number of remaining resources by default RemainingItemCount false    This feature is turned off by default because it may have an impact on the behavior or performance of the storage layer.\n For the default storage tier, returning the number of remaining resources results in an additional COUNT query\n ","categories":"","description":"","excerpt":"We can require the number of remaining resources to be included in the …","ref":"/docs/features/remaining-item-count/","tags":"","title":"Return RemainingItemCount"},{"body":"我们在查询时，可以通过 search label 或者 url query，要求在响应中携带剩余的资源数量。\n   search label url query     search.clusterpedia.io/with-continue withContinue     详细使用可以参考 响应携带剩余资源数量信息\n 可以通过 Feature Gates —— RemainingItemCount 来设置默认返回剩余的资源数量，这样用户就不需要在每次请求时使用 search label 或者 url query 来显示要求了。\n在默认返回剩余资源数量时，用于依然可以通过 search label 或者 url quera 来不返回剩余的资源数量\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?withRemainingCount=false\u0026limit=1\" | jq 专属于 clusterpedia apiserver 的 Feature Gate\n   作用 feature gate 默认值     设置是否默认返回剩余的资源数量 RemainingItemCount false    由于该功能可能会对存储层的行为或者性能有影响，所以默认关闭\n 对于默认存储层，返回剩余资源数量会导致额外的 COUNT 查询\n ","categories":"","description":"","excerpt":"我们在查询时，可以通过 search label 或者 url query，要求在响应中携带剩余的资源数量。\n   search label …","ref":"/zh-cn/docs/features/remaining-item-count/","tags":"","title":"返回剩余资源数量"},{"body":"Clusterpedia 的默认存储层支持 MySQL 和 PostgreSQL 两种存储组件。\n用户在安装 Clusterpedia 时，可以使用已存在的存储组件， 不过需要创建相应的默认存储层配置（ConfigMap）和存储组件密码 Secret。\n默认存储层配置 用户需要在 clusterpedia-system 命名空间下创建 clusterpedia-internalstorage ConfigMap。\n# internalstorage configmap exampleapiVersion:v1kind:ConfigMapmetadata:name:clusterpedia-internalstoragenamespace:clusterpedia-systemdata:internalstorage-config.yaml:|type: \"mysql\" host: \"clusterpedia-internalstorage-mysql\" port: 3306 user: root database: \"clusterpedia\" connPool: maxIdleConns: 10 maxOpenConns: 100 connMaxLifetime: 1h log: slowThreshold: \"100ms\" logger: filename: /var/log/clusterpedia/internalstorage.log maxbackups: 3internalstorage config 支持以下基本字段:\n   field description     type 存储组件的类型，支持 “postgres” 和 “mysql”   host 存储组件地址，可以使用 IP 或者 Service Name   port 存储组件端口   user 存储组件用户   password 存储组件密码   database Clusterpedia 所使用的 database    存储组件的访问密码，最好存放在 Secret，参考 配置存储组件密码 Secret\n数据库连接池配置    field description     connPool.maxIdleConns 空闲连接池中的最大数量，默认为 10   connPool.maxOpenConns 打开的数据库连接的最大数量，默认为 100   connPool.connMaxLifetime 连接可以复用的最大时间，默认为 1h    根据用户的当前环境，合理设置数据库连接池\n日志配置 支持配置存储层日志，通过 log 字段来开启日志打印慢 SQL 和错误\n   field description     log.stdout 打印日志到标准输出   log.colorful 是否开启彩色打印   log.slowThreshold 设置慢 SQL 阀值，例如 “100ms”   log.level 设置日志级别，支持 Slient, Error, Warn, Info   log.logger 日志轮滚配置    开启日志打印后，如果 log.stdout 不为 true，则将日志输出到 /var/log/clusterpedia/internalstorage.log 文件中\n日志轮滚配置 将存储层的日志保存到文件中，并且可以配置日志文件的轮滚\n   field description     log.logger.filename 日志文件路径, 默认为 /var/log/clusterpedia/internalstorage.log   log.logger.maxsize 触发日志轮滚的最大文件大小，单位为 MB   log.logger.maxage 轮滚的旧日志的最大存活时间   log.logger.maxbackups 轮滚的旧日志的最大数量   log.logger.localtime 是否为本地时间，默认为 UTC   log.logger.compress 是否将轮滚的日志文件进行压缩，默认不进行压缩    关闭日志打印 在 internalstorage config 不填写 log 字段，便会忽略日志打印，例如：\ntype:\"mysql\"host:\"clusterpedia-internalstorage-mysql\"port:3306user:rootdatabase:\"clusterpedia\"更多配置 默认存储层还提供了有关 MySQL 和 PostgreSQL 的更多配置，可以参考 internalstorage/config.go\n配置存储组件密码 Secret Clusterpedia 的安装 yaml 会从 internalstroage-password 的 Secret 中获取密码。\n将存储组件的密码配置到 Secret 中\nkubectl -n clusterpedia-system create secret generic \\  internalstorage-password --from-literal=password=\u003c存储组件访问密码\u003e ","categories":"","description":"","excerpt":"Clusterpedia 的默认存储层支持 MySQL 和 PostgreSQL 两种存储组件。\n用户在安装 Clusterpedia 时， …","ref":"/zh-cn/docs/installation/configurate/configurate-internalstorage/","tags":"","title":"配置存储层"},{"body":"Clusterpedia 使用自定义资源 PediaCluster 资源来代表接入的集群\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:cluster-examplespec:apiserver:\"https://10.30.43.43:6443\"kubeconfig:caData:tokenData:certData:keyData:syncResources:[]用户有两种方式来配置接入的集群:\n 直接配置 base64 编码的 kube config 到 kubeconfig 字段用于集群连接和验证 分别配置接入集群的地址，以及验证信息  在使用 apiserver 字段来设置接入集群的地址时，验证字段的配置有多种选择：\n caData + tokenData caData + certData + keyData   caData 在集群 APIServer 允许 Insecure 连接的情况下，也可以不填\n 这些验证字段都需要 base64 编码，如果这些字段的值是直接从 ConfigMap 或者 Secret 中获取的话，那么就已经 base64 过。\n使用 kube config 来接入集群 使用 kube config 来连接和验证集群是最简单的一种方式。\n首先需要将接入集群的 kube config base64 编码。\n# mac cat ./kubeconfig | base64 # linux cat ./kubeconfig | base64 -w 0 # 输出 base64 编码后的配置 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  如果 base64 后存在换行，那么可以使用 base64 -w 0 ./kubeconfig\n 将 base64 后的内容设置到 PeidaCluster 的 spec.kubeconfig 中即可，并且 spec.apiserver 以及其他验证字段都不需要填写\n不过由于集群地址在 kube config 中配置，所以使用 kubectl get pediacluster 时 APIServer 为空\nkubectl get pediacluster # 输出： NAME APISERVER URL VERSION STATUS cluster-1 v1.22.2 Healthy 未来会增加 Mutating admission webhooks 来自动设置 spec.apiserver，当前如果用户想要在 kubectl get 时显示集群地址，那么需要手动额外配置 spec.apiserver 字段\n使用 ServiceAccount 来接入集群 用户也可以选择在被接入集群中创建 ServiceAccount 并配置相应的 RBAC 来接入集群。\n# 注意：当前 kubectl 连接到被接入集群 kubectl apply -f https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/main/examples/clusterpedia_synchro_rbac.yaml # 获取 Service Account 对应 CA 和 Token SYNCHRO_CA=$(kubectl -n default get secret $(kubectl -n default get serviceaccount clusterpedia-synchro -o jsonpath='{.secrets[0].name}') -o jsonpath='{.data.ca\\.crt}') SYNCHRO_TOKEN=$(kubectl -n default get secret $(kubectl -n default get serviceaccount clusterpedia-synchro -o jsonpath='{.secrets[0].name}') -o jsonpath='{.data.token}') 将 $SYNCHRO_CA 和 $SYNCHRO_TOKEN 分别填写到 PediaCluster 资源的 spec.caData 和 spec.tokenData 字段中\n创建 PediaCluster 完善集群的验证信息后，就可以获得一个完整的 PediaCluster 资源了。直接使用 kubectl apply -f 直接创建即可\neg.\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:cluster-examplespec:apiserver:https://10.6.100.10:6443caData:LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeE1Ea3lOREV3TVRNeU5Gb1hEVE14TURreU1qRXdNVE15TkZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTy9TCnZta1U5bk1uUlRIT3lvK3hjdFRJY0lPYnMzc0F5cTI2djRQYkVtb3ZWM2xPOVQwMTF2cE96S0pyOUFxeVZMRnYKVXFBRHBTakM3WXd3MnZwSld3bDEySlBvUm1xZ1FBSFNkYlJpU3BDTDRudjlvR25VOWI2dllWSy9iRitkUVFCSApnQ1h6NnZoTGY4Wmd2N2tUQ2JBdkFPaE9OSlU3MllYTE8zT0lZQjJva1NCRGFVUjNvNnpwZGVWTkt5V0EyNVA3CkRobk8yTk01QzlpRERqTTRLY2FTa3JPSkJvbUlsSHFZRjRwVXdTTlFvcGVGRVRyZ3ZzcTkwSks2YUJVS0t5ajYKK2NGdjI3S0k4K1ZMUEtaSTE2c25Mbng2RXRTazZtZjJXTHdJZlhyQlgwREsvYXBEQ015R2pEb2dCaGpJSVhoVAp2bjVQZndFWUNsdGZFTEhKSkdVQ0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZJVDhLRHdCbUVvMHladUFEZkhkKzQ1L3ZFYzdNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBT0F5VHQ4S3ZFN0dvREhQT09pdgoyR2I2WWVsUU5KcUMza1dIOXc1NTFNaGZvS3ZiM21VaUV6ZVMwOUNwZUQrTFh5ZnlqQzhZYkJxQjZXSFhNZWMrCnpPdDNPazRYV0FmZVVZTXhOQ1FJblc4cjI4cmZnblErc1NCdHQyeERQN1RZY09oNVZGZkI2K3JtTmFTblZ1NjgKSFFxdlFMNEFXbVhkR09jRWNBRThYdkdiOWhwSjVNckRHdzQ0UTYyOG9YazZ0N01aWTFOMUNQdW9HZ1VmS1N3bgo1MUFWRTFOVVdNV0tEQXhaa2I4bEhvR3VWaDFzWmd3SnJRQjR5clh1cmxGN0Y2bVRlYm4rcDVKM0toT0V4KzlsCjFXdkwwbWkxL1J2bVJKNm11YmtjWUwzN1FJWjI1YXdyaEZMN0Z1ejNRSTFqTTdYMHZET2VUM2VuVUFCZW5SMS8KUnlnPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==tokenData:ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklrMHRSalJtZGpSdVgxcFljMGxsU1ZneFlXMHpPSFZOY0Zwbk1UTkhiVFpsVFZwQ2JIWk9SbU5XYW5NaWZRLmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUprWldaaGRXeDBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpXTnlaWFF1Ym1GdFpTSTZJbU5zZFhOMFpYSndaV1JwWVMxemVXNWphSEp2TFhSdmEyVnVMVGsxYTJSNElpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVibUZ0WlNJNkltTnNkWE4wWlhKd1pXUnBZUzF6ZVc1amFISnZJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpYSjJhV05sTFdGalkyOTFiblF1ZFdsa0lqb2lNREl5WXpNMk5USXRPR1k0WkMwME5qSmtMV0l6TnpFdFpUVXhPREF3TnpFeE9HUTBJaXdpYzNWaUlqb2ljM2x6ZEdWdE9uTmxjblpwWTJWaFkyTnZkVzUwT21SbFptRjFiSFE2WTJ4MWMzUmxjbkJsWkdsaExYTjVibU5vY204aWZRLkF4ZjhmbG5oR0lDYjJaMDdkT0FKUW11aHVIX0ZzRzZRSVY5Sm5sSmtPUnF5aGpWSDMyMkVqWDk1bVhoZ2RVQ2RfZXphRFJ1RFFpLTBOWDFseGc5OXpYRks1MC10ZzNfYlh5NFA1QnRFOUpRNnNraUt4dDFBZVJHVUF4bG5fVFU3SHozLTU5Vnl5Q3NwckFZczlsQWQwRFB6bTRqb1dyS1lKUXpPaGl5VjkzOWpaX2ZkS1BVUmNaMVVKVGpXUTlvNEFFY0hMdDlyTEJNMTk2eDRkbzA4ZHFaUnVtTzJZRXFkQTB3ZnRxZ2NGQzdtTGlSVVhkWElkYW9CY1BuWXBwM01MU3B5QjJQMV9vSlRFNS1nd3k4N2Jwb3U1RXo2TElSSExIeW5NWXAtWVRLR2hBbDJwMXdJb0tDZUNnQng4RlRfdzM4Rnh1TnE0UDRoQW5RUUh6bU9Ndw==syncResources:[]集群查看 集群接入成功后，可以通过 kubectl get pediacluster 命令来查看所有接入的集群，以及集群状态\nkubectl get pediacluster # 输出： NAME APISERVER URL VERSION STATUS cluster-1 https://10.6.100.10:6443 v1.22.2 Healthy cluster-2 https://10.50.10.11:16443 v1.10.11 Healthy 接下来 继续查看 同步集群资源\n","categories":"","description":"","excerpt":"Clusterpedia 使用自定义资源 PediaCluster …","ref":"/zh-cn/docs/usage/import-clusters/","tags":"","title":"集群接入"},{"body":"Different users may have different needs, and although clusterpedia provides many easy search options, such as specifying a set of namespaces or clusters, or specifying an owner for a query, users may still have more complex queries.\nIn this case, you can use the Raw SQL Query provided by the default storage layer to pass more complex search conditions.\nURL=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments\" kubectl get --raw=\"$URL?whereSQL=(cluster='global') OR (namespace IN ('kube-system','default'))\" In the example, we pass a SQL statement for a WHERE query —— (cluster=‘global’) OR (namespace IN (‘kube-system’,‘default’)),\nThis statement will retrieve deployments under all namespaces in the global cluster and under the kube-system and default namespaces in other clusters.\nThe sql statement needs to conform to the SQL syntax of the specific storage component(MySQL, PostgreSQL).\nThis feature gate is exclusive to the clusterpedia apiserver\n   desc feature gates 默认值     Allow search conditions to be set using raw SQL AllowRawSQLQuery false    Raw SQL queries are currently in alpha and are not well protected against SQL injection, so you need to enable this feature via Feature Gate.\n","categories":"","description":"","excerpt":"Different users may have different needs, and although clusterpedia …","ref":"/docs/features/raw-sql-query/","tags":"","title":"Raw SQL Query"},{"body":"不同的用户的需求可能是不同的，尽管 clusterpedia 提供了很多简便的检索条件，例如指定一组命名空间或者资源名称，也可以指定 owner 进行查询，但是用户依然可能会有更加复杂的查询。\n这时，用户可以使用默认存储层提供的 原生 SQL 条件查询 来传递更加复杂的检索条件\nURL=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments\" kubectl get --raw=\"$URL?whereSQL=(cluster='global') OR (namespace IN ('kube-system','default'))\" 示例中，我们传递一个用于 WHERE 查询的 SQL 语句 —— (cluster=‘global’) OR (namespace IN (‘kube-system’,‘default’)),\n这个语句会检索 global 集群内所有命名空间下以及其他集群中 kube-system 和 default 命名空间下的 deployments。\nsql 语句需要符合具体的存储组件的 SQL 语法\n该特性门控专属于 clusterpedia apiserver\n   作用 feature gates 默认值     允许使用原生 SQL 设置检索条件 AllowRawSQLQuery false    原生 SQL 查询当前还在 alpha 阶段，并且对 SQL 注入没有很好的防范，所以需要用户通过 Feature Gates 来开启该功能\n","categories":"","description":"","excerpt":"不同的用户的需求可能是不同的，尽管 clusterpedia 提供了很多简便的检索条件，例如指定一组命名空间或者资源名称， …","ref":"/zh-cn/docs/features/raw-sql-query/","tags":"","title":"原生 SQL 查询"},{"body":"There are some fields in the resource’s metadata that are usually not very useful in the actual search, so we prune these fields by default when syncing.\nWe use feature gates to separately control whether thess fields are prunned during resource synchronization, these feature gates are exclusive to the clustersynchro manager component\n   field feature gates default     metadata.managedFields PruneManagedFields true   metadata.annotations[‘lastAppliedConfiguration’] PruneLastAppliedConfiguration true    ","categories":"","description":"","excerpt":"There are some fields in the resource’s metadata that are usually not …","ref":"/docs/features/prune-fields/","tags":"","title":"Resource Field Pruning"},{"body":"When client-go creates any number of Clients with the same configuration, such as certificates, it reuses the same TCP connection. https://github.com/kubernetes/kubernetes/blob/3f823c0daa002158b12bfb2d53bcfe433516659d/staging/src/k8s.io/client-go/transport/transport.go#L54\nThis results in the cluster health check interface using the same TCP connection as the resource synchronized informer, which may cause TCP blocking and increased health check latency if a large number of informers are started for the first time. We add a feature gate - HealthCheckerWithStandaloneTCP to allow users to use a standalone tcp for health checks\n./clustersynchro-manager --feature-gates=HealthCheckerWithStandaloneTCP=true    desc feature gates default     Use standalone tcp for health checker HealthCheckerWithStandaloneTCP false    Note: When this feature is turned on, the TCP long connections to member clusters will change from 1 to 2. If 1000 clusters are imported, then ClusterSynchro Manager will keep 2000 TCP connections.\n","categories":"","description":"","excerpt":"When client-go creates any number of Clients with the same …","ref":"/docs/features/health-checker-with-standalone-tcp/","tags":"","title":"Standalone TCP for Health Checker"},{"body":"在 client-go 中使用相同的配置连接一个集群时，会使用同一条 TCP 连接 https://github.com/kubernetes/kubernetes/blob/3f823c0daa002158b12bfb2d53bcfe433516659d/staging/src/k8s.io/client-go/transport/transport.go#L54\n这导致集群的健康检查会和资源同步的 Informer 使用相同的 TCP。在大量资源 Informer 启动时，由于 TCP 阻塞可能会导致健康检查的请求超时，这时即使集群是健康的也会导致健康检查失败。\n我们现在允许健康检查使用单独的一条 TCP 连接，这样资源同步时的 TCP 拥堵并不会影响到健康检查的响应。该功能需要开启 Feature Gate —— HealthCheckerWithStandaloneTCP\n   作用 feature gates 默认值     集群健康检查使用独立 TCP 连接 HealthCheckerWithStandaloneTCP false    注意：开启该功能后，连接到成员集群的 TCP 长连接会从 1 变成 2，如果接入 1000 个集群，那么 ClusterSynchro Manager 会维持 2000 条 TCP 连接。\n","categories":"","description":"","excerpt":"在 client-go 中使用相同的配置连接一个集群时，会使用同一条 TCP …","ref":"/zh-cn/docs/features/health-checker-with-standalone-tcp/","tags":"","title":"独立健康检查连接"},{"body":"资源的 metadata 中有一些字段在实际搜索中通常没有太大用处，所以在同步时我们会默认裁剪这些字段。\n我们使用特性门控来分别控制这些字段是否在资源同步时被裁剪，这些特性门控专属于 clustersynchro manager 组件\n   field feature gates 默认值     metadata.managedFields PruneManagedFields true   metadata.annotations[‘lastAppliedConfiguration’] PruneLastAppliedConfiguration true    ","categories":"","description":"","excerpt":"资源的 metadata 中有一些字段在实际搜索中通常没有太大用处，所以在同步时我们会默认裁剪这些字段。\n我们使用特性门控来分别控制这些字段 …","ref":"/zh-cn/docs/features/prune-fields/","tags":"","title":"资源字段裁剪"},{"body":"The custom resources differ from kube’s built-in resources in that kube’s built-in resources do not usually change on a regular basis (there are still two cases where the native resource type can change).\nThe custom resource types can be created and deleted dynamically.\nIf you want to automatically adjust the synchronized resource types based on changes in the CRD of the imported cluster, you specify in PediaCluster to synchronize all custom resources.\nspec:syncAllCustomResources:trueThis feature may cause a lot of long connections, so you need to enable Feature Gate in the clustersynchro manager.\n   desc feature gate default     Allow synchronization of all custom resources AllowSyncAllCustomResources true    ","categories":"","description":"","excerpt":"The custom resources differ from kube’s built-in resources in that …","ref":"/docs/features/sync-all-custom-resources/","tags":"","title":"Sync All Custom Resources"},{"body":"自定义资源不同于 kube 的内置资源，kube 的内置资源通常不会经常性变动(依然有两种情况会导致原生资源类型资源改变)， 而自定义资源的类型可能会被动态的创建和删除\n用户如果想要根据被纳管集群中的 CRD 的变动来自动调节同步的资源类型,那么用户在 PediaCluster 中指定同步所有自定义资源。\nspec:syncAllCustomResources:true该功能可能会导致大量的长连接，所以需要在 clustersynchro manager 中开启 Feature Gate\n   作用 feature gate 默认值     允许同步所有的自定义资源 AllowSyncAllCustomResources true    ","categories":"","description":"","excerpt":"自定义资源不同于 kube 的内置资源，kube 的内置资源通常不会经常性变动(依然有两种情况会导致原生资源类型资源改变)， 而自定义资源的 …","ref":"/zh-cn/docs/features/sync-all-custom-resources/","tags":"","title":"同步所有的自定义资源"},{"body":"The Clusterpedia provides the public configuration of cluster sync resources —— ClusterSyncResources\nkubectl get clustersyncresources The spec.syncResources field of ClusterSyncResources is configured in the same way as PediaCluster’s spec.syncResources, see Synchronize Cluster Resources\napiVersion:cluster.clusterpedia.io/v1alpha2kind:ClusterSyncResourcesmetadata:name:global-basespec:syncResources:- group:\"\"resources:- pods- group:\"apps\"resources:- \"*\"The spec.syncAllCustomResource field will be supported in the future to support setting up the synchronization of all custom resources\nAny PediaCluster can refer to the same ClusterSyncResources via spec.syncResourcesRefName field.\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:demo1spec:syncResourcesRefName:\"global-base\"When we modify ClusterSyncResources, all resource types syncronized within the PediaCluster that reference it will be modified accordingly.\nIf PediaCluster has both spec.syncResourcesRefName and spec.syncResources set, then the concatenation of the two will be used.\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:demo1spec:syncResourcesRefName:\"global-base\"syncResources:- group:\"\"resources:- pods- configmapsIn the above example, clusterpedia synchronizes the pods and configmaps resources, and all resources under the apps group in the demo1 cluster.\n","categories":"","description":"","excerpt":"The Clusterpedia provides the public configuration of cluster sync …","ref":"/docs/concepts/cluster-sync-resources/","tags":"","title":"Public Configuration of Cluster Sync Resources(ClusterSyncResources)"},{"body":"You can synchronize all types of resources with the All-resource Wildcard, and any resource type change in the imported cluster (e.g. kube version upgrade, group/version disabled, CRD or APIService change) will cause the synchronized resource type to be modified.\nspec:syncResources:- group:\"*\"resources:- \"*\"Please use this feature with caution, it will create a lot of long connections, in the future Clusterpedia will add the Agent feature to avoid the creation of long connections\nIt is recommended to specify specific resource types, if you need to dynamically synchronize custom resources, you can use Sync all custom resources.\nTo use All-resources Wildcard you need to enable Feature Gate in clustersynchro manager.\n   desc feature gate default     Allow synchronization of all resources AllowSyncAllResources true    ","categories":"","description":"","excerpt":"You can synchronize all types of resources with the All-resource …","ref":"/docs/features/sync-all-resources/","tags":"","title":"Sync All Resources"},{"body":"Clusterpedia 提供了公共的集群资源同步配置 —— ClusterSyncResources。\nkubectl get clustersyncresources ClusterSyncResources 的 spec.syncResources 字段和 PediaCluster 的 spec.syncResources 配置方式相同，可以参考 同步集群资源\napiVersion:cluster.clusterpedia.io/v1alpha2kind:ClusterSyncResourcesmetadata:name:global-basespec:syncResources:- group:\"\"resources:- pods- group:\"apps\"resources:- \"*\"未来会支持 spec.syncAllCustomResources 字段来支持设置同步所有的自定义资源\n任何 PediaCluster 都可以通过 spec.syncResourcesRefName 引用相同的 ClusterSyncResources。\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:demo1spec:syncResourcesRefName:\"global-base\"当我们修改 ClusterSyncResources 时，所有引用它的 PediaCluster 内同步的资源都会发生相应的修改。\n如果 PediaCluster 同时设置了 spec.syncResourcesRefName 和 spec.syncResources，那么会取两者的并集\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:demo1spec:syncResourcesRefName:\"global-base\"syncResources:- group:\"\"resources:- pods- configmaps上例中，clusterpedia 会同步 demo1 集群中 pods 和 configmaps，以及 apps group 下的所有资源。\n","categories":"","description":"","excerpt":"Clusterpedia 提供了公共的集群资源同步配置 —— ClusterSyncResources。\nkubectl get …","ref":"/zh-cn/docs/concepts/cluster-sync-resources/","tags":"","title":"公共的集群资源同步配置(ClusterSyncResources)"},{"body":"用户可以通过 全资源通配符 来同步所有类型的资源，当被纳管集群中发生任意的资源类型变动(例如 kube 版本升级，group/version 被禁用，CRD 或者 APIService 变动)都会导致同步的资源类型发生修改。\nspec:syncResources:- group:\"*\"resources:- \"*\"请谨慎使用该功能，该功能会创建大量的长连接，未来 Clusterpedia 添加 Agent 功能后，可以避免长连接的创建\n建议指定具体的资源类型，如果需要对自定义资源进行动态同步，可以使用 同步所有的自定义资源\n使用全资源通配符 需要在 clustersynchro manager 中开启 Feature Gate\n   作用 feature gate 默认值     允许同步所有的资源 AllowSyncAllResources true    ","categories":"","description":"","excerpt":"用户可以通过 全资源通配符 来同步所有类型的资源，当被纳管集群中发生任意的资源类型变动(例如 kube 版本升级，group/version …","ref":"/zh-cn/docs/features/sync-all-resources/","tags":"","title":"同步所有的资源"},{"body":"In order to query multiple types of resources at once, Clusterpedia provides a new resource: Collection Resource.\nCollection Resource is composed of different types of resources, and these resources can be retrieved and paged in a uniform way through the Collection Resource.\nWhat Collection Resources are supported by the Clusterpedia depends on the Storage Layer. For example, the Default Storage Layer temporarily supports the any, workloads and kuberesources.\nkubectl get collectionresources # Output: NAME RESOURCES any * workloads deployments.apps,daemonsets.apps,statefulsets.apps kuberesources .*,*.admission.k8s.io,*.admissionregistration.k8s.io,*.apiextensions.k8s.io,*.apps,*.authentication.k8s.io,*.authorization.k8s.io,*.autoscaling,*.batch,*.certificates.k8s.io,*.coordination.k8s.io,*.discovery.k8s.io,*.events.k8s.io,*.extensions,*.flowcontrol.apiserver.k8s.io,*.imagepolicy.k8s.io,*.internal.apiserver.k8s.io,*.networking.k8s.io,*.node.k8s.io,*.policy,*.rbac.authorization.k8s.io,*.scheduling.k8s.io,*.storage.k8s.io any means any resources, the use need to pass the groups or resources he wants to combine when using it, for details see Use Any CollectionResource\nkuberesources contains all of kube’s built-in resources, and we can use kuberesources to filter and search all of theme in a uniform api.\nView the supported Collection Resource in a yaml file\nkubectl get collectionresources -o yaml # Output:apiVersion:v1items:- apiVersion:clusterpedia.io/v1beta1kind:CollectionResourcemetadata:creationTimestamp:nullname:anyresourceTypes:[]- apiVersion:clusterpedia.io/v1beta1kind:CollectionResourcemetadata:creationTimestamp:nullname:workloadsresourceTypes:- group:appsresource:deploymentsversion:v1- group:appsresource:daemonsetsversion:v1- group:appsresource:statefulsetsversion:v1- apiVersion:clusterpedia.io/v1beta1kind:CollectionResourcemetadata:creationTimestamp:nullname:kuberesourcesresourceTypes:- group:\"\"- group:admission.k8s.io- group:admissionregistration.k8s.io- group:apiextensions.k8s.io- group:apps- group:authentication.k8s.io- group:authorization.k8s.io- group:autoscaling- group:batch- group:certificates.k8s.io- group:coordination.k8s.io- group:discovery.k8s.io- group:events.k8s.io- group:extensions- group:flowcontrol.apiserver.k8s.io- group:imagepolicy.k8s.io- group:internal.apiserver.k8s.io- group:networking.k8s.io- group:node.k8s.io- group:policy- group:rbac.authorization.k8s.io- group:scheduling.k8s.io- group:storage.k8s.iokind:Listmetadata:resourceVersion:\"\"selfLink:\"\"It is found that workloads includes three resources: deployments, daemonsets, and statefulsets.\nAnd kuberesources contains all of kube’s built-in resources.\nFor details about Collection Resource, see Search for Collection Resource\nCustom Collection Resource Clusterpedia plans to provide two ways to let users combine the types of resources they want to query at will.\n Any CollectionResource —— use any collectionresource CustomCollectionResource —— custom collection resource  After 0.4, Clusterpedia provides any collectionresource to allow users to combine defferent types of resources by passing groups and resources parameters.\nHowever, it should be noted that any collectionresource cannot be retrieved using kubectl, see Using Any CollectionResource\n$ kubectl get collectionresources any Error from server (BadRequest): url query - `groups` or `resources` is required Custom Collection Resource allows users to create or update a Collection Resource via kubectl apply collectionresource \u003ccollectionresource name\u003e, and users can configure the resource type of the Collection Resource at will.\napiVersion:clusterpedia.io/v1beta1kind:CollectionResourcemetadata:name:workloadsresourceTypes:- group:appsresource:deployments- group:appsresource:daemonsets- group:appsresource:statefulsets- group:batchresource:cronjobsCustom Collection Resource are not currently supported\n","categories":"","description":"","excerpt":"In order to query multiple types of resources at once, Clusterpedia …","ref":"/docs/concepts/collection-resource/","tags":"","title":"Collection Resource"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/installation/","tags":"","title":"Installation"},{"body":"After 0.4.0, Clusterpedia provides a more friendly way to interface to multi-cloud platforms.\nUsers can create ClusterImportPolicy to automatically discover managed clusters in the multi-cloud platform and automatically synchronize them as PediaCluster, so you don’t need to maintain PediaCluster manually based on the managed clusters.\nWe maintain PediaCluster for each multi-cloud platform in the Clusterpedia repository. ClusterImportPolicy` for each multi-cloud platform. People also submit ClusterImportPolicy to Clusterpedia for interfacing to other multi-cloud platforms.\nAfter installing Clusterpedia, you can create the appropriate ClusterImportPolicy, or you can create a new ClusterImportPolicy according to your needs (multi-cloud platform).\nClusterAPI ClusterImportPolicy Users can refer to Cluster API Quick Start to install the Cluster API，or refer to Quickly deploy Cluster API + Clusterpedia to deploy a sample environment.\nCreate ClusterImportPolicy for interfacing to the ClusterAPI platform.\n$ kubectl apply -f https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/main/deploy/clusterimportpolicy/cluster_api.yaml $ kubectl get clusterimportpolicy NAME AGE cluster-api 4d19h If the clusters created by the ClusterAPI already exists in the management cluster, then you can view the Cluster and PediaCluster resources.\n$ kubectl get cluster NAME PHASE AGE VERSION capi-quickstart Provisioned 3d23h v1.24.2 capi-quickstart-2 Provisioned 3d23h v1.24.2 $ kubectl get pediaclusterlifecycle NAME AGE default-capi-quickstart 3d23h default-capi-quickstart-2 3d23h $ kubectl get pediacluster NAME READY VERSION APISERVER default-capi-quickstart True v1.24.2 default-capi-quickstart-2 True v1.24.2 PediaCluster is automatically created based on the Cluster, and the kubeconfig of PediaCluster is automatically updated when the kubeconfig of the Cluster changes.\nWhen creating a new Cluster, Clusterpedia automatically creates a PediaCluster when ControlPlaneInitialized is True according to the Cluster API ClusterImportPolicy, and you can check the initialization status of the cluster by using kubectl get kubeadmcontrolplane\nNAME CLUSTER INITIALIZED API SERVER AVAILABLE REPLICAS READY UPDATED UNAVAILABLE AGE VERSION capi-quickstart-2xcsz capi-quickstart true 1 1 1 86s v1.24.2 Once the Cluster has been initialized, you can use kubectl to retrieve multiple cluster resources directly.\n Beforing using kubectl, you need to generate cluster shortcut configuration for multi-cluster resource retrieval.\n $ # Since CNI is not installed, the nodes are not ready. $ kubectl --cluster clusterpedia get no CLUSTER NAME STATUS ROLES AGE VERSION default-capi-quickstart-2 capi-quickstart-2-ctm9k-g2m87 NotReady control-plane 12m v1.24.2 default-capi-quickstart-2 capi-quickstart-2-md-0-s8hbx-7bd44554b5-kzcb6 NotReady \u003cnone\u003e 11m v1.24.2 default-capi-quickstart capi-quickstart-2xcsz-fxrrk NotReady control-plane 21m v1.24.2 default-capi-quickstart capi-quickstart-md-0-9tw2g-b8b4f46cf-gggvq NotReady \u003cnone\u003e 20m v1.24.2 Karmada ClusterImportPolicy  For Karmada platform, you need to first deploy Clusterpedia in Karmada APIServer, the deployment steps can be found at https://github.com/Iceber/deploy-clusterpedia-to-karmada\n Create ClusterImportPolicy for interfacing to the Karmada platform.\n$ kubectl create -f https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/main/deploy/clusterimportpolicy/karmada.yaml $ kubectl get clusterimportpolicy NAME AGE karmada 7d5h View Karmada Cluster and PediaClusterLifecycle resources.\n$ kubectl get cluster NAME VERSION MODE READY AGE argocd Push False 8d member1 v1.23.4 Push True 22d member3 v1.23.4 Pull True 22d $ kubectl get pediaclusterlifecycle NAME AGE karmada-argocd 7d5h karmada-member1 7d5h karmada-member3 7d5h Clusterpedia creates a corresponding PediaClusterLifecycle for each Karmada Cluster, and you can use kubectl describe pediaclusterlifecycle \u003cname\u003e to see the status of the transition between Karmada Cluster and PediaCluster resources.\n The status will be detailed in kubectl get pediaclusterlifecycle in the future\n View the successfully created PediaCluster\nNAME APISERVER VERSION STATUS karmada-member1 https://172.18.0.4:6443 v1.23.4 Healthy The karmada clusterimportpolicy requires the karmada cluster to be in Push mode and in Ready state, so the karmada-member-1 pediacluster resource is created for the member-1 cluster.\nVCluster ClusterImportPolicy Create the ClusterImportPolicy for auto-discovery of VCluster.\n$ kubectl create -f https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/main/deploy/clusterimportpolicy/vcluster.yaml $ kubectl get clusterimportpolicy NAME AGE vclsuter 5h Note that the VCluster cluster needs to be created in such a way that the Server address of the generated kubeconfig can be accessed by other Pods in the host cluster.\nThis can be set to a VCluster Service domain name, a Node IP or an Ingress address.\nsyncer:extraArgs:- --out-kube-config-server=https://\u003cvcluster name\u003e.\u003cnamespace\u003e.svc- --tls-san=\u003cvcluster name\u003e.\u003cnamespace\u003e.svc,127.0.0.1Create two VClusters in the default namespace\ncreate the virtual cluster vcluster-1\n# vcluster-1.yamlsyncer:extraArgs:- --out-kube-config-server=https://vcluster-1.default.svc- --tls-san=vcluster-1.default.svc,127.0.0.1$ vcluster create -n default -f vcluster-1.yaml vcluster-1 create the virtual cluster vcluster-2\n# vcluster-2.yamlsyncer:extraArgs:- --out-kube-config-server=https://vcluster-2.default.svc- --tls-san=vcluster-2.default.svc,127.0.0.1$ vcluster create -n default -f vcluster-2.yaml vcluster-2 List all VCluster clusters\n$ vcluster list NAME NAMESPACE STATUS CONNECTED CREATED AGE caiwei-vcluster caiwei-vcluster Running 2022-08-26 16:10:52 +0800 CST 484h49m6s vcluster-1 default Running 2022-09-15 20:57:59 +0800 CST 1m59s vcluster-2 default Running 2022-09-15 20:59:34 +0800 CST 24s We can use kubectl + Clusterpedia directly to retrieve the resources in any VCluster.\n Beforing using kubectl, you need to generate cluster shortcut configuration for multi-cluster resource retrieval.\n $ kubectl --cluster clusterpedia get po -A NAMESPACE CLUSTER NAME READY STATUS RESTARTS AGE default vc-caiwei-vcluster-caiwei-vcluster backend-77f8f45fc8-5ssww 1/1 Running 0 20d default vc-caiwei-vcluster-caiwei-vcluster backend-77f8f45fc8-j5m4c 1/1 Running 0 20d default vc-caiwei-vcluster-caiwei-vcluster backend-77f8f45fc8-vjzf6 1/1 Running 0 20d kube-system vc-default-vcluster-1 coredns-669fb9997d-cxktv 1/1 Running 0 3m40s kube-system vc-default-vcluster-2 coredns-669fb9997d-g7w8l 1/1 Running 0 2m6s kube-system vc-caiwei-vcluster-caiwei-vcluster coredns-669fb9997d-x6vc2 1/1 Running 0 20d $ kubectl --cluster clusterpedia get ns CLUSTER NAME STATUS AGE vc-default-vcluster-2 default Active 2m49s vc-default-vcluster-1 default Active 4m24s vc-caiwei-vcluster-caiwei-vcluster default Active 20d vc-default-vcluster-2 kube-node-lease Active 2m49s vc-default-vcluster-1 kube-node-lease Active 4m24s vc-caiwei-vcluster-caiwei-vcluster kube-node-lease Active 20d vc-default-vcluster-2 kube-public Active 2m49s vc-default-vcluster-1 kube-public Active 4m24s vc-caiwei-vcluster-caiwei-vcluster kube-public Active 20d vc-default-vcluster-2 kube-system Active 2m49s vc-default-vcluster-1 kube-system Active 4m24s vc-caiwei-vcluster-caiwei-vcluster kube-system Active 20d Clusterpedia will automatically discover the virtual clusters(VClusters) within the host cluster and create the corresponding PediaCluster according to the VCluster ClusterImportPolicy, and users can access Clusterpedia directly to retrieve resources\n$ kubectl get pediaclusterlifecycle NAME AGE vc-caiwei-vcluster-caiwei-vcluster 20d vc-default-vcluster-1 5m57s vc-default-vcluster-2 4m24s $ kubectl get pediacluster NAME READY VERSION APISERVER vc-caiwei-vcluster-caiwei-vcluster True v1.23.5+k3s1 https://caiwei-vcluster.caiwei-vcluster.svc vc-default-vcluster-1 True v1.23.5+k3s1 https://vcluster-1.default.svc vc-default-vcluster-2 True v1.23.5+k3s1 https://vcluster-2.default.svc New ClusterImportPolicy If the Clusterpedia repository does not maintain a ClusterImportPolicy for a platform, then we can create a new ClusterImportPolicy\nA detailed description of the ClusterImportPolicy principles and fields can be found in the Cluster Auto Import Policy\nNow assume that there is a multi-cloud platform MCP that uses a custom resource – Cluster to represent the managed clusters and stores the cluster authentication information in a Secret with the same name as the cluster\napiVersion:cluster.mcp.iokind:Clustermetadata:name:cluster-1spec:apiEndpoint:\"https://172.10.10.10:6443\"authSecretRef:namespace:\"default\"name:\"cluster-1\"status:conditions:- type:Readystatus:True---apiVersion:v1kind:Secretmetadata:name:cluster-1data:ca:**clusterca bundle**token:**clustertoken**We define a ClusterImportPolicy resource for the MCP platform and synchronize the pods resource and all resources under the apps group by default.\napiVersion:policy.clusterpedia.io/v1alpha1kind:ClusterImportPolicymetadata:name:mcpspec:source:group:\"cluster.mcp.io\"resource:clustersversions:[]references:- group:\"\"resource:secretsversions:[]namespaceTemplate:\"{{ .source.spec.authSecretRef.namespace }}\"nameTemplate:\"{{ .source.spec.authSecretRef.name }}\"key:authSecretnameTemplate:\"mcp-{{ .source.metadata.name }}\"template:|spec: apiserver: \"{{ .source.spec.apiEndpoint }}\" caData: \"{{ .references.authSecret.data.ca }}\" tokenData: \"{{ .references.authSecret.data.token }}\" syncResources: - group: \"\" resources: - \"pods\" - group: \"apps\" resources: - \"*\" syncResourcesRefName: \"\"creationCondition:|{{ if ne .source.spec.apiEndpoint \"\" }} {{ range .source.status.conditions }} {{ if eq .type \"Ready\" }} {{ if eq .status \"True\" }} true {{ end }} {{ end }} {{ end }} {{ end }} spec.source defines the resource Cluster that needs to be watched to spec.preferences defines the resources involved in converting an MCP Cluster to a PediaCluster, currently only secrets resources are used spec.nameTemplate will render the name of the PediaCluster resource based on the MCP Cluster resource spec.template renders the PediaCluster resource from the resources defined in MCP Cluster and spec.references, see PediaCluster Template for rules spec.creationCondition determines when a PediaCluster can be created based on the resources defined by the MCP Cluster and spec.references, here it defines when the MCP Cluster is Ready before creating the PediaCluster. See Creation Condition for details  ","categories":"","description":"","excerpt":"After 0.4.0, Clusterpedia provides a more friendly way to interface to …","ref":"/docs/usage/interfacing-to-multi-cloud-platforms/","tags":"","title":"Interfacing to Multi-Cloud Platforms"},{"body":"Install The installation of Clusterpedia is divided into several parts:\n Install storage component Install Clusterpedia Final check   If you use existing storage component (MySQL or PostgreSQL), directly skip the step of installing the storage component.\n Pull clusterpedia project:\ngit clone https://github.com/clusterpedia-io/clusterpedia.git cd clusterpedia git checkout v0.7.0 Install storage component Clusterpedia installation provides two storage components (MySQL 8.0 and PostgreSQL 12) to choose.\n If you use existing storage components (MySQL or PostgreSQL), directly skip this step\n PostgreSQL MySQL Go to the installation directory of the selected storage component\ncd ./deploy/internalstorage/postgres  Go to the installation directory of the selected storage component\ncd ./deploy/internalstorage/mysql  The storage component uses the Local PV method to store data, and you shall specify the node where the Local PV is located during deployment\n You can choose to provide your own PV\n export STORAGE_NODE_NAME=\u003cnodename\u003e sed \"s|__NODE_NAME__|$STORAGE_NODE_NAME|g\" `grep __NODE_NAME__ -rl ./templates` \u003e clusterpedia_internalstorage_pv.yaml Deploy storage component\nkubectl apply -f . # Go back to Clusterpedia root directory cd ../../../ Install Clusterpedia Once the storage component are successfully deployed, you can install the Clusterpedia.\nIf you uses existing storage component, refer to Configure Storage Layer to set the storage component into Default Storage Layer\n Run the following cmd in the clusterpedia root directory\n # Deploy Clusterpedia CRD and components kubectl apply -f ./deploy Final check Check if the component Pods are running properly\nkubectl -n clusterpedia-system get pods Create Cluster Auto Import Policy —— ClusterImportPolicy After 0.4.0, Clusterpedia provides a more friendly way to interface to multi-cloud platforms.\nUsers can create ClusterImportPolicy to automatically discover managed clusters in the multi-cloud platform and automatically synchronize them as PediaCluster, so you don’t need to maintain PediaCluster manually based on the managed clusters.\nWe maintain PediaCluster for each multi-cloud platform in the Clusterpedia repository. ClusterImportPolicy` for each multi-cloud platform. People also submit ClusterImportPolicy to Clusterpedia for interfacing to other multi-cloud platforms.\nAfter installing Clusterpedia, you can create the appropriate ClusterImportPolicy, or create a new ClusterImportPolicy according to your needs (multi-cloud platform).\nFor details, please refer to Interfacing to Multi-Cloud Platforms\nkubectl get clusterimportpolicy Uninstall Clean up ClusterImportPolicy If you have deployed ClusterImportPolicy then you need to clean up the ClusterImportPolicy resources first.\nkubectl get clusterimportpolicy Clean up PediaCluster Before uninstalling Clusterpedia, you need to check if PediaCluster resources still exist in your environment, and clean up those resources.\nkubectl get pediacluster Uninstall Clusterpedia After the PediaCluster resource cleanup is complete, uninstall the Clusterpedia components.\nkubectl delete -f ./deploy/clusterpedia_apiserver_apiservice.yaml kubectl delete -f ./deploy/clusterpedia_apiserver_deployment.yaml kubectl delete -f ./deploy/clusterpedia_clustersynchro_manager_deployment.yaml kubectl delete -f ./deploy/clusterpedia_apiserver_rbac.yaml kubectl delete -f ./deploy/cluster.clusterpedia.io_pediaclusers.yaml Uninstall Storage Component Remove related resources depending on the type of storage component selected.\nkubectl delete -f ./deploy/internalstorage/\u003cstorage type\u003e remove Local PV and clean up data After the storage component is uninstalled, the Local PV and corresponding data will still be left in the node and we need to clean it manually.\nView the mounted nodes via Local PV resource details.\nkubectl get pv clusterpedia-internalstorage-\u003cstorage type\u003e Once you know the node where the data is stored, you can delete the Local PV.\nkubectl delete pv clusterpedia-internalstorage-\u003cstorage type\u003e Log in to the node where the data is located and clean up the data.\n# In the node where the legacy data is located rm -rf /var/local/clusterpedia/internalstorage/\u003cstorage type\u003e ","categories":"","description":"","excerpt":"Install The installation of Clusterpedia is divided into several …","ref":"/docs/installation/kubectl-apply/","tags":"","title":"kubectl apply"},{"body":"Clusterpedia provides kube-state-metrics features for multi-cluster resources at a fraction of the cost, providing the same metrics information as kube-state-metrics, but with the addition of a cluster name label.\nkube_deployment_created{cluster=\"test-14\",namespace=\"clusterpedia-system\",deployment=\"clusterpedia-apiserver\"} 1.676557618e+09 Since this feature is experimental, you will install Clusterpedia the standard way first.\nOnce Clusterpedia is installed, we need to update the helm to enable the multi-cluster kube-state-metrics feature.\n The kube-state-metrics feature has been merged into the main branch and will be included in v0.8.0 in the future. The feature is included in the ghcr.io/iceber/clusterpedia/clustersynchro-manager:v0.8.0-ksm.0\n Enable Multi-Cluster kube-state-metrics Ensure Clusterpedia Chart Version \u003e= v1.8.0 $ helm repo update clusterpedia $ helm search clusterpedia NAME CHART VERSION APP VERSION DESCRIPTION clusterpedia/clusterpedia 1.8.0 v0.7.0 A Helm chart for Kubernetes Get the current chart values $ helm -n clusterpedia-system get values clusterpedia \u003e values.yaml Create patch values $ echo \"clustersynchroManager:image:repository:iceber/clusterpedia/clustersynchro-managertag:v0.8.0-ksm.0kubeStateMetrics:enable:true\" \u003e patch.yamlUpdate Clusterpedia to enable multi-cluster kube-state-metrics. $ helm -n clusterpedia-system upgrade -f values.yaml -f patch.yaml clusterpedia clusterpedia/clusterpedia Get clusterpedia kube-state-metrics services\n$ kubectl -n clusterpedia-system get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE clusterpedia-apiserver ClusterIP 10.97.129.238 \u003cnone\u003e 443/TCP 150d clusterpedia-clustersynchro-manager-metrics ClusterIP 10.108.129.32 \u003cnone\u003e 8081/TCP 51m clusterpedia-kube-state-metrics ClusterIP 10.108.130.62 \u003cnone\u003e 8080/TCP 43m clusterpedia-mysql ClusterIP 10.102.38.225 \u003cnone\u003e 3306/TCP 150d clusterpedia-mysql-headless ClusterIP None \u003cnone\u003e 3306/TCP 150d For more information on importing clusters and using clusterpedia: Import Clusters\nFuture Multi-cluster kube-state-metrics is a very interesting feature that removes the need to install a single-cluster version of kube-state-metrics in each cluster, and it handles the issue of differing resource versions very well.\nThere is a lot of discussion about this feature here, feel free to comment!\n The resource state metrics provide different metrics paths depending on the cluster Support remote write to send resource metrics data Support for filtering exposed resource state metrics based on namespace Support for filtering exposed resource state metrics by cluster labels/annotations  Also welcome to create a new issue\n","categories":"","description":"","excerpt":"Clusterpedia provides kube-state-metrics features for multi-cluster …","ref":"/docs/advanced-features/kube_state_metrics/","tags":"","title":"Multi-Cluster kube-state-metrics"},{"body":"Multi-cluster resource search allows us to filter resources in multiple clusters at once based on query criteria, and provides the ability to paginate and sort these resources.\nWhen using kubectl, we can see what resources are currently available for search\nkubectl --cluster clusterpedia api-resources # Output： NAME SHORTNAMES APIVERSION NAMESPACED KIND configmaps cm v1 true ConfigMap namespaces ns v1 false Namespace nodes no v1 false Node pods po v1 true Pod secrets v1 true Secret daemonsets ds apps/v1 true DaemonSet deployments deploy apps/v1 true Deployment replicasets rs apps/v1 true ReplicaSet issuers cert-manager.io/v1 true Issuer Clusterpedia provides multi-cluster resource search based on all cluster-synchronized resources, and we can view Sync Cluster Resources to update the resources that need to be synchronized.\nBasic Features Specify Clusters When searching multiple clusters, all clusters will be retrieved by default, we can also specify a single cluster or a group of clusters\nkubectl URL Use Search Label search.clusterpedia.io/clusters to specify a group of clusters.\nkubectl --cluster clusterpedia get deployments -l \"search.clusterpedia.io/clusters in (cluster-1,cluster-2)\" # Output： NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kube-system cluster-1 coredns 2/2 2 2 68d kube-system cluster-2 coredns 2/2 2 2 64d For specifying a single cluster search, we can also use Search Label to set it up, or see Search in Specified Cluster to specify a cluster using URL Path.\n# specifying a single cluster kubectl --cluster clusterpedia get deployments -l \"search.clusterpedia.io/clusters=cluster-1\" # specifying a cluster can also be done with --cluster \u003ccluster name\u003e kubectl --cluster cluster-1 get deployments  When using URL, use clusters as URL Query to pass.\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?clusters=cluster-1\" If we specify a single cluster, we can also put the cluster name in the URL Path.\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-1/apis/apps/v1/deployments\" Lean More Specify Cluster Search\n Specify Namespaces We can specify a single namespace or all namespaces as if we were viewing a native Kubernetes resource.\nkubectl URL Use -n \u003cnamespace\u003e to specify the namespace, the default is in the default namespace\nkubectl --cluster clusterpedia get deployments -n kube-system # Output： CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE cluster-1 coredns 2/2 2 2 68d cluster-2 calico-kube-controllers 1/1 1 1 64d cluster-2 coredns 2/2 2 2 64d Use -A or --all-namespaces to see the resources under all namespaces for all clusters\nkubectl --cluster clusterpedia get deployments -A # Output： NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kube-system cluster-1 coredns 2/2 2 2 68d kube-system cluster-2 calico-kube-controllers 1/1 1 1 64d kube-system cluster-2 coredns 2/2 2 2 64d default cluster-2 dd-airflow-scheduler 0/1 1 0 54d default cluster-2 dd-airflow-web 0/1 1 0 54d  The URL Path to get the resources is the same as the native Kubernetes /apis/apps/v1/deployments.\nWe just need to prefix the path to Clusterpedia Resources with /apis/clusterpedia.io/v1beta1/resources to indicate that it is currently a Clusterpedia request.\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments\" # Specify namespace kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/namespaces/kube-system/deployments\"   In addition to specifying a single namespace, we can also specify to search the resources under a group of namespaces. kubectl URL Use Search Label search.clusterpedia.io/namespaces to specify a group of namespaces.\n Be sure to specify the -A flag to avoid kubectl setting default namespace in the path.\n kubectl --cluster clusterpedia get deployments -A -l \"search.clusterpedia.io/namespaces in (kube-system, default)\" # Output： NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kube-system cluster-1 coredns 2/2 2 2 68d kube-system cluster-2 calico-kube-controllers 1/1 1 1 64d kube-system cluster-2 coredns 2/2 2 2 64d default cluster-2 dd-airflow-scheduler 0/1 1 0 54d default cluster-2 dd-airflow-web 0/1 1 0 54d  When using URL, we don’t need to use Label Selector to pass parameters, just use URL Query - namespaces\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?namespaces=kube-system,default\"  Specify Resource Names Users can filter resources by a group of resource names\nkubectl URL Use Search Label search.clusterpedia.io/names to specify a group of resource names.\n Note: To search for resources under all namespaces, specify the -A flag, or use -n to specify the namespace.\n kubectl --cluster clusterpedia get deployments -A -l \"search.clusterpedia.io/names=coredns\" # Output: NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kube-system cluster-1 coredns 2/2 2 2 68d kube-system cluster-2 coredns 2/2 2 2 64d  When using URL, use names to pass as URL Query, and if you need to specify namespaces, then add namespace to the path.\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?names=kube-coredns,dd-airflow-web\" # search resources with specified names under default namespace kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/namespaces/default/deployments?names=kube-coredns,dd-airflow-web\" When searching from multiple clusters, the data returned is actually encapsulated in a structure similar to DeploymentList.\nIf we want to get a single Deployment then we need to specify the cluster name in the URL path, refer to Get Single Resource\n Creation Time Interval The creation time interval used for the search is left closed and right open, since \u003c= creation time \u003c before.\nFor more details on the time interval parameters, see Search by Creation Time Interval\nkubectl URL Use Search Label - search.clusterpedia.io/since and search.clusterpedia.io/before to specify the time interval respectively.\nkubectl --cluster clusterpedia get deployments -A -l \"search.clusterpedia.io/since=2022-03-24, \\ search.clusterpedia.io/before=2022-04-10\"  When using URLs, you can use Query - since and before to specify the time interval respectively.\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?since=2022-03-24\u0026before=2022-04-10\"  Fuzzy Search Currently supports fuzzy search based on resource names.\nSince fuzzy search needs to be discussed further, it is temporarily provided as an experimental feature.\nOnly the Search Label method is supported, URL Query isn’t supported.\nkubectl --cluster clusterpedia get deployments -A -l \"internalstorage.clusterpedia.io/fuzzy-name=test\" Filters out deployments whose names contain the test string.\nYou can use the in operator to pass multiple fuzzy arguments, so that you can filter out resources that have all strings in their names.\nField Selector Native Kubernetes currently only supports field filtering on metadata.name and metadata.namespace, and the operators only support =, !=, ==`, which is very limited.\nClusterpedia provides more powerful features based on the compatibility with existing Field Selector features, and supports the same operators as Label Selector.\nField Selector’s key currently supports three formats.\n Use . to sperate fields  kubectl --cluster clusterpedia get pods --field-selector=\"status.phase=Running\" # we can also add the first character `.` kubectl --cluster clusterpedia get pods --field-selector=\".status.phase notin (Running,Succeeded)\"  Field names wrapped in '' or \"\" can be used for fields with illegal characters like .  kubectl --cluster clusterpedia get deploy \\  --field-selector=\"metadata.annotations['test.io'] in (value1,value2),spec.replica=3\"  Use [] to separate fields, the string inside [] must be wrapped with '' or \"\"  kubectl --cluster clusterpedia get pods --field-selector=\"status['phase']!=Running\" Support List Fields The actual design of field filtering takes into account the filtering of fields within list elements, but more discussion is needed as to whether the usage scenario actually makes sense: issue: support list field filtering\nExamples：\nkubectl get po --field-selector=\"spec.containers[].name!=container1\" kubectl get po --field-selector=\"spec.containers[].name == container1\" kubectl get po --field-selector=\"spec.containers[1].name in (container1,container2)\" Search by Parent or Ancestor Owner Searching by Owner is a very useful search function, and Clusterpedia also supports the seniority advancement of Owner to search for grandparents and even higher seniority.\nBy searching by Owner, we can query all Pods under Deployment at once, without having to query ReplicaSet in between.\nWhen using the Owner query, we must specify a single cluster, either as a Serach Label or URL Query, or you can specify the cluster name in the URL Path.\nFor details on how to search by Owner, you can refer to Search by Parent or Ancestor Owenr within a specified cluster\nPaging and Sorting Paging and sorting are essential features for resource retrieval.\nSorting by multiple fields Multiple fields can be specified for sorting, and the support for sorting fields is determined by the Storage Layer.\nThe current Default Storage Layer supports sorting cluster，namespace，name，created_at，resource_version in both asc and desc, and the fields are also supported in any combination kubectl URL Sorting using multiple fields\nkubectl --cluster clusterpedia get pods -l \\  \"search.clusterpedia.io/orderby in (cluster, name)\" Because of Label Selector’s validation of value, order by desc requires _desc at the end of the field.\nkubectl --cluster clusterpedia get pods -l \\  \"search.clusterpedia.io/orderby in (namespace_desc, cluster, name)\"  Use URL Query to specify sorting fields\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?orderby=namespace,cluster\" When specifying a field in order by desc, add desc to the end of the field, separated by spaces\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?orderby=namespace desc,cluster\"  Paging Native Kubernetes actually supports paging, and fields for paging queries already exist in ListOptions.\nClusterpedia reuses the ListOptions.Limit and ListOptions.Continue fields as the size and offset for paging.\nkubectl URL kubectl --chunk-size is actually used for paging pulls by setting ListOptions.Limit.\nThe native Kubernetes APIServer carries the continue for the next list in the returned response, and performs the next list based on --chunk-size and conintue until the conintue is empty in the response data.\nClusterpedia does not return the continue field in the response by default in order to ensure paged search in kubectl, which prevents kubectl from pulling all data using chunks.\nkubectl --cluster cluster-1 get pods --chunk-size 10 Note that kubectl sets the limit to the default value of 500 without setting --chunk-size, which means that search.clusterpedia.io/size does not actually take effect and is only used to correspond to search.clusterpedia.io/offset.\n URL Query has a higher priority than Search Label\n There is no flag to set for continue in kubectl. So you have to use Search Label to pass it.\nkubectl --cluster clusterpedia get pods --chunk-size 10 -l \\  \"search.clusterpedia.io/offset=10\"  To paginate resources, just set the limit and continue in the URL.\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?limit=10\u0026continue=5\"  Response With Continue ListMeta.Continue can be used in ListOptions.Continue as the offset for the next request.\nAs mentioned in the paging feature, Clusterepdia does not have continue in the response to prevent kubectl from pulling the full amount of data in pieces.\nHowever, if the user requires it, he can request that the response include continue. URL kubectl When accessing Clusterepdia using a URL, the response' continue can be used as the offset for the next request.\n Use with paging\n kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?withContinue=true\u0026limit=1\" | jq { \"kind\": \"DeploymentList\", \"apiVersion\": \"apps/v1\", \"metadata\": { \"continue\": \"1\" }, \"items\": [ ... ] }  Setting search.clusterpedia.io/with-continue in kubectl will result in pulling the full amount of resources as a paged pull.\nkubectl --cluster clusterpedia get deploy -l \\  \"search.clusterpedia.io/with-continue=true\"  Response With Remaining Count In some UI cases, it is often necessary to get the total number of resources in the current search condition.\nThe RemainingItemCount field exists in the ListMeta of the Kubernetes List response.\nBy reusing this field, the total number of resources can be returned in a Kubernetes OpenAPI-compatible manner:\noffset + len(list.items) + list.metadata.remainingItemCount\n When offset is too large, remainingItemCount may be negative, ensuring that the total number of resources can always be calculated.\n URL kubectl Set withRemainingCount in the URL Query to request that the response include the number of remaining resources.\n Use with paging\n kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?withRemainingCount\u0026limit=1\" | jq { \"kind\": \"DeploymentList\", \"apiVersion\": \"apps/v1\", \"metadata\": { \"remainingItemCount\": 23 }, \"items\": [ ... ] }  Need to use this feature as a URL\n ","categories":"","description":"","excerpt":"Multi-cluster resource search allows us to filter resources in …","ref":"/docs/usage/search/multi-cluster/","tags":"","title":"Multiple Clusters"},{"body":"安装 Clusterpedia 的安装分为两个部分：\n 安装存储组件 安装 Clusterpedia   用户如果使用已有的存储组件（MySQL 或者 PostgreSQL），则直接跳过安装存储组件。\n 拉取项目：\ngit clone https://github.com/clusterpedia-io/clusterpedia.git cd clusterpedia git checkout v0.7.0 安装存储组件 Clusterpedia 安装时提供了 MySQL 8.0 和 PostgreSQL 12 两种存储组件以供选择。\n 用户如果使用已有的存储组件（MySQL 或者 PostgreSQL），则直接跳过存储组件安装。\n PostgreSQL MySQL 进入所选存储组件的安装目录\ncd ./deploy/internalstorage/postgres  进入所选存储组件的安装目录\ncd ./deploy/internalstorage/mysql  存储组件使用 Local PV 的方式存储数据，部署时需要指定 Local PV 所在节点\n 用户可以选择自己提供 PV\n export STORAGE_NODE_NAME=\u003c节点名称\u003e sed \"s|__NODE_NAME__|$STORAGE_NODE_NAME|g\" `grep __NODE_NAME__ -rl ./templates` \u003e clusterpedia_internalstorage_pv.yaml 部署存储组件\nkubectl apply -f . # 跳回 Clusterpedia 项目根目录 cd ../../../ 安装 Clusterpedia 存储组件部署完成后，便可安装 Clusterpedia。\n如果选择使用已存在的存储组件，则需要参考 配置存储层 来将存储组件对接到默认存储层中。\n 在 clusterpedia 项目根目录下进行操作。\n # 部署 Clusterpedia CRD 与组件 kubectl apply -f ./deploy 安装完成 检查组件 Pods 运行是否正常。\nkubectl -n clusterpedia-system get pods 部署集群自动接入策略 —— ClusterImportPolicy 0.4.0 后，Clusterpedia 提供了更加友好的接入多云平台的方式。\n用户通过创建 ClusterImportPolicy 来自动发现多云平台中纳管的集群，并将这些集群自动同步为 PediaCluster，用户不需要根据纳管的集群来手动去维护 PediaCluster 了。\n我们在 Clusterpedia 仓库 中维护了各个多云平台的 ClusterImportPolicy。 大家也提交用于对接其他多云平台的 ClusterImportPolicy。\n用户在安装 Clusterpedia 后，创建合适的 ClusterImportPolicy 即可，用户也可以根据自己的需求来创建新的 ClusterImportPolicy\n具体可以参考 接入多云平台\nkubectl get clusterimportpolicy 卸载 删除 ClusterImportPolicy 如果用户部署了 ClusterImportPolicy 那么需要先清理 ClusterImportPolicy 资源\nkubectl get clusterimportpolicy 清理 PediaCluster 在卸载 Clusterpedia 前，需要查看环境中是否还存在 PediaCluster 资源，如果存在那么需要删除这些资源。\nkubectl get pediacluster 卸载 Clusterpedia PediaCluster 资源清理完成后，卸载 Clusterpedia 相关组件。\n# delete compontents kubectl delete -f ./deploy/clusterpedia_apiserver_apiservice.yaml kubectl delete -f ./deploy/clusterpedia_apiserver_deployment.yaml kubectl delete -f ./deploy/clusterpedia_clustersynchro_manager_deployment.yaml kubectl delete -f ./deploy/clusterpedia_controller_manager_deployment.yaml kubectl delete -f ./deploy/clusterpedia_apiserver_rbac.yaml # delete crds kubectl delete -f ./deploy/cluster.clusterpedia.io_clustersyncresources.yaml kubectl delete -f ./deploy/cluster.clusterpedia.io_pediaclusers.yaml kubectl delete -f ./deploy/policy.clusterpedia.io_clusterimportpolicies.yaml kubectl delete -f ./deploy/policy.clusterpedia.io_pediaclusterlifecycles.yaml 卸载存储组件 根据选择的存储组件类型，来移除相关的资源。\nkubectl delete -f ./deploy/internalstorage/\u003cstorage type\u003e 清理 Local PV 以及数据 存储组件卸载后，PV 和相应的数据会依然遗留在节点中，我们需要手动清理。\n通过 Local PV 资源详情，来查看挂载的节点。\nkubectl get pv clusterpedia-internalstorage-\u003cstorage type\u003e 得知数据保存的节点后，删除 Local PV。\nkubectl delete pv clusterpedia-internalstorage-\u003cstorage type\u003e 登录数据所在节点，清理数据。\n# 遗留数据所在节点 rm -rf /var/local/clusterpedia/internalstorage/\u003cstorage type\u003e ","categories":"","description":"","excerpt":"安装 Clusterpedia 的安装分为两个部分：\n 安装存储组件 安装 Clusterpedia   用户如果使用已有的存储组 …","ref":"/zh-cn/docs/installation/kubectl-apply/","tags":"","title":"使用 kubectl apply"},{"body":"Clusterpedia 以极小的代价提供了多集群资源的 kube-state-metrics 功能，它提供的指标信息与 kube-state-metrics 一致，当然会额外增加了一个集群名称的 label.\nkube_deployment_created{cluster=\"test-14\",namespace=\"clusterpedia-system\",deployment=\"clusterpedia-apiserver\"} 1.676557618e+09 由于该功能处于试验阶段，所以使用该功能需要先额外通过标准方式安装 Clusterpedia.\nClusterpedia 安装完成后，我们需要更新 helm 来开启 多集群 kube-state-metrics 功能。\n 当前 main 分支中已经合并 kube-state-metrics 功能，未来会包含在 v0.8.0 中。 ghcr.io/iceber/clusterpedia/clustersynchro-manager:v0.8.0-ksm.0 镜像中包含该功能呢\n 开启多集群 kube-state-metrics 确保 Clusterpedia Chart 版本 \u003e= v1.8.0 $ helm repo update clusterpedia $ helm search clusterpedia NAME CHART VERSION APP VERSION DESCRIPTION clusterpedia/clusterpedia 1.8.0 v0.7.0 A Helm chart for Kubernetes 获取当前 chart values $ helm -n clusterpedia-system get values clusterpedia \u003e values.yaml 创建 patch values echo \"clustersynchroManager:image:repository:iceber/clusterpedia/clustersynchro-managertag:v0.8.0-ksm.0kubeStateMetrics:enable:true\" \u003e patch.yaml更新 Clusterpedia 开启多集群 kube-state-metrics $ helm -n clusterpedia-system upgrade -f values.yaml -f patch.yaml clusterpedia clusterpedia/clusterpedia 查看 clusterpedia kube-state-metrics services\n$ kubectl -n clusterpedia-system get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE clusterpedia-apiserver ClusterIP 10.97.129.238 \u003cnone\u003e 443/TCP 150d clusterpedia-clustersynchro-manager-metrics ClusterIP 10.108.129.32 \u003cnone\u003e 8081/TCP 51m clusterpedia-kube-state-metrics ClusterIP 10.108.130.62 \u003cnone\u003e 8080/TCP 43m clusterpedia-mysql ClusterIP 10.102.38.225 \u003cnone\u003e 3306/TCP 150d clusterpedia-mysql-headless ClusterIP None \u003cnone\u003e 3306/TCP 150d For more information on importing clusters and using clusterpedia: Import Clusters\n未来 多集群 kube-state-metrics 是一个非常有趣的功能，它可以让你不再需要在每一个集群中安装单集群版本的 kube-state-metrics，并且它可以很好的处理资源版本不同的问题。\n这里有很多关于该功能的讨论，欢迎评论\n The resource state metrics provide different metrics paths depending on the cluster Support remote write to send resource metrics data Support for filtering exposed resource state metrics based on namespace Support for filtering exposed resource state metrics by cluster labels/annotations  也欢迎创建新的 issue\n","categories":"","description":"","excerpt":"Clusterpedia 以极小的代价提供了多集群资源的 kube-state-metrics 功能， …","ref":"/zh-cn/docs/advanced-features/kube_state_metrics/","tags":"","title":"多集群 kube-state-metrics"},{"body":"多集群资源检索可以满足我们根据查询条件一次过滤多个集群内的资源，并提供对这些资源的分页排序的能力\n在使用 kubectl 操作时，可以查看一下当前可以检索哪些资源\nkubectl --cluster clusterpedia api-resources # 输出： NAME SHORTNAMES APIVERSION NAMESPACED KIND configmaps cm v1 true ConfigMap namespaces ns v1 false Namespace nodes no v1 false Node pods po v1 true Pod secrets v1 true Secret daemonsets ds apps/v1 true DaemonSet deployments deploy apps/v1 true Deployment replicasets rs apps/v1 true ReplicaSet issuers cert-manager.io/v1 true Issuer Clusterpedia 根据所有集群同步的资源来提供多集群的资源检索，可以查看 同步集群资源 来更新需要同步的资源\n基本功能 指定集群 多集群检索时，会默认检索所有的集群，我们也可以指定单个或者一组集群\nkubectl URL 使用 Search Label search.clusterpedia.io/clusters 来指定一组集群\nkubectl --cluster clusterpedia get deployments -l \"search.clusterpedia.io/clusters in (cluster-1,cluster-2)\" # 输出： NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kube-system cluster-1 coredns 2/2 2 2 68d kube-system cluster-2 coredns 2/2 2 2 64d 对于指定单个集群的检索，同样可以使用 Search Label 来设置，也可以查看 指定集群检索 来使用 URL Path 的方式指定集群\n# 指定单个集群 kubectl --cluster clusterpedia get deployments -l \"search.clusterpedia.io/clusters=cluster-1\" # 指定集群也可以使用 --cluster \u003ccluster name\u003e 来指定 kubectl --cluster cluster-1 get deployments  使用 URL 时，使用 clusters 作为 URL Query 来传递\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?clusters=cluster-1\" 如果指定单个集群，也可以将 cluster name 放到 URL 路径中\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-1/apis/apps/v1/deployments\" 了解更多指定集群检索\n 指定命名空间 可以像查看原生 Kube 一样来指定单个命名空间或者所有命名空间\nkubectl URL 使用 -n \u003cnamespace\u003e 来指定命名空间，默认在 default 命名空间\nkubectl --cluster clusterpedia get deployments -n kube-system # 输出： CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE cluster-1 coredns 2/2 2 2 68d cluster-2 calico-kube-controllers 1/1 1 1 64d cluster-2 coredns 2/2 2 2 64d 使用 -A 或者 --all-namespaces 来查看所有集群的所有命名空间下的资源\nkubectl --cluster clusterpedia get deployments -A # 输出： NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kube-system cluster-1 coredns 2/2 2 2 68d kube-system cluster-2 calico-kube-controllers 1/1 1 1 64d kube-system cluster-2 coredns 2/2 2 2 64d default cluster-2 dd-airflow-scheduler 0/1 1 0 54d default cluster-2 dd-airflow-web 0/1 1 0 54d  获取资源的 URL Path 和原生 Kubernetes 一样 /apis/apps/v1/deployments，\n只是需要加上 Clusterpedia Resources 的路径前缀 /apis/clusterpedia.io/v1beta1/resources 来表示当前是 Clusterpedia 请求。\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments\" # 指定命名空间 kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/namespaces/kube-system/deployments\"   除了指定单个命名空间，还可以指定查看一组命名空间下的资源 kubectl URL 使用 Search Label search.clusterpedia.io/namespaces 来指定一组命名空间\n 一定要指定 -A 参数，避免 kubectl 在路径中设置 default namespace\n kubectl --cluster clusterpedia get deployments -A -l \"search.clusterpedia.io/namespaces in (kube-system, default)\" # 输出： NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kube-system cluster-1 coredns 2/2 2 2 68d kube-system cluster-2 calico-kube-controllers 1/1 1 1 64d kube-system cluster-2 coredns 2/2 2 2 64d default cluster-2 dd-airflow-scheduler 0/1 1 0 54d default cluster-2 dd-airflow-web 0/1 1 0 54d  使用 URL 时，就不需要使用 Label Selector 来传递参数了，直接使用 URL Query namespaces 即可\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?namespaces=kube-system,default\"  指定资源名称 用户可以通过一组资源名称来过滤资源\nkubectl URL 使用 Search Label search.clusterpedia.io/names 来指定一组资源名称 注意：如果在所有命名空间下检索资源，需要指定 -A 参数，或者使用 -n 来指定命名空间\nkubectl --cluster clusterpedia get deployments -A -l \"search.clusterpedia.io/names=coredns\" # 输出： NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kube-system cluster-1 coredns 2/2 2 2 68d kube-system cluster-2 coredns 2/2 2 2 64d  使用 URL 时，使用 names 作为 URL Query 来传递，如果需要指定命名空间，那么就在路径中加上 namespace。\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?names=kube-coredns,dd-airflow-web\" # 在 default 命名空间下检索指定名字的资源 kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/namespaces/default/deployments?names=kube-coredns,dd-airflow-web\" 在多集群检索时，返回的数据实际是以类似 DeploymentList 的结构封装的数据。\n如果我们想要获取到单个的 Deployment 那么就需要在 URL 路径中指定 cluster name，参考获取单个资源\n 创建时间的区间 创建时间的区间以左闭右开的方式来进行检索，since \u003c= creation time \u003c before\n关于详细的时间区间参数可以查看 创建时间区间检索\nkubectl URL 使用 Search Label search.clusterpedia.io/since 和 search.clusterpedia.io/before 来指定时间区间\nkubectl --cluster clusterpedia get deployments -A -l \"search.clusterpedia.io/since=2022-03-24, \\ search.clusterpedia.io/before=2022-04-10\"  直接使用 URL 时，可以 Query since 和 before 来分别指定时间的区间\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?since=2022-03-24\u0026before=2022-04-10\"  模糊搜索 当前支持根据资源名称进行模糊搜索，由于模糊搜索还需要继续讨论，所以暂时以试验性功能来提供\n只支持 Search Label 的方式，不支持 URL Query\nkubectl --cluster clusterpedia get deployments -A -l \"internalstorage.clusterpedia.io/fuzzy-name=test\" 过滤出名字中包含 test 字符串的 deployments。\n可以使用 in 操作符来传递多个参数，这样可以过滤出名字中包含所有字符串的资源\n字段过滤 原生 Kubernetes 当前只支持对 metadata.name 和 metadata.namespace 的字段过滤，而且操作符只支持 =，!=，==，能力非常有限。\nClusterpedia 在兼容已有的 Field Selector 功能的基础上，提供了更加强大的功能，支持和 Label Selector 相同的操作符。\nField Selector 的 key 当前支持三种格式：\n 使用 . 分隔字段  kubectl --cluster clusterpedia get pods --field-selector=\"status.phase=Running\" # 也可以在首字符添加 `.` kubectl --cluster clusterpedia get pods --field-selector=\".status.phase notin (Running,Succeeded)\"  字段名称使用 '' 或者 \"\" 来包裹，可以用于带 . 之类的非法字符的字段  kubectl --cluster clusterpedia get deploy \\  --field-selector=\"metadata.annotations['test.io'] in (value1,value2),spec.replica=3\"  使用 [] 来分隔字段，[] 内字符串必须使用 '' 或者 \"\" 来包裹  kubectl --cluster clusterpedia get pods --field-selector=\"status['phase']!=Running\" 列表字段支持 实际在字段过滤的设计时考虑到了对列表元素内字段过滤，不过由于使用场景是否真正有意义还需要更多的讨论 issue: support list field filtering\n示例：\nkubectl get po --field-selector=\"spec.containers[].name!=container1\" kubectl get po --field-selector=\"spec.containers[].name == container1\" kubectl get po --field-selector=\"spec.containers[1].name in (container1,container2)\" 根据父辈以及祖辈 Owner 查询 通过 Owner 检索是一个非常有用的检索功能， 并且 Clusterpedia 在 Owner 的基础上还支持对 Owner 进行辈分提升来进行祖辈甚至更高辈分的检索。\n通过 Owner 检索，可以一次查询到 Deployment 下的所有 Pods，无需中间再查询 ReplicaSet。\nOwner 查询必须指定单个集群，可以使用 Serach Label 或者 URL Query 来指定，也可以在 URL Path 中指定集群名称\n关于根据 Owner 检索的具体使用方法，可以参考指定集群内根据父辈或者祖辈 Owenr 进行检索\n分页与排序 分页和排序是资源检索必不可少的功能\n根据多个字段进行排序 可以指定多个字段进行排序，而对排序字段的支持是由存储层来决定。\n当前默认存储层支持对 cluster，namespace，name，created_at，resource_version 进行正序和倒序的排序，字段也支持随意的组合 kubectl URL 使用多个字段进行正序排序\nkubectl --cluster clusterpedia get pods -l \\  \"search.clusterpedia.io/orderby in (cluster, name)\" 由于 Label Selector 对 value 的限制，倒序时需要在字段结尾加上 _desc\nkubectl --cluster clusterpedia get pods -l \\  \"search.clusterpedia.io/orderby in (namespace_desc, cluster, name)\"  使用 URL Query 来指定排序字段\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?orderby=namespace,cluster\" 指定倒序字段时，在字段后添加 desc，以空格分隔\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?orderby=namespace desc,cluster\"  分页 原生 Kubernetes 实际是支持分页的，ListOptions 中便已经存在用于分页查询的字段。\nClusterpedia 复用 ListOptions.Limit 和 ListOptions.Continue 字段作为分页的 size 和 offset。\nkubectl URL kubectl 的 --chunk-size 实际通过设置 limit 来用于分片拉取。\n原生的 Kubernetes APIServer 会在返回的响应中携带用于下一次拉取的 continue， 并根据 --chunk-size 和 conintue 进行下一次拉取，直到相应的数据中 Conintue 为空。\nClusterpedia 为了保证在 kubectl 中实现分页检索，默认并不会在响应中返回 continue 字段，这样避免了 kubectl 使用分片拉取全部数据\nkubectl --cluster cluster-1 get pods --chunk-size 10 需要注意 kubectl 在不设置 --chunk-size 的情况下，limit 会被设置成默认值 500， 也就是说 search.clusterpedia.io/size 实际是无法生效的，只是用于和 search.clusterpedia.io/offset 形成对应关系\n URL Query 的优先级大于 Search Label\n 在 kubectl 中 continue 是没有 flag 可以设置的。所以还是要使用 Search Label 来传递。\nkubectl --cluster clusterpedia get pods --chunk-size 10 -l \\  \"search.clusterpedia.io/offset=10\"  对资源进行分页检索，只需要在 URL 中设置 limit 和 continue 即可\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?limit=10\u0026continue=5\"  响应携带 Continue 信息 响应数据的 ListMeta.Continue 可以用于 ListOptions.Continue 中作为下一次拉取的 offset\n分页功能中我们提到，为了避免 kubectl 进行对全量数据的分片拉取，Clusterepdia 不会在响应中携带 Continue 信息。\n不过如果用户有需求那么可以要求响应中携带 Continue 信息 URL kubectl 在使用 URL 访问 Clusterepdia 时，响应的 Continue 可以作为下一次请求的 offset\n 搭配分页功能使用\n kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?withContinue=true\u0026limit=1\" | jq { \"kind\": \"DeploymentList\", \"apiVersion\": \"apps/v1\", \"metadata\": { \"continue\": \"1\" }, \"items\": [ ... ] }  在 kubectl 设置 search.clusterpedia.io/with-continue 会导致以分片拉取的形式拉取全量资源。\nkubectl --cluster clusterpedia get deploy -l \\  \"search.clusterpedia.io/with-continue=true\"  响应携带剩余资源数量信息 在一些 UI 场景下，往往会需要获取到当前检索条件下的资源总量。\nKubernetes List 响应的 ListMeta 中存在 RemainingItemCount 字段，\n通过复用该字段，便可在兼容 Kubernetes OpenAPI 的基础下计算出资源总量：\noffset + len(list.items) + list.metadata.remainingItemCount\n 在 offset 过大时，remainingItemCount 可能为负数，保证总是可以计算出资源总量\n URL kubectl 在 URL Query 设置 withRemainingCount 即可要求响应携带剩余资源数量\n 搭配分页功能使用\n kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?withRemainingCount\u0026limit=1\" | jq { \"kind\": \"DeploymentList\", \"apiVersion\": \"apps/v1\", \"metadata\": { \"remainingItemCount\": 23 }, \"items\": [ ... ] }  需要以 URL 的方式使用该功能\n ","categories":"","description":"","excerpt":"多集群资源检索可以满足我们根据查询条件一次过滤多个集群内的资源，并提供对这些资源的分页排序的能力\n在使用 kubectl 操作时，可以查看一 …","ref":"/zh-cn/docs/usage/search/multi-cluster/","tags":"","title":"多集群检索"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh-cn/docs/installation/","tags":"","title":"安装"},{"body":"0.4.0 后，Clusterpedia 提供了更加友好的接入多云平台的方式。\n用户通过创建 ClusterImportPolicy 来自动发现多云平台中纳管的集群，并将这些集群自动同步为 PediaCluster，用户不需要根据纳管的集群来手动去维护 PediaCluster 了。\n我们在 Clusterpedia 仓库 中维护了各个多云平台的 ClusterImportPolicy。 大家也提交用于对接其他多云平台的 ClusterImportPolicy。\n用户在安装 Clusterpedia 后，创建合适的 ClusterImportPolicy 即可，用户也可以根据自己的需求来创建新的 ClusterImportPolicy\nCluster API ClusterImportPolicy 用户可以参考 Cluster API Quick Start 来安装 Cluster API，或者参考 快速部署 Cluster API + Clusterpedia 来搭建示例环境。\n创建用于对接 Cluster API 平台的 ClusterImportPolicy。\n$ kubectl apply -f https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/main/deploy/clusterimportpolicy/cluster_api.yaml $ kubectl get clusterimportpolicy NAME AGE cluster-api 4d19h 如果集群中已经存在由 Cluster API 创建的集群，那么可以查看 Cluster 与 PediaCluster 资源\n$ kubectl get cluster NAME PHASE AGE VERSION capi-quickstart Provisioned 3d23h v1.24.2 capi-quickstart-2 Provisioned 3d23h v1.24.2 $ kubectl get pediaclusterlifecycle NAME AGE default-capi-quickstart 3d23h default-capi-quickstart-2 3d23h $ kubectl get pediacluster NAME READY VERSION APISERVER default-capi-quickstart True v1.24.2 default-capi-quickstart-2 True v1.24.2 PediaCluster 会根据 Cluster 自动创建，并且当 Cluster 的 kubeconfig 发生变动时会自动更新 PediaCluster.\n新建一个 Cluster 资源时，Clusterpedia 根据 Cluster API ClusterImportPolicy 等到 ControlPlaneInitialized 为 True 时才会自动创建 PediaCluster，可以通过 kubectl get kubeadmcontrolplane 来查看集群的初始化状态\nNAME CLUSTER INITIALIZED API SERVER AVAILABLE REPLICAS READY UPDATED UNAVAILABLE AGE VERSION capi-quickstart-2xcsz capi-quickstart true 1 1 1 86s v1.24.2 Cluster 初始化完成后，就可以直接使用 kubectl 来检索多集群资源了\n 使用 kubectl 前，需要为多集群资源检索生成集群快捷配置 —— 为 kubectl 生成集群访问的快捷配置\n $ # Since CNI is not installed, the nodes are not ready. $ kubectl --cluster clusterpedia get no CLUSTER NAME STATUS ROLES AGE VERSION default-capi-quickstart-2 capi-quickstart-2-ctm9k-g2m87 NotReady control-plane 12m v1.24.2 default-capi-quickstart-2 capi-quickstart-2-md-0-s8hbx-7bd44554b5-kzcb6 NotReady \u003cnone\u003e 11m v1.24.2 default-capi-quickstart capi-quickstart-2xcsz-fxrrk NotReady control-plane 21m v1.24.2 default-capi-quickstart capi-quickstart-md-0-9tw2g-b8b4f46cf-gggvq NotReady \u003cnone\u003e 20m v1.24.2 Karmada ClusterImportPolicy  对于 Karmada 平台，用户首先需要先将 Clusterpedia 部署在 Karmada APIServer 中，部署步骤可以参考 https://github.com/Iceber/deploy-clusterpedia-to-karmada\n 创建用于对接 Karmada 平台的 ClusterImportPolicy。\n$ kubectl create -f https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/main/deploy/clusterimportpolicy/karmada.yaml $ kubectl get clusterimportpolicy NAME AGE karmada 7d5h 查看 Karmada Cluster 与 PediaClusterLifecycle\n$ kubectl get cluster NAME VERSION MODE READY AGE argocd Push False 8d member1 v1.23.4 Push True 22d member3 v1.23.4 Pull True 22d $ kubectl get pediaclusterlifecycle NAME AGE karmada-argocd 7d5h karmada-member1 7d5h karmada-member3 7d5h Clusterpedia 会为每一个 Karmada Cluster 创建对应的 PediaClusterLifecycle，可以使用 kubectl describe pediaclusterlifecycle \u003cname\u003e 来查看 Karmada Cluster 与 PediaCluster 的转换状态\n 未来会在 kubectl get pediaclusterlifecycle 中详细状态\n 查看成功创建的 PediaCluster\nNAME APISERVER VERSION STATUS karmada-member1 https://172.18.0.4:6443 v1.23.4 Healthy karmada clusterimportpolicy 要求 karmada 集群为 Push 模式，并且处于 Ready 状态，所以为 member-1 集群创建了 karmada-member-1 pediacluster 资源。\nVCluster ClusterImportPolicy 创建用于自动发现 VCluster 的 ClusterImportPolicy。\n$ kubectl create -f https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/main/deploy/clusterimportpolicy/vcluster.yaml $ kubectl get clusterimportpolicy NAME AGE vclsuter 5h 需要注意，VCluster 集群在创建时需要保证生成的 kubeconfig 的 Server 地址可以由宿主集群内的其他 Pod 访问。\n可以设置为 VCluster Service 域名，也可以是 Node IP 或者 Ingress 地址\nsyncer:extraArgs:- --out-kube-config-server=https://\u003cvcluster name\u003e.\u003cnamespace\u003e.svc- --tls-san=\u003cvcluster name\u003e.\u003cnamespace\u003e.svc,127.0.0.1在 default 命名空间创建两个 VCluster， 创建虚拟集群 vcluster-1\n# vcluster-1.yamlsyncer:extraArgs:- --out-kube-config-server=https://vcluster-1.default.svc- --tls-san=vcluster-1.default.svc,127.0.0.1$ vcluster create -n default -f vcluster-1.yaml vcluster-1 创建虚拟集群 vcluster-2\n# vcluster-2.yamlsyncer:extraArgs:- --out-kube-config-server=https://vcluster-2.default.svc- --tls-san=vcluster-2.default.svc,127.0.0.1$ vcluster create -n default -f vcluster-2.yaml vcluster-2 查看所有的 VCluster 集群\n$ vcluster list NAME NAMESPACE STATUS CONNECTED CREATED AGE caiwei-vcluster caiwei-vcluster Running 2022-08-26 16:10:52 +0800 CST 484h49m6s vcluster-1 default Running 2022-09-15 20:57:59 +0800 CST 1m59s vcluster-2 default Running 2022-09-15 20:59:34 +0800 CST 24s 我们可以直接使用 kubectl + Clusterpedia 来检索任意 VCluster 内的资源\n 使用 kubectl 前，需要为多集群资源检索生成集群快捷配置 —— 为 kubectl 生成集群访问的快捷配置\n $ kubectl --cluster clusterpedia get po -A NAMESPACE CLUSTER NAME READY STATUS RESTARTS AGE default vc-caiwei-vcluster-caiwei-vcluster backend-77f8f45fc8-5ssww 1/1 Running 0 20d default vc-caiwei-vcluster-caiwei-vcluster backend-77f8f45fc8-j5m4c 1/1 Running 0 20d default vc-caiwei-vcluster-caiwei-vcluster backend-77f8f45fc8-vjzf6 1/1 Running 0 20d kube-system vc-default-vcluster-1 coredns-669fb9997d-cxktv 1/1 Running 0 3m40s kube-system vc-default-vcluster-2 coredns-669fb9997d-g7w8l 1/1 Running 0 2m6s kube-system vc-caiwei-vcluster-caiwei-vcluster coredns-669fb9997d-x6vc2 1/1 Running 0 20d $ kubectl --cluster clusterpedia get ns CLUSTER NAME STATUS AGE vc-default-vcluster-2 default Active 2m49s vc-default-vcluster-1 default Active 4m24s vc-caiwei-vcluster-caiwei-vcluster default Active 20d vc-default-vcluster-2 kube-node-lease Active 2m49s vc-default-vcluster-1 kube-node-lease Active 4m24s vc-caiwei-vcluster-caiwei-vcluster kube-node-lease Active 20d vc-default-vcluster-2 kube-public Active 2m49s vc-default-vcluster-1 kube-public Active 4m24s vc-caiwei-vcluster-caiwei-vcluster kube-public Active 20d vc-default-vcluster-2 kube-system Active 2m49s vc-default-vcluster-1 kube-system Active 4m24s vc-caiwei-vcluster-caiwei-vcluster kube-system Active 20d Clusterpedia 会自动发现宿主集群内的虚拟集群（VCluster），并根据 VCluster ClusterImportPolicy 创建相应的 PediaCluster，用户可以直接访问 Clusterpedia 来检索资源\n$ kubectl get pediaclusterlifecycle NAME AGE vc-caiwei-vcluster-caiwei-vcluster 20d vc-default-vcluster-1 5m57s vc-default-vcluster-2 4m24s $ kubectl get pediacluster NAME READY VERSION APISERVER vc-caiwei-vcluster-caiwei-vcluster True v1.23.5+k3s1 https://caiwei-vcluster.caiwei-vcluster.svc vc-default-vcluster-1 True v1.23.5+k3s1 https://vcluster-1.default.svc vc-default-vcluster-2 True v1.23.5+k3s1 https://vcluster-2.default.svc 新建 ClusterImportPolicy 如果 Clusterpedia 仓库 中没有维护某个平台的 ClusterImportPolicy，那么我们可以新建 ClusterImportPolicy\n关于 ClusterImportPolicy 原理和字段的详细描述可以参考 集群自动接入策略\n现在假定有一个多云平台 MCP，该平台使用自定义资源 —— Cluster 来代表被纳管的集群，并且将集群的认证信息保存在和集群同名的 Secret 中\napiVersion:cluster.mcp.iokind:Clustermetadata:name:cluster-1spec:apiEndpoint:\"https://172.10.10.10:6443\"authSecretRef:namespace:\"default\"name:\"cluster-1\"status:conditions:- type:Readystatus:True---apiVersion:v1kind:Secretmetadata:name:cluster-1data:ca:**clusterca bundle**token:**clustertoken**我们为 MCP 平台定义一个 ClusterImportPolicy 资源，并且默认同步 pods 和 apps group 下的资源\napiVersion:policy.clusterpedia.io/v1alpha1kind:ClusterImportPolicymetadata:name:mcpspec:source:group:\"cluster.mcp.io\"resource:clustersversions:[]references:- group:\"\"resource:secretsversions:[]namespaceTemplate:\"{{ .source.spec.authSecretRef.namespace }}\"nameTemplate:\"{{ .source.spec.authSecretRef.name }}\"key:authSecretnameTemplate:\"mcp-{{ .source.metadata.name }}\"template:|spec: apiserver: \"{{ .source.spec.apiEndpoint }}\" caData: \"{{ .references.authSecret.data.ca }}\" tokenData: \"{{ .references.authSecret.data.token }}\" syncResources: - group: \"\" resources: - \"pods\" - group: \"apps\" resources: - \"*\" syncResourcesRefName: \"\"creationCondition:|{{ if ne .source.spec.apiEndpoint \"\" }} {{ range .source.status.conditions }} {{ if eq .type \"Ready\" }} {{ if eq .status \"True\" }} true {{ end }} {{ end }} {{ end }} {{ end }} spec.source 定义了需要监听的资源 Cluster spec.references 定义了将 MCP Cluster 转换为 PediaCluster 时涉及到的资源，当前只有 secrets 资源 spec.nameTemplate 会根据 MCP Cluster 资源渲染出 PediaCluster 资源的名字 spec.template 通过 MCP Cluster 和 spec.references 中定义的资源来渲染出 PediaCluster 资源，具体规则可以参考 PediaCluster Template spec.creationCondition 可以根据 MCP Cluster 和 spec.references 定义的资源来可以决定了什么时候可以创建 PediaCluster，这里定义了当 MCP Cluster 处于 Ready 后再创建 PediaCluster，具体使用可以参考 Creation Condition  ","categories":"","description":"","excerpt":"0.4.0 后，Clusterpedia 提供了更加友好的接入多云平台的方式。\n用户通过创建 ClusterImportPolicy 来自动 …","ref":"/zh-cn/docs/usage/interfacing-to-multi-cloud-platforms/","tags":"","title":"接入多云平台"},{"body":"Clusterpedia 为了能够一次性获取多个类型的资源，在单个资源类型的基础上提供了一种新的资源 —— 聚合资源（Collection Resource）。\n聚合资源是由不同的资源类型组合而成，可以对这些资源类型进行统一的检索和分页。\n具体支持哪些聚合资源是由存储层来决定的，例如 默认存储层 支持 any，workloads 和 kuberesources 两种聚合资源。\nkubectl get collectionresources # 输出: NAME RESOURCES any * workloads deployments.apps,daemonsets.apps,statefulsets.apps kuberesources .*,*.admission.k8s.io,*.admissionregistration.k8s.io,*.apiextensions.k8s.io,*.apps,*.authentication.k8s.io,*.authorization.k8s.io,*.autoscaling,*.batch,*.certificates.k8s.io,*.coordination.k8s.io,*.discovery.k8s.io,*.events.k8s.io,*.extensions,*.flowcontrol.apiserver.k8s.io,*.imagepolicy.k8s.io,*.internal.apiserver.k8s.io,*.networking.k8s.io,*.node.k8s.io,*.policy,*.rbac.authorization.k8s.io,*.scheduling.k8s.io,*.storage.k8s.io any 表示任意的资源，用户在使用时需要传递想要组合的 groups 或者 resources，具体使用可以参考 使用 Any CollectionResource\nkuberesources 包含了所有 kube 的内置资源，我们可以通过 kuberesources 来对所有的内置资源进行统一的过滤和检索。\n以 yaml 形式查看支持的聚合资源\nkubectl get collectionresources -o yaml # 输出：apiVersion:v1items:- apiVersion:clusterpedia.io/v1beta1kind:CollectionResourcemetadata:creationTimestamp:nullname:anyresourceTypes:[]- apiVersion:clusterpedia.io/v1beta1kind:CollectionResourcemetadata:creationTimestamp:nullname:workloadsresourceTypes:- group:appsresource:deploymentsversion:v1- group:appsresource:daemonsetsversion:v1- group:appsresource:statefulsetsversion:v1- apiVersion:clusterpedia.io/v1beta1kind:CollectionResourcemetadata:creationTimestamp:nullname:kuberesourcesresourceTypes:- group:\"\"- group:admission.k8s.io- group:admissionregistration.k8s.io- group:apiextensions.k8s.io- group:apps- group:authentication.k8s.io- group:authorization.k8s.io- group:autoscaling- group:batch- group:certificates.k8s.io- group:coordination.k8s.io- group:discovery.k8s.io- group:events.k8s.io- group:extensions- group:flowcontrol.apiserver.k8s.io- group:imagepolicy.k8s.io- group:internal.apiserver.k8s.io- group:networking.k8s.io- group:node.k8s.io- group:policy- group:rbac.authorization.k8s.io- group:scheduling.k8s.io- group:storage.k8s.iokind:Listmetadata:resourceVersion:\"\"selfLink:\"\"可以看到 workloads 包含了 deployments，daemonsets， statefulsets 三种资源。\n而 kuberesources 则包含了 kube 内置的所有资源。\n更多关于聚合资源的操作可以查看 聚合资源检索\n自定义聚合资源 Clusterpedia 计划提供两种方式来让用户随意组合想要查询的资源类型\n Any CollectionResource —— 使用聚合资源 any CustomCollectionResource —— 自定义聚合资源  0.4 中，Clusterpedia 提供了 any collectionresource 来让用户通过传递 groups 和 resources 参数来组合不同类型的资源。\n不过需要注意 any collectionresource 不能使用 kubectl 来获取，具体使用可以参考 使用 Any CollectionResource\n$ kubectl get collectionresources any Error from server (BadRequest): url query - `groups` or `resources` is required 自定义聚合资源允许用户通过 kubectl apply collectionresource \u003ccollectionresource name\u003e 来创建或者更新一个 Collection Resource，用户随意的配置 Collection Resource 的资源类型\napiVersion:clusterpedia.io/v1beta1kind:CollectionResourcemetadata:name:workloadsresourceTypes:- group:appsresource:deployments- group:appsresource:daemonsets- group:appsresource:statefulsets- group:batchresource:cronjobs当前还未支持自定义聚合资源\n","categories":"","description":"","excerpt":"Clusterpedia 为了能够一次性获取多个类型的资源，在单个资源类型的基础上提供了一种新的资源 —— 聚合资源（Collection …","ref":"/zh-cn/docs/concepts/collection-resource/","tags":"","title":"聚合资源(Collection Resource)"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/concepts/","tags":"","title":"Concepts"},{"body":"In addition to searching in multiple clusters, Clusterpedia can also search for resources in a specified cluster.\n Using Search Label or URL Query to specify a single cluster is not different from specifying a cluster in URL Path in terms of performance\nThis topic focuses on specifying clusters in URL Path\n Before using kubectl in the way of specifying a cluster, you need to configure the cluster shortcut for kubectl\nkubectl URL kubectl --cluster cluster-1 get deployments -n kube-system # Output: NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kube-system cluster-1 coredns 2/2 2 2 68d  Specify a cluster by using the cluster name in the URL path\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-1/apis/apps/v1/deployments\" You can also specify a single cluster by URL Query\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?clusters=cluster-1\"  The function supported by searching in a specified cluster is basically the same as that of multi-cluster search.\nIt is more convenient for searching by Owner in a specified cluster. In addition, when getting a single resource, you can only use the specified cluster in the URL Path.\nSearch by Parent or Ancestor Owner To query by Owner, you shall specify a single cluster. You can use Search Label or URL Query to specify, or specify the cluster name in the URL Path.\nSearching for resources based on ancestor owners can be done with Owner UID or Owner Name, and with Owner Seniority for Owner seniority advancement.\n For the specific query parameters, you can refer to Search by Owner\n In this way, you can directly search for the Pods corresponding to a Deployment without having to query which ReplicaSet belong to that Deployment.\nUse the Owner UID Owner Name and Owner Group Resource will be ignored after Owner UID is specified.\nFirstly use kubectl to get Deployment UID\nkubectl --cluster cluster-1 get deploy fake-deploy -o jsonpath=\"{.metadata.uid}\" #Output: 151ae265-28fe-4734-850e-b641266cd5da  Getting the uid under kubectl may be tricky, but it’s usually already easier to check metadata.uid in UI scenarios\n kubectl URL Use owner-uid to specify Owner UID and use owner-seniority to promote the Owner’s seniority.\n owner-seniority is 0 by default, which represents Owner is parent. If you set it to 1, Owenr can be promoted to grandfather\n kubectl --cluster cluster-1 get pods -l \\ \"search.clusterpedia.io/owner-uid=151ae265-28fe-4734-850e-b641266cd5da,\\ search.clusterpedia.io/owner-seniority=1\"  kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-1/api/v1/namespaces/default/pods?ownerUID=151ae265-28fe-4734-850e-b641266cd5da\u0026ownerSeniority=1\"  Use the Owner Name If the Owner UID is not known in advance, then using Owner UID is a more troublesome way.\nWe can specify the Owner by it’s name, and we can also specify Owner Group Resource to restrict the Owner’s Group Resource.\nAgain, let’s take the example of getting the corresponding Pods under Deployment. kubectl URL kubectl --cluster cluster-1 get pods -l \\  \"search.clusterpedia.io/owner-name=deploy-1,\\ search.clusterpedia.io/owner-seniority=1\" In addition, to avoid multiple types of owner resources in some cases, we can use the Owner Group Resource to restrict the type of owner.\nkubectl --cluster cluster-1 get pods -l \\  \"search.clusterpedia.io/owner-name=deploy-1,\\ search.clusterpedia.io/owner-gr=deployments.apps,\\ search.clusterpedia.io/owner-seniority=1\"  kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-1/api/v1/namespaces/default/pods?ownerName=deploy-1\u0026ownerSeniority=1\"  Get a single resource When we want to use the resource name to get (Get) a resource, we must pass the cluster name in the URL Path, just like namespace.\nkubectl URL If a resource name is passed in a multi-cluster mode, an error will be reported\nkubectl --cluster cluster-1 get deploy fake-deploy # Output: CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE cluster-1 fake-deploy 1/1 1 1 35d Certainly, you can use Search Label to specify a resource name in the case of kubectl.\nHowever, if you use -o yaml or other methods to check the returned source data, it is different from using kubectl --cluster \u003ccluster name\u003e.\n# The actual server returns the DeploymentList resource, which is replaced with a list by kubectl kubectl --cluster clusterpedia get deploy -l \"search.clusterpedia.io/clusters=cluster-1,\\ search.clusterpedia.io/names=fake-deploy\" -o yaml # Output:apiVersion:v1items:- ...kind:Listmetadata:resourceVersion:\"\"selfLink:\"\"The actual returned resource is still a KindList, while kubectl --cluster \u003cclsuter name\u003e returns a specific Kind.\nkubectl --cluster cluster-1 get deploy fake-deploy -o yaml # Output:apiVersion:apps/v1kind:Deploymentmetadata:annotations:deployment.kubernetes.io/revision:\"1\"shadow.clusterpedia.io/cluster-name:cluster-1creationTimestamp:\"2021-12-16T02:26:29Z\"generation:2name:fake-deploynamespace:defaultresourceVersion:\"38085769\"uid:151ae265-28fe-4734-850e-b641266cd5daspec:...status:... The URL to get a specified resource can be divided into three parts:\n Prefix to search for resource: /apis/clusterpedia.io/v1beta1/resources Specified cluster name: /clusters/\u003c cluster name \u003e Resource name for Kubernetes API: Path /apis/apps/v1/namespaces/\u003c namespace \u003e/deployments/\u003c resource name \u003e  kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-1/apis/apps/v1/namespaces/default/deployments/fake-deploy\"  ","categories":"","description":"","excerpt":"In addition to searching in multiple clusters, Clusterpedia can also …","ref":"/docs/usage/search/specified-cluster/","tags":"","title":"Specified a Cluster"},{"body":"Clusterpedia 除了支持多个集群的混合检索，还可以指定集群来检索资源。\n 在性能上使用 Search Label 或者 URL Query 来指定单个集群和在 URL Path 中指定集群并无区别\n本文主要讲述在 URL Path 中指定集群\n 在以指定集群的方式使用 kubectl 前，需要先配置 kubectl 的集群快捷方式\nkubectl URL kubectl --cluster cluster-1 get deployments -n kube-system # 输出： NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kube-system cluster-1 coredns 2/2 2 2 68d  将 cluster name 放到 URL 路径中来指定集群\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-1/apis/apps/v1/deployments\" 也可以通过 URL Query 来指定单个集群\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?clusters=cluster-1\"  指定集群支持的功能和多集群检索的作用基本相同，而且在 Owner 检索上更加方便， 另外在获取单个资源时也只能使用在 URL Path 中指定集群的方式。\n根据父辈或者祖辈 Owner 进行检索 Owner 查询必须指定单个集群，可以使用 Search Label 或者 URL Query 来指定，也可以在 URL Path 中指定集群名称\n通过 Owenr UID 或者 Owner Name, 并且配合用于 Owner 辈分提升的 Owenr Senirority 可以完成基于祖辈 Owner 的资源检索。\n 关于具体的查询参数，可以参考 Owner 检索\n 通过这种方式，可以直接查询到 Deployment 相应的 Pods，无需查询有哪些 ReplicaSet 属于该 Deployment。\n指定 Owner 的 UID 在指定 Owenr UID 后，Owner Name 和 Owenr Group Resource 会被忽略\n首先使用 kubectl 获取 Deployment 的 UID\nkubectl --cluster cluster-1 get deploy fake-deploy -o jsonpath=\"{.metadata.uid}\" #输出： 151ae265-28fe-4734-850e-b641266cd5da  在 kubectl 下获取 uid 可能比较麻烦，但是在 UI 场景中通常已经更容易查看 metadata.uid\n kubectl URL 使用 owner-uid 来指定 Owner 的 UID, owner-seniority 对 Owner 进行辈分提升。\n owner-seniority 默认为 0，表示 Owner 为父辈。设置为 1，提升 Owenr 辈分成为祖父 Owenr\n kubectl --cluster cluster-1 get pods -l \\ \"search.clusterpedia.io/owner-uid=151ae265-28fe-4734-850e-b641266cd5da,\\ search.clusterpedia.io/owner-seniority=1\"  kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-1/api/v1/namespaces/default/pods?ownerUID=151ae265-28fe-4734-850e-b641266cd5da\u0026ownerSeniority=1\"  指定 Owner Name 如果事先并不知道 Owner 的 UID，那么指定 Owner UID 是一种比较麻烦的方式。\n我们可以通过 Owner 的名字来指定 Owner，同时还可以指定 Owner Group Resource 来限制 Owner 的 Group Resource。\n同样，我们以获取 Deployment 下相应的 Pods 来举例 kubectl URL kubectl --cluster cluster-1 get pods -l \\  \"search.clusterpedia.io/owner-name=deploy-1,\\ search.clusterpedia.io/owner-seniority=1\" 另外为了避免某些情况下，owner 资源存在多种类型，我们可以使用 Owner Group Resource 来限制 Owner 的类型\nkubectl --cluster cluster-1 get pods -l \\  \"search.clusterpedia.io/owner-name=deploy-1,\\ search.clusterpedia.io/owner-gr=deployments.apps,\\ search.clusterpedia.io/owner-seniority=1\"  kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-1/api/v1/namespaces/default/pods?ownerName=deploy-1\u0026ownerSeniority=1\"  获取单个资源 当我们想要使用资源名称获取（Get）一个资源时，就必须要以 URL Path 的方式将集群名称传递进去，就像 namespace 一样。\nkubectl URL 如果使用多集群方式传递一个资源名称会报错\nkubectl --cluster cluster-1 get deploy fake-deploy # 输出： CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE cluster-1 fake-deploy 1/1 1 1 35d 当然在 kubectl 中也可以通过 Search Label 来指定一个资源名称。\n不过在 -o yaml 或者其他方式查看返回的源数据时，和使用 kubectl --cluster \u003ccluster name\u003e 是不一样的。\n# 实际服务端返回 DeploymentList 的资源，由 kubectl 替换成 List 资源 kubectl --cluster clusterpedia get deploy -l \"search.clusterpedia.io/clusters=cluster-1,\\ search.clusterpedia.io/names=fake-deploy\" -o yaml # 输出：apiVersion:v1items:- ...kind:Listmetadata:resourceVersion:\"\"selfLink:\"\"实际返回的资源依然是一个 KindList，而 kubectl --cluster \u003cclsuter name\u003e 返回的便是具体的 Kind。\nkubectl --cluster cluster-1 get deploy fake-deploy -o yaml # 输出：apiVersion:apps/v1kind:Deploymentmetadata:annotations:deployment.kubernetes.io/revision:\"1\"shadow.clusterpedia.io/cluster-name:cluster-1creationTimestamp:\"2021-12-16T02:26:29Z\"generation:2name:fake-deploynamespace:defaultresourceVersion:\"38085769\"uid:151ae265-28fe-4734-850e-b641266cd5daspec:...status:... 获取指定资源的 URL 可以分为三部分\n 资源检索前缀： /apis/clusterpedia.io/v1beta1/resources 指定集群名称 /clusters/\u003c cluster name \u003e 原生 Kubernetes API 的资源 Path /apis/apps/v1/namespaces/\u003c namespace \u003e/deployments/\u003c resource name \u003e  kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-1/apis/apps/v1/namespaces/default/deployments/fake-deploy\"  ","categories":"","description":"","excerpt":"Clusterpedia 除了支持多个集群的混合检索，还可以指定集群来检索资源。\n 在性能上使用 Search Label 或者 URL …","ref":"/zh-cn/docs/usage/search/specified-cluster/","tags":"","title":"指定集群检索"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh-cn/docs/concepts/","tags":"","title":"概念"},{"body":"For collection resource, refer to What is Collection Resource\nDue to the limitation of kubectl, we cannot pass search conditions through Label Selector or other methods, so it is recommended to search for Collection Resource by using a URL.\nURL kubectl  When requesting Collection Resource, you shall use paging because the number of resources may be very large.\n kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/collectionresources/workloads?limit=1\" | jq # Output { \"kind\": \"CollectionResource\", \"apiVersion\": \"clusterpedia.io/v1beta1\", \"metadata\": { \"name\": \"workloads\", \"creationTimestamp\": null }, \"resourceTypes\": [ { \"group\": \"apps\", \"version\": \"v1\", \"kind\": \"Deployment\", \"resource\": \"deployments\" }, { \"group\": \"apps\", \"version\": \"v1\", \"resource\": \"daemonsets\" }, { \"group\": \"apps\", \"version\": \"v1\", \"resource\": \"statefulsets\" } ], \"items\": [ { \"apiVersion\": \"apps/v1\", \"kind\": \"Deployment\", ... } ] } The complex search of Collection Resource is basically the same as the function of multi-cluster resource search, only some operations are not supported:\n Search by Owner is not supported. If you need to specify a specific resource type to search by Owner, you can refer to multi-cluster resource search and specified cluster search Getting a specific single resource in Collection Resource is not supported, because you shall specify cluster and type for a specific resource. In this case, you can use Get a single resource.   It is not easy to search for Collection Resource by using kubectl. However, you can have a try.\n kubectl cannot pass pages and other search conditions and may get all Collection Resources at one time. It is not recommended to use kubectl to view Collection Resource if a large number of clusters are imported or a cluster has many deployments, daemonsets and statefulsets resources.\n kubectl get collectionresources workloads # Output CLUSTER GROUP VERSION KIND NAMESPACE NAME AGE cluster-1 apps v1 DaemonSet kube-system vsphere-cloud-controller-manager 63d cluster-2 apps v1 Deployment kube-system calico-kube-controllers 109d cluster-2 apps v1 Deployment kube-system coredns-coredns 109d ... Search for Collection Resource by using URL\n Only Metadata When we retrieve a CollectionResource, the default resource is the full resource content, but sometimes we just need to retrieve the metadata of the resource.\nWe can use url query – onlyMetadata to retrieve only the resource metadata when retrieving.\n$ kubectl get --raw \"/apis/clusterpedia.io/v1beta1/collectionresources/workloads?onlyMetadata=true\u0026limit=1\" | jq { \"kind\": \"CollectionResource\", \"apiVersion\": \"clusterpedia.io/v1beta1\", \"metadata\": { \"name\": \"workloads\", \"creationTimestamp\": null }, \"resourceTypes\": [ { \"group\": \"apps\", \"version\": \"v1\", \"kind\": \"Deployment\", \"resource\": \"deployments\" } ], \"items\": [ { \"apiVersion\": \"apps/v1\", \"kind\": \"Deployment\", \"metadata\": { \"annotations\": { \"deployment.kubernetes.io/revision\": \"1\", \"shadow.clusterpedia.io/cluster-name\": \"cluster-example\" }, \"creationTimestamp\": \"2021-09-24T10:19:19Z\", \"generation\": 1, \"labels\": { \"k8s-app\": \"tigera-operator\" }, \"name\": \"tigera-operator\", \"namespace\": \"tigera-operator\", \"resourceVersion\": \"125073610\", \"uid\": \"992f9d53-37cb-4184-a004-15b278b11f79\" } } ] } Any CollectionResource  any collectionresource is one of the ways that users can freely combine resource types with custom collection resources to see more.\n clusterpedia supports a special CollectionResource —— any.\n$ kubectl get collectionresources NAME RESOURCES any * When retrieving any collectionresource, we must specify a set of resource types by url query, so we can only retrieve any collectionresource via clusterpedia-io/client-go or URL.\n$ kubectl get collectionresources any Error from server (BadRequest): url query - `groups` or `resources` is required any collectionresource supports two url queries —— groups and resources\ngroups and resources can be specified together, currently they are taken together and are not de-duplicated, the caller is responsible for de-duplication, there are some future optimizations for this behavior.\n$ kubectl get --raw \"/apis/clusterpedia.io/v1beta1/collectionresources/any?onlyMetadata=true\u0026groups=apps\u0026resources=batch/jobs,batch/cronjobs\" | jq groups groups can specify a group and version of a set of resources, with multiple group versions separated by ,,\nthe group version format is \u003c group \u003e/\u003c version \u003e, or no version can be specified \u003c group \u003e, for resources under /api, you can just use the empty string.\nExample: groups=apps/v1,,batch specifies three groups apps/v1, core, batch.\nresources resources can specify a specific resource type, multiple resource types are separated by ,,\nthe resource type format is \u003c group \u003e/\u003c version \u003e/\u003c resource\u003e, by also not specifying the version \u003c group \u003e/\u003c resource \u003e.\nExample: resources=apps/v1/deployments,apps/daemonsets,/pods specifies three resources deloyments, daemonsets and pods.\n","categories":"","description":"","excerpt":"For collection resource, refer to What is Collection Resource\nDue to …","ref":"/docs/usage/search/collection-resource/","tags":"","title":"Collection Resource"},{"body":"关于聚合资源的概念可以查看 什么是聚合资源 （Collection Resource）\n由于 kubectl 的限制，我们无法通过 Label Selector 或者其他方式来传递检索参数， 所以建议以 URL 的方式来检索聚合资源。\nURL kubectl  请求聚合资源时，由于资源数量可能会非常大，一定要搭配分页功能使用。\n kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/collectionresources/workloads?limit=1\" | jq # 输出 { \"kind\": \"CollectionResource\", \"apiVersion\": \"clusterpedia.io/v1beta1\", \"metadata\": { \"name\": \"workloads\", \"creationTimestamp\": null }, \"resourceTypes\": [ { \"group\": \"apps\", \"version\": \"v1\", \"kind\": \"Deployment\", \"resource\": \"deployments\" }, { \"group\": \"apps\", \"version\": \"v1\", \"resource\": \"daemonsets\" }, { \"group\": \"apps\", \"version\": \"v1\", \"resource\": \"statefulsets\" } ], \"items\": [ { \"apiVersion\": \"apps/v1\", \"kind\": \"Deployment\", ... } ] } 聚合资源的复杂检索和多集群资源检索 功能基本相同，只有部分操作不支持：\n 不支持根据 Owner 检索，如果需要进行根据 Owner 检索需要指定具体的资源类型，可以参考 多集群检索 和 指定集群检索 不支持在 Collection Resource 中获取具体的单个资源，因为具体资源需要指定集群和资源类型，可以使用 获取单个资源   尽管 kubectl 无法很好的检索聚合资源，但是可以简单的体验一下。\n 由于无法传递分页以及其他检索条件，kubectl 会一次获取到所有的聚合资源，在接入了大量集群或者存在大量 deployments，daemonsets，statefulsets 资源时，不要使用 kubectl 来查看聚合资源\n kubectl get collectionresources workloads # 输出 CLUSTER GROUP VERSION KIND NAMESPACE NAME AGE cluster-1 apps v1 DaemonSet kube-system vsphere-cloud-controller-manager 63d cluster-2 apps v1 Deployment kube-system calico-kube-controllers 109d cluster-2 apps v1 Deployment kube-system coredns-coredns 109d ... 请使用 URL 来检索聚合资源\n Only Metadata 我们在检索 CollectionResource 时，获取到的资源默认是全量的资源信息，但是我们通常只需要获取资源的 metadata 即可。\n在检索时我们可以使用 url query —— onlyMetadata 来只获取资源 Metadata。\n$ kubectl get --raw \"/apis/clusterpedia.io/v1beta1/collectionresources/workloads?onlyMetadata=true\u0026limit=1\" | jq { \"kind\": \"CollectionResource\", \"apiVersion\": \"clusterpedia.io/v1beta1\", \"metadata\": { \"name\": \"workloads\", \"creationTimestamp\": null }, \"resourceTypes\": [ { \"group\": \"apps\", \"version\": \"v1\", \"kind\": \"Deployment\", \"resource\": \"deployments\" } ], \"items\": [ { \"apiVersion\": \"apps/v1\", \"kind\": \"Deployment\", \"metadata\": { \"annotations\": { \"deployment.kubernetes.io/revision\": \"1\", \"shadow.clusterpedia.io/cluster-name\": \"cluster-example\" }, \"creationTimestamp\": \"2021-09-24T10:19:19Z\", \"generation\": 1, \"labels\": { \"k8s-app\": \"tigera-operator\" }, \"name\": \"tigera-operator\", \"namespace\": \"tigera-operator\", \"resourceVersion\": \"125073610\", \"uid\": \"992f9d53-37cb-4184-a004-15b278b11f79\" } } ] } Any CollectionResource  any collectionresource 是用户自由组合资源类型的方式之一，可以通过 自定义聚合资源 来查看更多。\n clusterpedia 支持一种特殊的 CollectionResource —— any\n$ kubectl get collectionresources NAME RESOURCES any * 在检索 any collectionresource 时，我们必须通过 url query 来指定一组资源类型，因此我们只能通过 clusterpedia-io/client-go 或者 url 来访问 any collectionresource\n$ kubectl get collectionresources any Error from server (BadRequest): url query - `groups` or `resources` is required any collectionresource 支持两个 url query —— groups 和 resources\ngroups 和 resources 可以同时指定，当前是取两者并集，并且不会进行去重处理，由调用者负责去重，未来对该行为有一些优化。\n$ kubectl get --raw \"/apis/clusterpedia.io/v1beta1/collectionresources/any?onlyMetadata=true\u0026groups=apps\u0026resources=batch/jobs,batch/cronjobs\" | jq groups groups 可以指定一组资源的组和版本，多个组版本使用 , 分隔，组版本格式为 \u003c group \u003e/\u003c version \u003e，也可以不指定版本 \u003c group \u003e，对于 /api 下的资源，可以直接使用空字符串\n示例：groups=apps/v1,,batch 指定了三个组 apps/v1, core, batch。\nresources resources 可以指定具体的资源类型，多个资源类型使用 , 分隔，资源类型格式为 \u003c group \u003e/\u003c version \u003e/\u003c resource\u003e，通过也可以不指定版本 \u003c group \u003e/\u003c resource \u003e。\n示例：resources=apps/v1/deployments,apps/daemonsets,/pods 指定了三种资源 deloyments，daemonsets 和 pods。\n","categories":"","description":"","excerpt":"关于聚合资源的概念可以查看 什么是聚合资源 （Collection Resource）\n由于 kubectl 的限制， …","ref":"/zh-cn/docs/usage/search/collection-resource/","tags":"","title":"聚合资源检索"},{"body":"The custom resource ClusterImportPolicy defines how a certain type of resource should be converted into a PediaCluster, so that clusterpedia can automatically create, update and delete PediaCluster based on a certain resource.\nFirst we need to define the type of resource (that you want to convert) to watch to in the ClusterImportPolicy resource , we will call the resource being watched to the Source resource.\nWhen a Source resource is created or deleted, the ClusterImportPolicy Controller creates the corresponding PediaClusterLifecycle resource.\nThe custom resource PediaClusterLifecycle creates, updates and deletes PediaCluster based on the specific Source resource.\nWhen creating and updating a PediaCluster, the Source resource may store the cluster’s authentication information (eg. CA, Token, etc.) in other resources, which are collectively referred to as Reference resources.\n The reconciliation of ClusterImportPolicy and PediaClusterLifecycle is done by the ClusterImportPolicy Controller and PediaClusterLifecycle Controller within the Clusterpedia Controller Manager\nClusterImportPolicy and PediaClusterLifecycle resource structures may be updated more frequently, so to avoid unnecessary impact on the cluster.clusterpedia.io group, they are placed in the policy.clusterpedia.io group. It may be migrated to cluster.clusterpedia.io in the future 1.0 release.\n ClusterImportPolicy An example of a complete ClusterImportPolicy resource is as follows:\napiVersion:policy.clusterpedia.io/v1alpha1kind:ClusterImportPolicymetadata:name:mcpspec:source:group:\"cluster.example.io\"resource:clustersselectorTemplate:\"\"references:- group:\"\"resource:secretsnamespaceTemplate:\"{{ .source.spec.authSecretRef.namespace }}\"nameTemplate:\"{{ .source.spec.authSecretRef.name }}\"key:authSecretnameTemplate:\"mcp-{{ .source.metadata.name }}\"template:|spec: apiserver: \"{{ .source.spec.apiEndpoint }}\" caData: \"{{ .references.authSecret.data.ca }}\" tokenData: \"{{ .references.authSecret.data.token }}\" syncResources: - group: \"\" resources: - \"pods\" - group: \"apps\" resources: - \"*\"creationCondition:|{{ if ne .source.spec.apiEndpoint \"\" }} {{ range .source.status.conditions }} {{ if eq .type \"Ready\" }} {{ if eq .status \"True\" }} true {{ end }} {{ end }} {{ end }} {{ end }}There are these sections:\n spec.source and spec.references define Source resource type and Reference resources spec.nameTemplate defines the name of the generated PediaClusterLifecycle and PediaCluster, which can be rendered according to the Source resource. spec.template and spec.creationCondition define the resource conversion policy.  Templates within references, template, and creationCondition all support the 70+ template functions provided by sprig, Sprig Function Documentation\nSource and References Resource The first thing we need to define in the ClusterImportPolicy resource is the Source resource type and the Reference resources.\napiVersion:policy.clusterpedia.io/v1alpha1kind:ClusterImportPolicymetadata:name:multi-cluster-polatformspec:source:group:\"example.io\"resource:clustersversions:[]selectorTemplate:|{{if eq .source.metadata.namespace \"default\" }} true {{ end }}references:- group:\"\"resource:secretsversions:[]namespaceTemplate:\"{{ .source.spec.secretRef.namespace }}\"nameTemplate:\"{{ .source.spec.secretRef.name }}\"key:secretThe Source resource specifies the resource group and resource name via spec.source.group and spec.source.resource. We can also use spec.source.versions to restrict Source resource versions, by default there is no restriction on Source resource versions\n A Source resource can only have one ClusterImportPolicy resource responsible for converting that resource\n You can also filter the Source by the spec.source.selectorTemplate field.\napiVersion:policy.clusterpedia.io/v1alpha1kind:ClusterImportPolicymetadata:name:kubevelaspec:source:group:\"\"resource:secretsselectorTemplate:|{{ if eq .source.metadata.namespace \"vela-system\" }} {{ if .source.metadata.labels }} {{ eq (index .source.metadata.labels \"cluster.core.oam.dev/cluster-credential-type\") \"X509Certificate\" }} {{ end }} {{ end }}source resources can be used for other template fields via {{ .source.\u003cfield\u003e }}\nThe resources involved in the conversion process are defined in spec.references and we need to specify the type of the resource and the specific reference resource via namespace and name templates. We can also restrict the version of the Reference resource in the same way as the Source resource.\nIn addition to this, we need to set a key for the reference resource, which will be used by subsequent template fields as {{ .references.\u003ckey\u003e }}\n*The later items in *spec.references can also refer to the earlier ones via .references.\u003ckey\u003e\nspec:references:- group:a.example.ioresource:aresourcenamespaceTemplate:\"{{ .source.spec.aNamespace }}\"nameTemplate:\"{{ .source.spec.aName }}\"key:refA- group:b.example.ioresource:bresourcenamespaceTemplate:\"{{ .references.refA.spec.bNamespace }}\"nameTemplate:\"{{ .references.refA.spec.bName }}\"key:refBPediaClusterLifecycle When a Source is created, the ClusterImportPolicy Controller creates the corresponding PediaClusterLifecycle resource based on the ClusterImportPolicy resource.\nThe name of the PediaClusterLifecycle resource is set via the spec.nameTemplate field of the ClusterImportPolicy.\napiVersion: policy.clusterpedia.io/v1alpha1 kind: ClusterImportPolicy metadata: name: multi-cluster-platform spec: nameTemplate: \"mcp-{{ .source.metadata.namespace }}-{{ .source.metadata.name }}\" The nameTemplate can only render templates based on Source resources, and the field is usually set based on whether it is a Cluster Scoped resource.\n nameTemplate: \"\u003cprefix\u003e-{{ .source.metadata.namespace}}-{{ .source.metadata.name }}\" nameTemplate: \"\u003cprefix\u003e-{{ .source.metadata.name }}\"  **nameTemplate is usually prefixed with a multi-cloud platform or other meaningful name, but can of course be set without a prefix. **\nThe PediaClusterLifecycle sets the specific source resource and references resource and the conversion policy\napiVersion:policy.clusterpedia.io/v1alpha1kind:PediaClusterLifecyclemetadata:name:\u003cprefix\u003e-examplespec:source:group:example.ioversion:v1beta1resource:clustersnamespace:\"\"name:examplereferences:- group:\"\"resource:secretsversion:v1namespaceTemplate:\"{{ .source.spec.secretRef.namespace }}\"nameTemplate:\"{{ .source.spec.secretRef.name }}\"key:secretThe spec.source of the PediaClusterLifecycle sets a specific Source resource, including the specific version, namespace and name of the resource.\nspec.references contains the specific resource version compared to ClusterImportPolicy, the other fields are the same as the References definition within ClusterImportPolicy.\nThe namespace and name of the references resource will be resolved when converting the resource.\nPediaClusterLifecycle 和 PediaCluster The name of PediaClusterLifecycle corresponds to PediaCluster, and PediaClusterLifecycle creates and updates PediaCluster with the same name according to the conversion policy.\nPediaCluster Convertion Policy We focus on the following aspects when defining the conversion policy:\n the template used to create or update the PediaCluster When to trigger the creation of a `PediaCluster  In ClusterImportPolicy, we use spec.template and spec.creationCondition to define them\napiVersion:policy.clusterpedia.io/v1alpha1kind:ClusterImportPolicymetadata:name:mcpspec:...other fieldstemplate:|spec: apiserver: \"{{ .source.spec.apiEndpoint }}\" caData: \"{{ .references.authSecret.data.ca }}\" tokenData: \"{{ .references.tokenData.data.token }}\" syncResources: - group: \"\" resources: - \"pods\" - group: \"apps\" resources: - \"*\"creationCondition:|{{ if ne .source.spec.apiEndpoint \"\" }} {{ range .source.status.conditions }} {{ if eq .type \"Ready\" }} {{ if eq .status \"True\" }} true {{ end }} {{ end }} {{ end }} {{ end }}Both of these fields are template fields that need to be rendered based on Source resource and References resources.\nWhen the Source resource is created, the ClusterImportPolicy Controller will create the corresponding PediaClusterLifecycle based on the ClusterImportPolicy, and the PediaClusterLifecycle will will also contain the conversion policy.\n Of course, if the policy in ClusterImportPolicy is modified, it will be synchronized to all PediaClusterLifecycle resources it belongs to.\n apiVersion:policy.clusterpedia.io/v1alpha1kind:ClusterImportPolicymetadata:name:mcp-examplespec:...other fieldstemplate:|spec: apiserver: \"{{ .source.spec.apiEndpoint }}\" caData: \"{{ .references.authSecret.data.ca }}\" tokenData: \"{{ .references.tokenData.data.token }}\" syncResources: - group: \"\" resources: - \"pods\" - group: \"apps\" resources: - \"*\"creationCondition:|{{ if ne .source.spec.apiEndpoint \"\" }} {{ range .source.status.conditions }} {{ if eq .type \"Ready\" }} {{ if eq .status \"True\" }} true {{ end }} {{ end }} {{ end }} {{ end }}PediaClusterLifecycleis responsible for creating and updating specificPediaClustersbased onspec.creationConditionandspec.template`.\nCreation Condition Sometimes we don’t create a PediaCluster immediately after a Source resource is created, but rather we need to wait until some fields or some state of the Source resource is ready before creating the PediaCluster.\nspec.creationCondition uses the template syntax to determine if the creation condition is met, and when the template is rendered with a value of True (case insensitive) then PediaCluster is created according to `spec.\nIf the PediaCluster already exists, spec.creationCondition will not affect updates to the PediaCluster.\nPediaCluster Template spec.template defines a PediaCluster resource template that renders specific resources based on Source resource and References resources when creating or updating a PediaCluster.\nThe PediaCluster template can be separated into three parts.\n Metadata: labels and annotations Cluster endpoint and authentication fields: spec.apiserver, spec.caData, spec.tokenData, spec.certData, spec.keyData and spec.kubeconfig Resource sync fields: spec.syncResources, spec.syncAllCustomResources, spec.syncResourcesRefName  The metadata and resource sync fields of the PediaCluster resource are only available when the PediaCluser is created, and only the cluster endpoint and authentication fields are updated when the PediaCluster resource is updated\nPediaCluster Deletion Condition If a PediaCluster is created by PediaClusterLifecycle, then PediaClusterLifecycle will be set to the owner of that PediaCluster resource.\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:mcp-exampleownerReferences:- apiVersion:policy.clusterpedia.io/v1alpha1kind:PediaClusterLifecyclename:mcp-exampleuid:f932483a-b1c5-4894-a524-00f78ea34a9fWhen a Source resource is deleted, the PediaClusterLifecycle is deleted at the same time and the PediaCluster is deleted automatically.\nIf PediaCluster already existed before PediaClusterLifecycle, then Source will not automatically delete PediaCluster when it is deleted.\nDeletionCondition will be added in the future to allow users to force or preempt the deletion of PediaCluster.\n","categories":"","description":"","excerpt":"The custom resource ClusterImportPolicy defines how a certain type of …","ref":"/docs/concepts/cluster-import-policy/","tags":"","title":"Cluster Auto Import Policy"},{"body":"Clusterpedia can use different storage components such as MySQL/PostgreSQL, Memory, Elasticsearch through the storage layer.\nCurrently, Clusterpedia has two built-in storage layers:\n The internalstorage storage layer for accessing relational databases. The memory storage layer based on Memory  Although Clusterpedia already supports relational databases and memory by default, user requirements are often variable and complex, and a fixed storage layer may not match the requirements of different users for storage components and performance, so Clusterpedia supports access to user-implemented storage layers by means of plugins, which we call custom storage layer plugins, or storage plugins for short.\nWith the storage plugin, users can do the following things:\n Use any storage component, such as Elasticsearch, RedisGraph, Etcd, or even MessageQueue with no problem Allow users to optimize the storage format and query performance of resources for their business Implement more advanced retrieval features for storage components  Clusterpedia also maintains a number of storage plugins that users can choose from, depending on your needs:\n Sample Storage: Example of a storage plugin that can connect to relational databases Elasticsearch Storage: Storage plugin for connecting to Elasticsearch  Storage plugins are loaded by Clusterpedia components via Go Plugin, which provides very flexible plug-in access without any performance loss compared to RPC or other methods.\n The performance impact of the Go Plugin can be found at https://github.com/uberswe/goplugins\n As we all know, Go Plugin is troublesome to develop and use, but Clusterpedia cleverly optimizes the use and development of storage plugins through some mechanisms, and provides clusterpedia-io/sample-storage plugin as a reference.\nHere we take clusterpedia-io/sample-storage as an example to introduce.\n How to use the custom storage layer plugin How to implement the custom storage layer plugin  Use the custom storage layer plugin The use of the storage plugin can be broadly divided into three ways:\n Run the Clusterpedia component binary and load the storage plugins Use the base Chart – clusterpedia-core to set up the storage plugin image and configure the storage layer Use the Clusterpedia Advanced Chart to not care about the storage plugin settings  By running the component binary locally, we can get a better understanding of how the Cluserpedia component loads and runs the storage plugins.\nUsers can actually use the storage plugin image already built, or deploy Clusterpedia Advanced Chart directly\nLocal Run Building Plugins A storage plugin is actually a dynamic link library with a .so suffix. Clusterpedia components can load storage plugins at startup and use specific storage plugins depending on the specified storage layer name.\nLet’s take clusterpedia-io/sample-storage as an example and build a storage plugin binary\n$ git clone --recursive https://github.com/clusterpedia-io/sample-storage.git \u0026\u0026 cd sample-storage $ make build-plugin Use the file command to view storage plugin information\n$ file ./plugins/sample-storage-layer.so ./plugins/sample-storage-layer.so: Mach-O 64-bit dynamically linked shared library x86_64 Clusterpedia’s ClusterSynchro Manager and APIServer components can load and use storage plugins via environment variables and command flags:\n STORAGE_PLUGINS=\u003cplugins dir\u003e environment variable sets the directory where the plugins are located, and Clusterpedia will load all plugins in that directory into the component --storage-name=\u003cstorage name\u003e command flag, set the storage layer name --storage-config=\u003cstorage config path\u003e command flag, set the storage layer configuration  Building components To ensure consistent dependencies when running locally, clusterpedia components need to be built locally with the make build-components command\n For more information on building storage plugins and Clusterpedia components see Developing custom storage layer plugins\n $ # cd sample-storage $ make build-components $ ls -al ./bin -rwxr-xr-x 1 icebergu staff 90707488 11 7 11:15 apiserver -rwxr-xr-x 1 icebergu staff 91896016 11 7 11:16 binding-apiserver -rwxr-xr-x 1 icebergu staff 82769728 11 7 11:16 clustersynchro-manager -rwxr-xr-x 1 icebergu staff 45682000 11 7 11:17 controller-manager Storage plugin runtime configuration file Before running clusterpedia you also need to prepare the runtime configuration file for the storage plugin. sample-storage provides an example configuration example-config.yaml\nWhen running the clusterpedia component, set the configuration file via --storage-config=./config.yaml to specify the runtime configuration file\n# example-config.yamltype:mysqlhost:127.0.0.1port:\"3306\"user:rootpassword:dangerous0database:clusterpedialog:stdout:truecolorful:trueslowThreshold:100msThe user needs to configure the runtime configuration according to the selected storage layer\nRun clusterpedia clustersynchro manager $ STORAGE_PLUGINS=./plugins ./bin/clustersynchro-manager --kubeconfig ~/.kube/config \\  --storage-name=sample-storage-layer \\  --storage-config ./config.yaml Run clusterpedia apiserver You can choose not to use your own generated certificate, which requires running apiserver without the -client-ca-file ca.crt flag.\n$ openssl req -nodes -new -x509 -keyout ca.key -out ca.crt $ openssl req -out client.csr -new -newkey rsa:4096 -nodes -keyout client.key -subj \"/CN=development/O=system:masters\" $ openssl x509 -req -days 365 -in client.csr -CA ca.crt -CAkey ca.key -set_serial 01 -sha256 -out client.crt run apiserver\n$ STORAGE_PLUGINS=./plugins ./bin/apiserver --client-ca-file ca.crt --secure-port 8443 \\  --kubeconfig ~/.kube/config \\  --authentication-kubeconfig ~/.kube/config \\  --authorization-kubeconfig ~/.kube/config \\  --storage-name=sample-storage-layer \\  --storage-config ./config.yaml Storage Plugin Image + Helm Charts Clusterpeida already provides several Charts:\n charts/clusterpedia is a Chart using the internalstorage storage layer, which can be optionally deployed with MySQL or PostgreSQL, but does not support setting up storage plugins charts/clusterpedia-core supports configuration of any storage layer Chart, usually used as a child Chart charts/clusterpedia-mysql is an advanced Chart using MySQL as the storage component, based on clusterpedia-core implementation charts/clusterpedia-postgresql is an advanced Chart using PostgreSQL as the storage component, based on the clusterpedia-core implementation charts/clusterpedia-elasticsearch uses Elasticsearch as the advanced Chart for the storage component, based on the clusterpedia-core implementation  If you don’t need a storage plugin and the internalstorage storage layer and relational database are sufficient, you can use charts/clusterpedia directly, out of the box.\nclusterpedia-mysql，clusterpedia-postgresql and clusterpedia-elasticsearch are advanced Charts based on charts/clusterpedia-core, in which the user is shielded from the complex concept of storage plugins by default configuration of clusterpedia-core’s storage plugin image and storage layer configuration, right out of the box.\nAlthough we usually use Advanced Charts directly in our usage, knowing how to use charts/clusterpedia-core to set up storage plugin images gives us a better understanding of how plugin images work.\nclusterpedia-core Let’s take clusterpedia-io/sample-storage as an example and deploy Clusterpedia using the ghcr.io/clusterpedia-io/clusterpedia/sample-storage-layer plugin image.\nThe clusterpedia-core does not involve the deployment and installation of any storage components, so users need to configure the storage layer according to the deployed storage components\n# myvalues.yamlstorage:name:\"sample-storage-layer\"image:registry:ghcr.iorepository:clusterpedia-io/clusterpedia/sample-storage-layertag:v0.0.0-v0.6.0config:type:\"mysql\"host:\"10.111.94.196\"port:3306user:rootpassword:dangerous0database:clusterpediastorage.name sets the storage layer name of the storage image plugin\nclusterpedia-core copies the storage plugins from the plugin image defined by storage.image to the component’s plugin directory.\n# helm template clusterpedia -n clusterpedia-system -f myvalues.yaml ./clusterpedia-core...initContainers:- name:copy-storage-pluginimage:ghcr.io/clusterpedia-io/clusterpedia/sample-storage-layer:v0.0.0-v0.6.0imagePullPolicy:IfNotPresentcommand:- /bin/sh- -ec- cp /plugins/* /var/lib/clusterpedia/plugins/volumeMounts:- name:storage-pluginsmountPath:/var/lib/clusterpedia/pluginscontainers:- name:clusterpedia-clusterpedia-core-apiserverimage:ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.6.0imagePullPolicy:IfNotPresentcommand:- /usr/local/bin/apiserver- --secure-port=443- --storage-name=sample-storage-layer- --storage-config=/etc/clusterpedia/storage/config.yamlenv:- name:STORAGE_PLUGINSvalue:/var/lib/clusterpedia/pluginsvolumeMounts:- name:storage-configmountPath:/etc/clusterpedia/storagereadOnly:true- name:storage-pluginsmountPath:/var/lib/clusterpedia/pluginsreadOnly:truevolumes:- name:storage-configconfigMap:name:clusterpedia-clusterpedia-core-sample-storage-layer-config- name:storage-pluginsemptyDir:{}...In addition to using storage.config to define the runtime configuration config.yaml for the storage layer, you can also use the existing configmap and secret.\n# myvalues.yamlstorage:name:\"sample-storage-layer\"image:registry:ghcr.iorepository:clusterpedia-io/clusterpedia/sample-storage-layertag:v0.0.0-v0.6.0configMap:\"sample-storage-config\"componentEnv:- name:DB_PASSWORDvalueFrom:secretKeyRef:name:\"sample-storage-password\"key:passwordclusterpedia-core is very flexible in configuration of the storage layer in order to be referenced by other advanced Charts as a child Chart, but users do not necessarily need to use clusterpedia-core directly in practice, just the advanced Charts deployed for the specific storage component, such as clusterpedia-mysql and clusterpedia-postgresql.\nIn the next section we will also describe how to implement Advanced Charts for specific storage components based on clusterpedia-core.\nDeveloping custom storage layer plugins clusterpedia-io/sample-storage is not only a storage plugin example, but also a template repository where the project structure and most of the build tools can be used in other storage plugin projects\nWe first clone sample-storage, or generate a new storage plugin repository based on sample-storage\n$ git clone --recursive https://github.com/clusterpedia-io/sample-storage.git \u0026\u0026 cd sample-storage Note that when pulling the repository, you need to specify --recursive to pull the sub-repository\n$ ls -al ... -rw-r--r-- 1 icebergu staff 260 12 13 15:14 Dockerfile -rw-r--r-- 1 icebergu staff 1836 12 13 16:03 Makefile -rw-r--r-- 1 icebergu staff 2219 11 23 10:25 README.md drwxr-xr-x 32 icebergu staff 1024 11 23 10:30 clusterpedia -rw-r--r-- 1 icebergu staff 156 11 23 10:25 example-config.yaml -rw-r--r-- 1 icebergu staff 2376 12 13 15:33 go.mod -rw-r--r-- 1 icebergu staff 46109 12 13 15:33 go.sum -rw-r--r-- 1 icebergu staff 139 11 23 10:25 main.go drwxr-xr-x 16 icebergu staff 512 12 13 15:33 storage drwxr-xr-x 9 icebergu staff 288 12 13 15:33 vendor The entire project structure is divided into three categories:\n main.go, storage package: the core logic of the custom storage plugin clusterpedia local repository: used for local development and testing Dockerfile and Makefile for project build and image packaging, which can be applied to any storage plugin project  core logic main.go is the main storage plugin file, mainly used to call the registration function in the storage package – RegisterStorageLayer.\npackage main import ( plugin \"github.com/clusterpedia-io/sample-storage-layer/storage\" ) func init() { plugin.RegisterStorageLayer() } The storage package contains the core logic of the storage plugin:\n Implementing the clusterpedia storage layer interface storage.StorageFactory  import ( \"gorm.io/gorm\" \"github.com/clusterpedia-io/clusterpedia/pkg/storage\" ) type StorageFactory struct { db *gorm.DB } var _ storage.StorageFactory = \u0026StorageFactory{} NewStorageFactory function to return an instance of storage.StorageFactory  func NewStorageFactory(configPath string) (storage.StorageFactory, error) The RegisterStorageLayer function registers the NewStorageFactory with clusterpedia  const StorageName = \"sample-storage-layer\" func RegisterStorageLayer() { storage.RegisterStorageFactoryFunc(StorageName, NewStorageFactory) } The registered NewStorageFactory is automatically called when the user specifies the storage layer with --storage-name to create an instance of storage.StorageFactory.\nLocal development run To facilitate development and testing, we have added the clusterpedia repository as a subrepository to the storage plugin repository\n$ git submodule status +4608c8d13101d82960525dfe39f51e4f64ed49b3 clusterpedia (v0.6.0) and replace the clusterpedia repository in go.mod with a local subrepository\n# go.mod replace ( github.com/clusterpedia-io/api =\u003e ./clusterpedia/staging/src/github.com/clusterpedia-io/api github.com/clusterpedia-io/clusterpedia =\u003e ./clusterpedia ) The local cluserpedia subrepository will not be used when building the storage layer image\nBuild storage plugin The build of the storage plugin is divided into two parts, building the components in the clusterpedia repository and building the storage plugin.\n$ make build-components OUTPUT_DIR=/Users/icebergu/workspace/clusterpedia/sample-storage-layer ON_PLUGINS=true \\  /Library/Developer/CommandLineTools/usr/bin/make -C clusterpedia all hack/builder.sh apiserver hack/builder.sh binding-apiserver hack/builder.sh clustersynchro-manager hack/builder-nocgo.sh controller-manager $ ls -al ./bin -rwxr-xr-x 1 icebergu staff 90724968 12 15 09:51 apiserver -rwxr-xr-x 1 icebergu staff 91936472 12 15 09:52 binding-apiserver -rwxr-xr-x 1 icebergu staff 82826584 12 15 09:52 clustersynchro-manager -rwxr-xr-x 1 icebergu staff 45677904 12 15 09:52 controller-manager The make build-components command will call make all from the clusterpedia repository and output the result to ./bin directory of the storage plugin project.\n If the clusterpedia subrepository has not changed, then you only need to build the components once\n Build the storage plugin\n$ make build-plugin CLUSTERPEDIA_REPO=/Users/icebergu/workspace/clusterpedia/sample-storage/clusterpedia \\  clusterpedia/hack/builder.sh plugins sample-storage-layer.so $ ls -al ./plugins -rw-r--r-- 1 icebergu staff 53354352 12 15 09:47 sample-storage-layer.so Building the storage plugin locally also requires using the builder.sh script of the clusterpedia repository to build the plugin binary.\nFor running storage plugins, see Running storage plugins locally\nstorage plugin image As mentioned above, storage plugins are shared with clusterpedia by image in a real deployment.\nThe Makefile provides make image-plugin to build images and make push-images to publish them.\nBuilding images To build a plugin image, we need to use the clusterpedia/builder image as the base image to build the plugin, and the builder image needs to be the same version as the clusterpedia component that uses the plugin\n$ BUILDER_IMAGE=ghcr.io/clusterpedia-io/clusterpedia/builder:v0.6.0 make image-plugin clusterpedia maintains a builder image of the published version, and users can also use their own locally built builder image\nBuild the builder image locally\n$ cd clusterpedia $ make image-builder docker buildx build \\  -t \"ghcr.io/clusterpedia-io/clusterpedia\"/builder-amd64:4608c8d13101d82960525dfe39f51e4f64ed49b3 \\  --platform=linux/amd64 \\  --load \\  -f builder.dockerfile . ; \\ The tag format for storage plugin images is \u003c stroage version \u003e-\u003cclusterpedia-version/commit\u003e, for example: ghcr.io/clusterpedia-io/clusterpedia/sample-storage-layer:v0.0.0-v0.6.0\nThe storage plugin image can be deployed in the \u003cclusterpedia-version/commit\u003e version of Clusterpedia\npush images make image-plugin builds the storage plugin image based on the manually set builder image\nWhile pushing images with make push-images automatically builds images for all compatible versions and architectures\n# Makefile CLUSTERPEDIA_VERSIONS = v0.6.0-beta.1 v0.6.0 RELEASE_ARCHS ?= amd64 arm64 Once the image is built, the storage plugin image can be used via cluserpedia-core\nAdvanced Chart based on clusterpedia-core After implementing our own storage plugin, we still need to provide an Advanced Chart based on clusterpedia-core Chart to make it easier to use.\nAdvanced Chart needs to provide the following capabilities:\n Set the default storage plugin image Set the storage layer name Support dynamic setting of the runtime configuration of the storage layer Provide configuration and installation of storage components  Create a new Chart using the sample-storage storage plugin – clusterpedia-sample-mysql, which will use mysql as the storage component.\n# Chart.yamldependencies:- name:mysqlrepository:https://charts.bitnami.com/bitnamiversion:9.x.x- name:commonrepository:https://charts.bitnami.com/bitnamiversion:1.x.x- name:clusterpedia-corerepository:https://clusterpedia-io.github.io/clusterpedia-helm/version:0.1.xWe need to override the storage layer related settings in clusterpedia-core, which provides both values.yaml and dynamic templates to set up the storage plugin and storage layer information\nWe override the static settings of the storage layer in values.yaml, such as plugin image and storage layer name\n# values.yamlclusterpedia-core:storage:name:\"sample-storage-layer\"image:registry:\"ghcr.io\"repository:\"clusterpedia-io/clusterpedia/sample-storage-layer\"tag:\"v0.0.0-v0.6.0\"The config.yaml and some environment variables of the custom storage layer generally need to refer to ConfigMap and Secret, and the names of these resources will change dynamically according to the Chart release name, so we need to use the dynamic templates way to set\nclusterpedia-core provides three overriding naming templates\n# clusterpedia-core/templates/_storage_override.yaml{{- define \"clusterpedia.storage.override.initContainers\" -}}{{- end -}}{{- define \"clusterpedia.storage.override.configmap.name\" -}}{{- end -}}{{- define \"clusterpedia.storage.override.componentEnv\" -}}{{- end -}}Each of them can be set as follows:\n apiserver and clustersynchro manager init containers before running ConfigMap name to store the config.yaml configuration that the plugin needs to read Environment variables to be used by the storage plugin  Let’s take clusterpedia-mysql as an example and see how it is set\n# _storage_override.yaml{{- define \"clusterpedia.storage.override.initContainers\" -}}- name:ensure-databaseimage:docker.io/bitnami/mysql:8.0.28-debian-10-r23command:- /bin/sh- -ec- |if [ ${CREARE_DATABASE} = \"ture\" ]; then until mysql -u${STORAGE_USER} -p${DB_PASSWORD} --host=${STORAGE_HOST} --port=${STORAGE_PORT} -e 'CREATE DATABASE IF NOT EXISTS ${STORAGE_DATABASE}'; do echo waiting for database check \u0026\u0026 sleep 1; done; echo 'DataBase OK ✓' else until mysqladmin status -u${STORAGE_USER} -p${DB_PASSWORD} --host=${STORAGE_HOST} --port=${STORAGE_PORT}; do sleep 1; done fienv:- name:DB_PASSWORDvalueFrom:secretKeyRef:name:{{include \"clusterpedia.mysql.storage.fullname\" . }}key:passwordenvFrom:- configMapRef:name:{{include \"clusterpedia.mysql.storage.initContainer.env.name\" . }}{{- end -}}clusterpedia-mysql defines the environment variables needed to init containers in the storage-initcontainer-env-configmap.yaml\napiVersion:v1kind:ConfigMapmetadata:name:{{include \"clusterpedia.mysql.storage.initContainer.env.name\" . }}namespace:{{.Release.Namespace }}labels:{{include \"common.labels.standard\" . | nindent 4 }}data:STORAGE_HOST:{{include \"clusterpedia.mysql.storage.host\" . | quote }}STORAGE_PORT:{{include \"clusterpedia.mysql.storage.port\" . | quote }}STORAGE_USER:{{include \"clusterpedia.mysql.storage.user\" . | quote }}STORAGE_DATABASE:{{include \"clusterpedia.mysql.storage.database\" . | quote }}CREARE_DATABASE:{{.Values.externalStorage.createDatabase | quote }}The init container dynamically set by the clusterpedia.storage.override.initContainers naming template will be rendered to Deployment\n# helm template clusterpedia -n clusterpedia-system --set persistenceMatchNode=None ....spec:initContainers:- name:ensure-databaseimage:docker.io/bitnami/mysql:8.0.28-debian-10-r23command:- /bin/sh- -ec- |if [ ${CREARE_DATABASE} = \"ture\" ]; then until mysql -u${STORAGE_USER} -p${DB_PASSWORD} --host=${STORAGE_HOST} --port=${STORAGE_PORT} -e 'CREATE DATABASE IF NOT EXISTS ${STORAGE_DATABASE}'; do echo waiting for database check \u0026\u0026 sleep 1; done; echo 'DataBase OK ✓' else until mysqladmin status -u${STORAGE_USER} -p${DB_PASSWORD} --host=${STORAGE_HOST} --port=${STORAGE_PORT}; do sleep 1; done fienv:- name:DB_PASSWORDvalueFrom:secretKeyRef:name:clusterpedia-mysql-storagekey:passwordenvFrom:- configMapRef:name:clusterpedia-mysql-storage-initcontainer-envThe ConfigMap and environment variables of the storage plugin runtime configuration config.yaml are also dynamically configured in clusterpedia-mysql\n# _storage_override.yaml{{- define \"clusterpedia.storage.override.configmap.name\" -}}{{- printf \"%s-mysql-storage-config\" .Release.Name -}}{{- end -}}{{- define \"clusterpedia.storage.override.componentEnv\" -}}- name:DB_PASSWORDvalueFrom:secretKeyRef:name:{{include \"clusterpedia.mysql.storage.fullname\" . }}key:password{{- end -}}The storage layer configuration is set to the APIServer and ClusterSynchro Manager Deployment through static override of values and dynamic setting of naming templates\nAdvanced Chart like clusterpedia-mysql allows you to mask the use of underlying storage plugins for users out of the box\n","categories":"","description":"","excerpt":"Clusterpedia can use different storage components such as …","ref":"/docs/advanced-features/custom_storage_layer/","tags":"","title":"Custom Storage Layer Plugin"},{"body":"Clusterpedia 可以通过存储层来使用不同的存储组件，例如 MySQL/PostgreSQL, Memory, Elasticsearch\n当前，Clusterpedia 内置了两个存储层：\n 用于接入关系型数据库的 internalstorage 存储层 基于内存的 memory 存储层  尽管 Clusterpedia 已经默认支持了关系型数据库和内存，但是用户的需求往往是多变和复杂的，固定的存储层可能无法满足不同用户对于存储组件和性能的要求，于是 Clusterpedia 支持通过插件的方式来接入用户自己实现的存储层，我们称这种方式为 自定义存储层插件，简称为 存储插件。\n通过存储插件，用户可以做到以下事情：\n 使用任意的存储组件，例如 Elasticsearch，RedisGraph，Etcd，甚至是 MessageQueue 也没有问题 允许用户针对自己的业务来优化资源的存储格式和查询性能 针对存储组件的特性来实现更高级的检索功能  Clusterpedia 也维护了一些存储插件，用户可以根据需求选用：\n Sample Storage: 可以连接关系型数据库的存储插件示例 Elasticsearch Storage: 用于连接 Elasticsearch 的存储插件  存储插件是通过 Go Plugin 的方式来让 Clusterpedia 组件加载，相比 RPC 或者其他方式，这种方式在没有任何损耗的前提下提供非常灵活的插件接入。\n 关于 Go Plugin 对性能的影响可以简单参考 https://github.com/uberswe/goplugins\n 众所周知，Go Plugin 在开发和使用上都比较繁琐，不过 Clusterpedia 通过一些机制来巧妙的优化了存储插件的使用和开发，并且提供了 clusterpedia-io/sample-storage 插件作为参考。\n下面我们以 clusterpedia-io/sample-storage 为例，分别介绍：\n 如何使用 自定义存储层插件 如何实现 自定义存储层插件  使用 自定义存储层插件 存储插件的使用可以大致分为三种方式：\n 运行 Clusterpedia 组件二进制并加载 存储插件 使用基础 Chart —— clusterpedia-core 来设置存储插件镜像和配置存储层 使用 Clusterpedia 高级 Chart，无需关心存储插件的设置  通过本地运行组件二进制，我们可以更加了解 Cluserpedia 组件是如何加载和运行 存储插件，\n用户在真正使用时通常是利用已经构建好的存储插件镜像，或者是直接部署 Clusterpedia 高级 Chart\n本地运行 插件构建 存储插件实际是一个 .so 后缀的动态链接库，Clusterpedia 组件在启动时可以加载存储插件，并根据指定的存储层名称来使用具体的存储插件。\n我们以 clusterpedia-io/sample-storage 为例，构建出一个存储插件二进制\n$ git clone --recursive https://github.com/clusterpedia-io/sample-storage.git \u0026\u0026 cd sample-storage $ make build-plugin 使用 file 命令查看存储插件信息\n$ file ./plugins/sample-storage-layer.so ./plugins/sample-storage-layer.so: Mach-O 64-bit dynamically linked shared library x86_64 Clusterpedia 的 ClusterSynchro Manager 和 APIServer 组件可以通过环境变量和命令参数来加载和使用存储插件：\n STORAGE_PLUGINS=\u003cplugins dir\u003e 环境变量设置插件所在目录，Clusterpedia 会将该目录下所有插件都加载到组件中 --storage-name=\u003cstorage name\u003e 插件命令参数，设置存储层名称 --storage-config=\u003cstorage config path\u003e 插件命令参数，设置存储层配置  组件构建 本地运行时，为了保证依赖一致，需要在本地通过 make build-components 命令构建 clusterpedia 组件\n$ # 在 sample-storage 目录 $ make build-components $ ls -al ./bin -rwxr-xr-x 1 icebergu staff 90707488 11 7 11:15 apiserver -rwxr-xr-x 1 icebergu staff 91896016 11 7 11:16 binding-apiserver -rwxr-xr-x 1 icebergu staff 82769728 11 7 11:16 clustersynchro-manager -rwxr-xr-x 1 icebergu staff 45682000 11 7 11:17 controller-manager  关于存储插件与 Clusterpedia 组件的构建可以查看 开发自定义存储层插件\n 存储插件运行时的配置文件 在运行 clusterpedia 前还需要准备存储插件在运行时的配置文件，sample-storage 提供了它的配置示例 example-config.yaml\n在运行时 clusterpedia 组件时，通过 --storage-config=./config.yaml 来指定运行时配置文件\n# example-config.yamltype:mysqlhost:127.0.0.1port:\"3306\"user:rootpassword:dangerous0database:clusterpedialog:stdout:truecolorful:trueslowThreshold:100ms用户需要根据选择的存储层来配置运行时配置\n运行 clusterpedia clustersynchro manager $ STORAGE_PLUGINS=./plugins ./bin/clustersynchro-manager --kubeconfig ~/.kube/config \\  --storage-name=sample-storage-layer \\  --storage-config ./config.yaml 运行 clusterpedia apiserver 可以选择不使用自己生成的证书，这时需要在运行 apiserver 忽略掉 --client-ca-file ca.crt 参数\n$ openssl req -nodes -new -x509 -keyout ca.key -out ca.crt $ openssl req -out client.csr -new -newkey rsa:4096 -nodes -keyout client.key -subj \"/CN=development/O=system:masters\" $ openssl x509 -req -days 365 -in client.csr -CA ca.crt -CAkey ca.key -set_serial 01 -sha256 -out client.crt 运行 apiserver\n$ STORAGE_PLUGINS=./plugins ./bin/apiserver --client-ca-file ca.crt --secure-port 8443 \\  --kubeconfig ~/.kube/config \\  --authentication-kubeconfig ~/.kube/config \\  --authorization-kubeconfig ~/.kube/config \\  --storage-name=sample-storage-layer \\  --storage-config ./config.yaml 存储插件镜像 + Helm Charts Clusterpeida 已经提供了多个 Charts：\n charts/clusterpedia 使用 internalstorage 存储层的 Chart，可以选择部署 MySQL 或者 PostgreSQL，但是不支持设置存储插件 charts/clusterpedia-core 支持配置任意存储层的 Chart，通常作为子 Chart 来使用 charts/clusterpedia-mysql 使用 MySQL 作为存储组件的高级 Chart，基于 clusterpedia-core 实现 charts/clusterpedia-postgresql 使用 PostgreSQL 作为存储组件的高级 Chart，基于 clusterpedia-core 实现 charts/clusterpedia-elasticsearch 使用 Elasticsearch 作为存储组件的高级 Chart，基于 clusterpedia-core 实现  如果用户没有存储插件需求，默认存储层和关系型数据库已经可以满足需求的话，可以直接选用 charts/clusterpedia，开箱即用\nclusterpedia-mysql，clusterpedia-postgresql 和 clusterpedia-elasticsearch 便是基于 clusterpedia-core 实现的高级 Charts，在这些 Charts 中通过默认配置 clusterpedia-core 的存储插件镜像和存储层配置来为用户屏蔽掉存储插件的复杂概念，开箱即用\n尽管我们在使用中通常会直接使用高级 Charts，但是知道如何使用 clusterpedia-core 来设置存储插件镜像，可以让我们更好的理解插件镜像是如何工作的。\nclusterpedia-core 我们以 clusterpedia-io/sample-storage 为例，使用 ghcr.io/clusterpedia-io/clusterpedia/sample-storage-layer 插件镜像来部署 Clusterpedia。\nclusterpedia-core 不涉及任何存储组件的部署安装，所以用户需要根据已部署的存储组件来配置存储层\n# myvalues.yamlstorage:name:\"sample-storage-layer\"image:registry:ghcr.iorepository:clusterpedia-io/clusterpedia/sample-storage-layertag:v0.0.0-v0.6.0config:type:\"mysql\"host:\"10.111.94.196\"port:3306user:rootpassword:dangerous0database:clusterpediastorage.name 配置存储镜像插件的存储层名称\nclusterpedia-core 会将 storage.image 定义的插件镜像中的存储插件复制到组件的插件目录下\n# helm template clusterpedia -n clusterpedia-system -f myvalues.yaml ./clusterpedia-core...initContainers:- name:copy-storage-pluginimage:ghcr.io/clusterpedia-io/clusterpedia/sample-storage-layer:v0.0.0-v0.6.0imagePullPolicy:IfNotPresentcommand:- /bin/sh- -ec- cp /plugins/* /var/lib/clusterpedia/plugins/volumeMounts:- name:storage-pluginsmountPath:/var/lib/clusterpedia/pluginscontainers:- name:clusterpedia-clusterpedia-core-apiserverimage:ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.6.0imagePullPolicy:IfNotPresentcommand:- /usr/local/bin/apiserver- --secure-port=443- --storage-name=sample-storage-layer- --storage-config=/etc/clusterpedia/storage/config.yamlenv:- name:STORAGE_PLUGINSvalue:/var/lib/clusterpedia/pluginsvolumeMounts:- name:storage-configmountPath:/etc/clusterpedia/storagereadOnly:true- name:storage-pluginsmountPath:/var/lib/clusterpedia/pluginsreadOnly:truevolumes:- name:storage-configconfigMap:name:clusterpedia-clusterpedia-core-sample-storage-layer-config- name:storage-pluginsemptyDir:{}...除了使用 storage.config 定义存储层的运行时配置 config.yaml 外，还可以使用已有的 configmap 以及 secret\n# myvalues.yamlstorage:name:\"sample-storage-layer\"image:registry:ghcr.iorepository:clusterpedia-io/clusterpedia/sample-storage-layertag:v0.0.0-v0.6.0configMap:\"sample-storage-config\"componentEnv:- name:DB_PASSWORDvalueFrom:secretKeyRef:name:\"sample-storage-password\"key:passwordclusterpedia-core 为了能够作为子 Chart 被其他高级 Charts 引用，在存储层配置上是非常灵活的，但是用户实际在使用中并不一定需要直接使用 clusterpedia-core，只需要使用针对具体存储组件部署的高级 Charts 即可，例如 clusterpedia-mysql 和 clusterpedia-postgresql\n在下节我们也会介绍如何基于 clusterpedia-core 来针对具体存储组件实现高级 Chart。\n开发自定义存储层插件 clusterpedia-io/sample-storage 不仅仅是一个存储插件示例，也是一个模版仓库，其中项目结构和大部分构建工具都可以在其他存储插件项目中使用\n我们首先 clone sample-storage，或者根据 sample-storage 生成一个新的存储插件仓库\n$ git clone --recursive https://github.com/clusterpedia-io/sample-storage.git \u0026\u0026 cd sample-storage 注意拉取仓库时，需要指定 --recursive 拉取子仓库\n$ ls -al ... -rw-r--r-- 1 icebergu staff 260 12 13 15:14 Dockerfile -rw-r--r-- 1 icebergu staff 1836 12 13 16:03 Makefile -rw-r--r-- 1 icebergu staff 2219 11 23 10:25 README.md drwxr-xr-x 32 icebergu staff 1024 11 23 10:30 clusterpedia -rw-r--r-- 1 icebergu staff 156 11 23 10:25 example-config.yaml -rw-r--r-- 1 icebergu staff 2376 12 13 15:33 go.mod -rw-r--r-- 1 icebergu staff 46109 12 13 15:33 go.sum -rw-r--r-- 1 icebergu staff 139 11 23 10:25 main.go drwxr-xr-x 16 icebergu staff 512 12 13 15:33 storage drwxr-xr-x 9 icebergu staff 288 12 13 15:33 vendor 整个项目结构分为三类\n main.go, storage 包：自定义存储层插件的核心逻辑 clusterpedia 主库，用于本地开发和测试 Dockerfile 和 Makefile 用于项目构建和镜像打包，可以适用于任何存储插件项目  核心逻辑 main.go 是存储插件的主文件，主要用来调用 storage 包中的注册函数 —— RegisterStorageLayer。\npackage main import ( plugin \"github.com/clusterpedia-io/sample-storage-layer/storage\" ) func init() { plugin.RegisterStorageLayer() } storage 包中的是存储插件的核心逻辑：\n 实现 clusterpedia 存储层接口 storage.StorageFactory  import ( \"gorm.io/gorm\" \"github.com/clusterpedia-io/clusterpedia/pkg/storage\" ) type StorageFactory struct { db *gorm.DB } var _ storage.StorageFactory = \u0026StorageFactory{} NewStorageFactory 函数来返回 storage.StorageFactory 实例  func NewStorageFactory(configPath string) (storage.StorageFactory, error) RegisterStorageLayer 函数将 NewStorageFactory 注册到 clusterpedia 中  const StorageName = \"sample-storage-layer\" func RegisterStorageLayer() { storage.RegisterStorageFactoryFunc(StorageName, NewStorageFactory) } 当用户通过 --storage-name 指定该存储层时，会自动调用注册的 NewStorageFactory 来创建 storage.StorageFactory 实例。\n./bin/apiserver --storage-name=sample-storage-layer \u003cother flags\u003e 本地开发运行 为了方便开发测试，我们在存储插件的仓库中添加了 clusterpedia 主库作为子库\n$ git submodule status +4608c8d13101d82960525dfe39f51e4f64ed49b3 clusterpedia (v0.6.0) 并且将 go.mod 中 clusterpedia 仓库 replace 为本地子库\n# go.mod replace ( github.com/clusterpedia-io/api =\u003e ./clusterpedia/staging/src/github.com/clusterpedia-io/api github.com/clusterpedia-io/clusterpedia =\u003e ./clusterpedia ) 在构建存储层镜像时，不会使用本地 cluserpedia 子库\n存储插件构建 存储插件的构建分为两部分，分别是构建 clusterpedia 子库中组件和构建存储插件\n$ make build-components OUTPUT_DIR=/Users/icebergu/workspace/clusterpedia/sample-storage-layer ON_PLUGINS=true \\  /Library/Developer/CommandLineTools/usr/bin/make -C clusterpedia all hack/builder.sh apiserver hack/builder.sh binding-apiserver hack/builder.sh clustersynchro-manager hack/builder-nocgo.sh controller-manager $ ls -al ./bin -rwxr-xr-x 1 icebergu staff 90724968 12 15 09:51 apiserver -rwxr-xr-x 1 icebergu staff 91936472 12 15 09:52 binding-apiserver -rwxr-xr-x 1 icebergu staff 82826584 12 15 09:52 clustersynchro-manager -rwxr-xr-x 1 icebergu staff 45677904 12 15 09:52 controller-manager make build-components 命令会在调用 clusterpedia 库中的 make all，并将结果输出到存储插件项目的 ./bin 目录下\n 如果 clusterpedia 子库未发生更改，那么只需要构建组件即可\n 构建存储插件\n$ make build-plugin CLUSTERPEDIA_REPO=/Users/icebergu/workspace/clusterpedia/sample-storage/clusterpedia \\  clusterpedia/hack/builder.sh plugins sample-storage-layer.so $ ls -al ./plugins -rw-r--r-- 1 icebergu staff 53354352 12 15 09:47 sample-storage-layer.so 本地构建存储插件也是需要使用 clusterpedia 库的 builder.sh 脚本来构建插件二进制\n关于运行存储层插件可以参考 本地运行存储插件\n存储插件镜像 上文提到，存储插件在真正的部署中，是通过镜像的方式将存储插件共享给 clusterpedia。\nMakefile 中提供 make image-plugin 来构建镜像，make push-images 来发布镜像\n构建镜像 构建插件镜像时，我们需要使用 clusterpedia/builder 镜像作为基础镜像来构建插件，builder 镜像的版本需要和使用插件的 clusterpedia 组件的版本一致\n$ BUILDER_IMAGE=ghcr.io/clusterpedia-io/clusterpedia/builder:v0.6.0 make image-plugin clusterpedia 中维护了已发布版本的 builder 镜像，用户也可以使用自己本地构建的 builder 镜像\n本地构建 builder 镜像\n$ cd clusterpedia $ make image-builder docker buildx build \\  -t \"ghcr.io/clusterpedia-io/clusterpedia\"/builder-amd64:4608c8d13101d82960525dfe39f51e4f64ed49b3 \\  --platform=linux/amd64 \\  --load \\  -f builder.dockerfile . ; \\ 存储插件镜像的 tag 格式为 -\u003cclusterpedia-version/commit\u003e，例如： ghcr.io/clusterpedia-io/clusterpedia/sample-storage-layer:v0.0.0-v0.6.0\n存储插件镜像可以部署在 \u003cclusterpedia-version/commit\u003e 版本的 Clusterpedia 中\n镜像推送 make image-plugin 根据手动设置的 builder 镜像来构建存储插件镜像\n而使用 make push-images 推送镜像时会自动为所有兼容版本和架构构建镜像\n# Makefile CLUSTERPEDIA_VERSIONS = v0.6.0-beta.1 v0.6.0 RELEASE_ARCHS ?= amd64 arm64 镜像构建好后，可以通过 cluserpedia-core 来使用存储插件镜像\n基于 clusterpeida-core 实现高级 Chart 我们在实现自己的存储插件后，为了更加方便的使用，还是需要基于 clusterpedia-core Chart 来封装出高级 Chart\n高级 Chart 需要提供以下能力：\n 设置默认的存储插件镜像 设置存储层名称 支持动态设置存储层的运行时配置 提供对存储组件的配置和安装  创建一个使用 sample-storage 存储插件的新 Chart —— clusterpedia-sample-mysql，这个 Chart 会使用 mysql 作为存储组件。\n# Chart.yamldependencies:- name:mysqlrepository:https://charts.bitnami.com/bitnamiversion:9.x.x- name:commonrepository:https://charts.bitnami.com/bitnamiversion:1.x.x- name:clusterpedia-corerepository:https://clusterpedia-io.github.io/clusterpedia-helm/version:0.1.x我们需要覆盖 clusterpedia-core 中存储层相关的设置，clusterpedia-core 提供 values.yaml 和动态模版两种方式来设置存储插件和存储层信息\n我们在 values.yaml 覆盖存储层的静态设置，例如插件镜像和存储层名称\n# values.yamlclusterpedia-core:storage:name:\"sample-storage-layer\"image:registry:\"ghcr.io\"repository:\"clusterpedia-io/clusterpedia/sample-storage-layer\"tag:\"v0.0.0-v0.6.0\"自定义存储层的 config.yaml 和一些环境变量的设置，一般需要引用 ConfigMap 和 Secret，而这些资源的名称会根据 Chart 的 Release 名字动态变化，所以我们需要使用 动态模版 的方式来设置\nclusterpedia-core 提供了三个可以覆盖的命名模版\n# clusterpedia-core/templates/_storage_override.yaml{{- define \"clusterpedia.storage.override.initContainers\" -}}{{- end -}}{{- define \"clusterpedia.storage.override.configmap.name\" -}}{{- end -}}{{- define \"clusterpedia.storage.override.componentEnv\" -}}{{- end -}}可以分别设置：\n apiserver，clustersynchro manager 组件运行前的 init containers 保存存储插件需要读取的 config.yaml 配置的 ConfigMap 名称 存储插件需要使用的环境变量  我们以 clusterpedia-mysql 为例，看看它的设置\n# _storage_override.yaml{{- define \"clusterpedia.storage.override.initContainers\" -}}- name:ensure-databaseimage:docker.io/bitnami/mysql:8.0.28-debian-10-r23command:- /bin/sh- -ec- |if [ ${CREARE_DATABASE} = \"ture\" ]; then until mysql -u${STORAGE_USER} -p${DB_PASSWORD} --host=${STORAGE_HOST} --port=${STORAGE_PORT} -e 'CREATE DATABASE IF NOT EXISTS ${STORAGE_DATABASE}'; do echo waiting for database check \u0026\u0026 sleep 1; done; echo 'DataBase OK ✓' else until mysqladmin status -u${STORAGE_USER} -p${DB_PASSWORD} --host=${STORAGE_HOST} --port=${STORAGE_PORT}; do sleep 1; done fienv:- name:DB_PASSWORDvalueFrom:secretKeyRef:name:{{include \"clusterpedia.mysql.storage.fullname\" . }}key:passwordenvFrom:- configMapRef:name:{{include \"clusterpedia.mysql.storage.initContainer.env.name\" . }}{{- end -}}clusterpedia-mysql 在 storage-initcontainer-env-configmap.yaml 中定义了 init container 需要的环境变量\napiVersion:v1kind:ConfigMapmetadata:name:{{include \"clusterpedia.mysql.storage.initContainer.env.name\" . }}namespace:{{.Release.Namespace }}labels:{{include \"common.labels.standard\" . | nindent 4 }}data:STORAGE_HOST:{{include \"clusterpedia.mysql.storage.host\" . | quote }}STORAGE_PORT:{{include \"clusterpedia.mysql.storage.port\" . | quote }}STORAGE_USER:{{include \"clusterpedia.mysql.storage.user\" . | quote }}STORAGE_DATABASE:{{include \"clusterpedia.mysql.storage.database\" . | quote }}CREARE_DATABASE:{{.Values.externalStorage.createDatabase | quote }}通过 clusterpedia.storage.override.initContainers 命名模版动态设置的 init container 会被渲染到 Deployment 中：\n# helm template clusterpedia -n clusterpedia-system --set persistenceMatchNode=None ....spec:initContainers:- name:ensure-databaseimage:docker.io/bitnami/mysql:8.0.28-debian-10-r23command:- /bin/sh- -ec- |if [ ${CREARE_DATABASE} = \"ture\" ]; then until mysql -u${STORAGE_USER} -p${DB_PASSWORD} --host=${STORAGE_HOST} --port=${STORAGE_PORT} -e 'CREATE DATABASE IF NOT EXISTS ${STORAGE_DATABASE}'; do echo waiting for database check \u0026\u0026 sleep 1; done; echo 'DataBase OK ✓' else until mysqladmin status -u${STORAGE_USER} -p${DB_PASSWORD} --host=${STORAGE_HOST} --port=${STORAGE_PORT}; do sleep 1; done fienv:- name:DB_PASSWORDvalueFrom:secretKeyRef:name:clusterpedia-mysql-storagekey:passwordenvFrom:- configMapRef:name:clusterpedia-mysql-storage-initcontainer-env保存存储插件运行时配置 config.yaml 的 ConfigMap 和环境变量也是在 clusterpedia-mysql 中动态配置\n# _storage_override.yaml{{- define \"clusterpedia.storage.override.configmap.name\" -}}{{- printf \"%s-mysql-storage-config\" .Release.Name -}}{{- end -}}{{- define \"clusterpedia.storage.override.componentEnv\" -}}- name:DB_PASSWORDvalueFrom:secretKeyRef:name:{{include \"clusterpedia.mysql.storage.fullname\" . }}key:password{{- end -}}通过 values 静态覆盖和 命名模版的动态设置，存储层配置会被设置到 APIServer 和 ClusterSynchro Manager 的 Deployment 中\n通过类似 clusterpedia-mysql 的高级 Chart 可以为用户屏蔽掉底层存储插件的使用，达到开箱即用。\n","categories":"","description":"","excerpt":"Clusterpedia 可以通过存储层来使用不同的存储组件，例如 MySQL/PostgreSQL, Memory, …","ref":"/zh-cn/docs/advanced-features/custom_storage_layer/","tags":"","title":"自定义存储层插件"},{"body":"自定义资源 ClusterImportPolicy 定义了某种类型的资源应该如何转换成 PediaCluster，这样 clusterpedia 便可以根据某种资源来自动的创建、更新和删除 PediaCluster\n首先需要在 ClusterImportPolicy 资源中定义监听（想要转换的）的资源类型，我们将被监听的资源称为 Source 资源。\n当一个 Source 资源被创建或者删除时，ClusterImportPolicy Controller 会创建相应 PediaClusterLifecycle 资源。 而 PediaClusterLifecycle 会根据具体的 Source 资源来创建，更新以及删除 PediaCluster。\n在创建和更新 PediaCluster 时，Source 资源可能会将集群的认证信息（例如 CA，Token 等）保存在其他资源中，我们将这些涉及到的其他资源统称为 References 资源。\n 对于 ClusterImportPolicy 和 PediaClusterLifecycle 的调协由 Clusterpedia Controller Manager 内的 ClusterImportPolicy Controller 和 PediaClusterLifecycle Controller 负责\nClusterImportPolicy 和 PediaCusterLifecycle 资源结构的更新可能会比较频繁，为了避免对 cluster.clusterpedia.io group 带来不必要的影响，所以放在 policy.clusterpedia.io group 中, 未来 1.0 发布时，可能会迁移到 cluster.clusterpedia.io 中。\n ClusterImportPolicy 一个完整 ClusterImportPolicy 示例如下：\napiVersion:policy.clusterpedia.io/v1alpha1kind:ClusterImportPolicymetadata:name:mcpspec:source:group:\"cluster.example.io\"resource:clustersselectorTemplate:\"\"references:- group:\"\"resource:secretsnamespaceTemplate:\"{{ .source.spec.authSecretRef.namespace }}\"nameTemplate:\"{{ .source.spec.authSecretRef.name }}\"key:authSecretnameTemplate:\"mcp-{{ .source.metadata.name }}\"template:|spec: apiserver: \"{{ .source.spec.apiEndpoint }}\" caData: \"{{ .references.authSecret.data.ca }}\" tokenData: \"{{ .references.authSecret.data.token }}\" syncResources: - group: \"\" resources: - \"pods\" - group: \"apps\" resources: - \"*\"creationCondition:|{{ if ne .source.spec.apiEndpoint \"\" }} {{ range .source.status.conditions }} {{ if eq .type \"Ready\" }} {{ if eq .status \"True\" }} true {{ end }} {{ end }} {{ end }} {{ end }}主要分为三部分\n spec.source 和 spec.references 分别定义 Source 资源和 References 资源 spec.nameTemplate 定义生成的 PediaClusterLifecycle 和 PediaCluster 的名称，可以根据 Source 资源进行渲染 spec.template 和 spec.creationCondition 定义资源转换策略。  references，template，creationCondition 内的模板均支持由 sprig 提供的 70 多种模版函数，Sprig Function Documentation\nSource 和 References 资源 在 ClusterImportPolicy 资源中我们首先需要定义的就是 Source 资源类型以及 References 资源\napiVersion:policy.clusterpedia.io/v1alpha1kind:ClusterImportPolicymetadata:name:multi-cluster-polatformspec:source:group:\"example.io\"resource:clustersversions:[]selectorTemplate:|{{if eq .source.metadata.namespace \"default\" }} true {{ end }}references:- group:\"\"resource:secretsversions:[]namespaceTemplate:\"{{ .source.spec.secretRef.namespace }}\"nameTemplate:\"{{ .source.spec.secretRef.name }}\"key:secretSource 资源通过 spec.source.group 和 spec.source.resource 指定了资源组和资源名称。我们也可以使用 spec.source.versions 来限制 Source 的资源版本，默认是不会对 Source 资源版本进行限制\n 一种 Source 资源只能有一个负责转换该资源的 ClusterImportPolicy 资源\n 用户也可以通过 spec.source.selectorTemplate 字段来过滤 Source\napiVersion:policy.clusterpedia.io/v1alpha1kind:ClusterImportPolicymetadata:name:kubevelaspec:source:group:\"\"resource:secretsselectorTemplate:|{{ if eq .source.metadata.namespace \"vela-system\" }} {{ if .source.metadata.labels }} {{ eq (index .source.metadata.labels \"cluster.core.oam.dev/cluster-credential-type\") \"X509Certificate\" }} {{ end }} {{ end }}source 资源可以通过 {{ .source.\u003cfield\u003e }} 来用于其他的模版字段\nspec.references 中定义了在转换过程中涉及到的资源，我们需要指定资源的类型，以及通过 namespace 和 name 模版来获取具体的 reference 资源。我们也可以和 Source 资源一样对 Reference 资源的版本进行限制。\n除此之外还要为 reference 资源设置一个 key，这个 key 会以 {{ .references.\u003ckey\u003e }} 的方式来让后续模版字段使用\nspec.references 中后面的项也可以通过 .references.\u003ckey\u003e 来引用前面的项\nspec:references:- group:a.example.ioresource:aresourcenamespaceTemplate:\"{{ .source.spec.aNamespace }}\"nameTemplate:\"{{ .source.spec.aName }}\"key:refA- group:b.example.ioresource:bresourcenamespaceTemplate:\"{{ .references.refA.spec.bNamespace }}\"nameTemplate:\"{{ .references.refA.spec.bName }}\"key:refBPediaClusterLifecycle 当一个 Source 被创建后，ClusterImportPolicy Controller 会根据 ClusterImportPolicy 创建相应的 PediaClusterLifecycle 资源。\nPediaClusterLifecycle 资源的名字是通过 ClusterImportPolicy 的 spec.nameTemplate 字段来设置的。\napiVersion: policy.clusterpedia.io/v1alpha1 kind: ClusterImportPolicy metadata: name: multi-cluster-platform spec: nameTemplate: \"mcp-{{ .source.metadata.namespace }}-{{ .source.metadata.name }}\" nameTemplate 只能根据 Source 资源来渲染模版，通常根据是否为 Cluster Scoped 资源来设置该字段：\n nameTemplate: \"\u003cprefix\u003e-{{ .source.metadata.namespace}}-{{ .source.metadata.name }}\" nameTemplate: \"\u003cprefix\u003e-{{ .source.metadata.name }}\"  nameTemplate 前缀通常是多云平台或者其他有意义的名字，当然也可以没有前缀。\nPediaClusterLifecycle 中会设置具体的 source 资源和 references 资源以及转换策略\napiVersion:policy.clusterpedia.io/v1alpha1kind:PediaClusterLifecyclemetadata:name:\u003cprefix\u003e-examplespec:source:group:example.ioversion:v1beta1resource:clustersnamespace:\"\"name:examplereferences:- group:\"\"resource:secretsversion:v1namespaceTemplate:\"{{ .source.spec.secretRef.namespace }}\"nameTemplate:\"{{ .source.spec.secretRef.name }}\"key:secretPediaClusterLifecycle 的 spec.source 设置了一个具体的 Source 资源，包括了资源的具体版本，命名空间和名称。\nspec.references 相比 ClusterImportPolicy 包含了具体的资源版本，其他字段和 ClusterImportPolicy 内的 References 定义相同。 references 资源的命名空间和名字会在转换资源时进行解析。\nPediaClusterLifecycle 和 PediaCluster PediaClusterLifecycle 的名字会和 PediaCluster 进行一一对应，PediaClusterLifecycle 根据转换策略创建和更新同名的 PediaCluster。\nPediaCluster 转换策略 我们在定义转换策略时，主要关注以下方面:\n 用于创建或者更新 PediaCluster 的模版 什么时候触发 PediaCluster 的创建  在 ClusterImportPolicy 中，我们使用 spec.template 和 spec.creationCondition 来定义他们\napiVersion:policy.clusterpedia.io/v1alpha1kind:ClusterImportPolicymetadata:name:mcpspec:...other fieldstemplate:|spec: apiserver: \"{{ .source.spec.apiEndpoint }}\" caData: \"{{ .references.authSecret.data.ca }}\" tokenData: \"{{ .references.tokenData.data.token }}\" syncResources: - group: \"\" resources: - \"pods\" - group: \"apps\" resources: - \"*\"creationCondition:|{{ if ne .source.spec.apiEndpoint \"\" }} {{ range .source.status.conditions }} {{ if eq .type \"Ready\" }} {{ if eq .status \"True\" }} true {{ end }} {{ end }} {{ end }} {{ end }}这两个字段都是模版字段，需要根据 Source 资源和 References 资源来渲染。\n当 Source 资源被创建后，ClusterImportPolicy Controller 会根据 ClusterImportPolicy 创建对应的 PediaClusterLifecycle，并且 PediaClusterLifecycle 中也会包含转换策略。\n 当然如果 ClusterImportPolicy 内的策略发生修改，也会同步给所属的所有 PediaClusterLifecycle 资源。\n apiVersion:policy.clusterpedia.io/v1alpha1kind:ClusterImportPolicymetadata:name:mcp-examplespec:...other fieldstemplate:|spec: apiserver: \"{{ .source.spec.apiEndpoint }}\" caData: \"{{ .references.authSecret.data.ca }}\" tokenData: \"{{ .references.tokenData.data.token }}\" syncResources: - group: \"\" resources: - \"pods\" - group: \"apps\" resources: - \"*\"creationCondition:|{{ if ne .source.spec.apiEndpoint \"\" }} {{ range .source.status.conditions }} {{ if eq .type \"Ready\" }} {{ if eq .status \"True\" }} true {{ end }} {{ end }} {{ end }} {{ end }}PediaClusterLifecycle 会负责根据 spec.creationCondition 和 spec.template 来创建更新具体的 PediaCluster。\nCreation Condition 我们有时在 Source 资源创建后并不会立刻创建 PediaCluster, 而是需要等到 Source 资源某些字段或者某些状态就绪后再创建 PediaCluster。\nspec.creationCondition 使用模版语法来判断是否满足创建条件，当模版渲染后的值为 True（大小写模糊）后则会根据 spec.Template 创建 PediaCluster。\n如果 PediaCluster 已经存在，spec.creationCondition 不会影响后续对 PediaCluster 的更新。\nPediaCluster Template spec.template 定义了 PediaCluster 资源模版，在创建或者更新 PediaCluster 时，会根据 Source 资源和 References 资源来渲染出具体的资源。\nPediaCluster 模版可以分成三部分：\n 元信息：labels 和 annotations 集群访问与认证字段：spec.apiserver，spec.caData，spec.tokenData，spec.certData，spec.keyData 还有 spec.kubeconfig 资源同步字段：spec.syncResources，spec.syncAllCustomResources，spec.syncResourcesRefName  PediaCluster 资源的元信息和资源同步字段只有在创建 PediaCluser 时才会有效，在更新 PediaCluster 资源时，只会更新集群访问与认证字段\nPediaCluster 的删除 如果一个 PediaCluster 是由 PediaClusterLifecycle 创建，那么会将 PediaClusterLifecycle 设置为该 PediaCluster 资源的 owner\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:mcp-exampleownerReferences:- apiVersion:policy.clusterpedia.io/v1alpha1kind:PediaClusterLifecyclename:mcp-exampleuid:f932483a-b1c5-4894-a524-00f78ea34a9f当一个 Source 资源被删除时，会同步删除 PediaClusterLifecycle，PediaCluster 会自动删除。\n如果 PediaCluster 在 PediaClusterLifecycle 前已经出现了，那么 Source 删除时不会自动的删除 PediaCluster。\n未来会增加 DeletionCondition 来允许用户强制或者提前删除 PediaCluster。\n","categories":"","description":"","excerpt":"自定义资源 ClusterImportPolicy 定义了某种类型的资源应该如何转换成 PediaCluster， …","ref":"/zh-cn/docs/concepts/cluster-import-policy/","tags":"","title":"集群自动接入策略(ClusterImportPolicy)"},{"body":"The main function of Clusterpedia is to provide complex search for resources in multiple clusters.\nClusterpedia uses the PediaCluster resource to specify which resources in the cluster need to support complex search, and synchronizes these resources onto the Storage Component via Storage Layer in real time.\n# exampleapiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:cluster-examplespec:apiserver:\"https://10.30.43.43:6443\"syncResources:- group:appsresources:- deployments- group:\"\"resources:- pods- configmaps- group:cert-manager.ioversions:- v1resources:- certificatesSynchronize built-in resources In order to manage and view these synchronized resources through PediaCluster, you need to configure resources in groups\nsyncResources:- group:appsversions:[]resources:- deployments- daemonsetsFor built-in resources, versions is not required.\nClusterpedia will automatically select the appropriate version to synchronize based on the resource version supported in the cluster.\nAlso, you do not need to worry about version conversion because Clusterpedia will open all version interfaces for built-in resources.\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps\" | jq { \"kind\": \"APIGroup\", \"apiVersion\": \"v1\", \"name\": \"apps\", \"versions\": [ { \"groupVersion\": \"apps/v1\", \"version\": \"v1\" }, { \"groupVersion\": \"apps/v1beta2\", \"version\": \"v1beta2\" }, { \"groupVersion\": \"apps/v1beta1\", \"version\": \"v1beta1\" } ], \"preferredVersion\": { \"groupVersion\": \"apps/v1\", \"version\": \"v1\" } } Clusterpedia supports three versions of Deployment: v1, v1beta2, and v1beta1.\nSynchronize custom resources Compared with built-in resources, custom resources have slightly different configuration on resource versions.\nsyncResources: - group: cert-manager.io versions: [] resources: - certificates You can also ignore the versions field and then Clusterpedia will synchronize the previous three cluster versions in the Group.\nTake cert-manager.io as an example to get the Group supported by cert-manager.io in an imported cluster\n# Run the command in an imported cluster kubectl get --raw=\"/apis/cert-manager.io\" | jq { \"kind\": \"APIGroup\", \"apiVersion\": \"v1\", \"name\": \"cert-manager.io\", \"versions\": [ { \"groupVersion\": \"cert-manager.io/v1\", \"version\": \"v1\" }, { \"groupVersion\": \"cert-manager.io/v1beta1\", \"version\": \"v1beta1\" }, { \"groupVersion\": \"cert-manager.io/v1alpha3\", \"version\": \"v1alpha3\" }, { \"groupVersion\": \"cert-manager.io/v1alpha2\", \"version\": \"v1alpha2\" } ], \"preferredVersion\": { \"groupVersion\": \"cert-manager.io/v1\", \"version\": \"v1\" } } The imported cluster supports four versions for cert-manager.io: v1, v1beta1, v1alpha3, v1alpha2.\nWhen syncResources.[group].versions is left blank, Clusterpedia will synchronize three versions v1, v1beta1, v1alpah3 in the order of the APIGroup.versions list except for v1alpha2.\nSpecify a sync version for custom resources If you specified versions, the specific resource would be synchronized by versions.\nsyncResources:- group:cert-manager.ioversions:- v1beta1resources:- certificatesThe above snippet only synchronizes v1beta1.\nUsage notes The custom resource synchronization does not support version conversion currently. The versions are fixed after synchronization.\nIf cluster-1 only synchronizes v1beta1 resources when you are searching for multi-cluster resources, the request to search for version v1 will ignore the version v1beta1.\nYou are required to learn and handle the different versions in multiple clusters for custom resources.\nSync all custom resources The custom resource types and versions change with the CRD, so when a CRD is created and we don’t want to modify spec.syncResources to sync resources as the same time, we can set spec.syncAllCustomResources to sync all custom resources.\nspec:syncAllCustomResources:trueHowever, it should be noted that to use this feature, you need to enabled the corresponding Feature Gate in clustersynchro-manager, which can be found in Sync All Custom Resource\nUsing wildcards to sync resources Group Wildcard spec:syncResources:- group:\"apps\"resources:- \"*\"Use Group Wildcard to sync all types of resources under the specified group.\nIn the above example, all resources under apps will be synced.\nAll-resources Wildcard spec:syncResources:- group:\"*\"resources:- \"*\"The All-resources Wildcard allows we to sync built-in resources, custom resources and aggregated API resources in the imported cluster.\nThis feature creates a large number of long connections, so use it with caution and enable the corresponding Feature Gate in the clustersynchro-manager, as described in Sync All Resources\nReference ClusterSyncResources ClusterSyncResources is used to define cluster resource synchronization configurations that are commonly referenced by multiple PediaClusters, see Public Configuration of Cluster Sync Resources for more information about ClusterSyncResources\nPediaCluster sets the referenced ClusterSyncResources by spec.syncResourceRefName.\napiVersion:cluster.clusterpedia.io/v1alpha2kind:ClusterSyncResourcesmetadata:name:global-basespec:syncResources:- group:\"\"resources:- pods- group:\"apps\"resources:- \"*\"---apiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:demo1spec:syncResourcesRefName:\"global-base\"syncResources:- group:\"\"resources:- pods- configmapsIf PediaCluster has both spec.syncResourcesRefName and spec.syncResources set, then the concatenation of the two will be used.\nIn the above example, clusterpedia synchronizes the pods and configmaps resources, and all resources under the apps group in the demo1 cluster.\nView synchronized resources You can view resources, sync versions, and storage versions by using Status of the PediaCluster resource.\nFor Status, a resource may have Sync Version and Storage Version:\n Sync Version refers to the resource version from a synchronized cluster by Clusterpedia Storage Version refers to the version stored at the storage layer by Clusterpedia  status:syncResources:- group:appsresources:- name:deploymentskind:Deploymentnamespaced:truesyncConditions:- lastTransitionTime:\"2022-01-13T04:34:08Z\"status:SyncingstorageVersion:v1version:v1In general, Sync Version is same as Storage Version for a cluster resource.\nHowever, if an imported cluster only provides the Deployment resource of the v1beta1 version, the Sync Version is v1beta1 and the Storage Version is v1.\nFor example, when synchronizing a Deployment of Kubernetes 1.10, the synchronization status is as follows:\nstatus:syncResources:- group:appsresources:- name:deploymentskind:Deploymentnamespaced:truesyncConditions:- lastTransitionTime:\"2022-01-13T04:34:04Z\"status:SyncingstorageVersion:v1version:v1beta1For a custom resource, Synchronized Version is same as Storage Version\nNext After resource synchronization, you can Access the Clusterpedia to Search for Resources\n","categories":"","description":"","excerpt":"The main function of Clusterpedia is to provide complex search for …","ref":"/docs/usage/sync-resources/","tags":"","title":"Synchronize Cluster Resources"},{"body":"Clusterpedia 的主要功能，便是提供对多集群内的资源进行复杂检索。\n通过 PediaCluster 资源来指定该集群中哪些资源需要支持复杂检索，Clusterpedia 会将这些资源实时的通过存储层同步到存储组件中\n# exampleapiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:cluster-examplespec:apiserver:\"https://10.30.43.43:6443\"syncResources:- group:appsresources:- deployments- group:\"\"resources:- pods- configmaps- group:cert-manager.ioversions:- v1resources:- certificates内置资源同步 PediaCluster 为了方便管理和查看这些同步的资源，用户需要以 Group 为单位来配置资源\nsyncResources:- group:appsversions:[]resources:- deployments- daemonsets对于内置资源，不需要填写 versions 字段。\nClusterpedia 会根据该集群内所支持的资源版本自动选择合适的版本来收集， 并且用户无需担心版本转换的问题， Clusterpedia 会开放出该内置资源的所有版本接口。\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps\" | jq { \"kind\": \"APIGroup\", \"apiVersion\": \"v1\", \"name\": \"apps\", \"versions\": [ { \"groupVersion\": \"apps/v1\", \"version\": \"v1\" }, { \"groupVersion\": \"apps/v1beta2\", \"version\": \"v1beta2\" }, { \"groupVersion\": \"apps/v1beta1\", \"version\": \"v1beta1\" } ], \"preferredVersion\": { \"groupVersion\": \"apps/v1\", \"version\": \"v1\" } } 可以看到 Clusterpedia 支持 v1，v1beta2，v1beta1 三个版本的 Deployment\n自定义资源同步 相比内置资源，自定义资源在资源版本的配置上会稍有不同。\nsyncResources: - group: cert-manager.io versions: [] resources: - certificates 用户同样可以忽略 versions 字段，这时 Clusterpedia 就会同步该 Group 在该集群的前三个版本。\n以 cert-manager.io 为例，获取被接入集群中 cert-manager.io 支持的 Group\n# 在被接入集群内执行 kubectl get --raw=\"/apis/cert-manager.io\" | jq { \"kind\": \"APIGroup\", \"apiVersion\": \"v1\", \"name\": \"cert-manager.io\", \"versions\": [ { \"groupVersion\": \"cert-manager.io/v1\", \"version\": \"v1\" }, { \"groupVersion\": \"cert-manager.io/v1beta1\", \"version\": \"v1beta1\" }, { \"groupVersion\": \"cert-manager.io/v1alpha3\", \"version\": \"v1alpha3\" }, { \"groupVersion\": \"cert-manager.io/v1alpha2\", \"version\": \"v1alpha2\" } ], \"preferredVersion\": { \"groupVersion\": \"cert-manager.io/v1\", \"version\": \"v1\" } } 可以看到，被接入集群支持 cert-manager.io 的 v1，v1beta1，v1alpha3，v1alpha2 四个版本。\n当 syncResources.[group].versions 为空时，Clusterpedia 就会以 APIGroup.versions 列表的顺序，收集 v1， v1beta1，v1alpah3 三个版本，而 v1alpha2 不会被收集\n指定自定义资源的同步版本 如果用户指定了 versions，那么就会按照 versions 的配置来收集指定的版本资源。\nsyncResources:- group:cert-manager.ioversions:- v1beta1resources:- certificates这时，只会收集 v1beta1 版本。\n使用注意 自定义资源收集暂时不支持版本转换，收集了哪些版本，那么就只支持哪些资源版本的收集。\n这时在检索多集群资源时，如果 cluster-1 只收集了 v1beta1 版本的资源，而检索请求 v1 版本的资源便会忽略 cluster-1 所收集的 v1beta1 版本\n需要用户去协调处理自定义资源在多个集群内的版本情况\n同步所有的自定义资源 自定义资源类型和版本会随着 CRD 进行变动，当一个 CRD 被创建时，我们不想同时修改 spec.syncResources 来同步资源，这时我们就可以设置 spec.syncAllCustomResources 来同步所有的自定义资源\nspec:syncAllCustomResources:true但是需要注意，使用该功能需要在 clustersynchro-manager 中开启相应的 Feature Gate，具体操作可以参考 同步所有自定义资源\n使用通配符来同步资源 使用通配符，收集指定组下的所有类型资源 spec:syncResources:- group:\"apps\"resources:- \"*\"通过组通配符可以收集指定的 Group 下的所有类型的资源。\n例如上例中，便会同步 apps 下的所有资源\n使用通配符，收集所有类型的资源 spec:syncResources:- group:\"*\"resources:- \"*\"通过全资源通配符 可以同步集群中的内置资源，自定义资源以及聚合式 API 资源。\n使用该功能会创建大量的长连接，所以需要谨慎使用，并且在 clustersynchro-manager 中开启相应的 Feature Gate, 具体操作可以参考 同步所有资源\n引用 ClusterSyncResources ClusterSyncResources 用于定义多个 PediaCluster 共同引用的集群资源同步配置，关于 ClusterSyncResources 可以查看 公共的集群资源同步配置(ClusterSyncResources) \nPediaCluster 通过 spec.syncResourceRefName 来设置引用的 ClusterSyncResources。\napiVersion:cluster.clusterpedia.io/v1alpha2kind:ClusterSyncResourcesmetadata:name:global-basespec:syncResources:- group:\"\"resources:- pods- group:\"apps\"resources:- \"*\"---apiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:demo1spec:syncResourcesRefName:\"global-base\"syncResources:- group:\"\"resources:- pods- configmaps如果 PediaCluster 同时设置了 spec.syncResourcesRefName 和 spec.syncResources，那么会取两者的并集。\n上例中，clusterpedia 会同步 demo1 的 pods 和 confgimaps，以及 apps group 下的所有资源。\n查看资源同步状态 我们可以通过 PediaCluster 资源的 Status 来查看资源的信息，同步的资源版本和状态以及存储版本\n在 Status 中，资源会有同步版本和存储版本：\n 同步版本是 Clusterpedia 从被同步集群中获取到的资源的版本 存储版本是 Clusterpedia 存储到存储层中的版本  status:syncResources:- group:appsresources:- name:deploymentskind:Deploymentnamespaced:truesyncConditions:- lastTransitionTime:\"2022-01-13T04:34:08Z\"status:SyncingstorageVersion:v1version:v1通常集群资源的同步版本和存储版本是相同的。\n但是当接入一个比较老的集群时，集群只提供了 v1beta1 版本的 Deployment 资源，而这时资源的同步版本为 v1beta1，存储版本为 v1\n例如，同步 1.10 版本 Kubernetes 的 Deployment 时，同步状态为：\nstatus:syncResources:- group:appsresources:- name:deploymentskind:Deploymentnamespaced:truesyncConditions:- lastTransitionTime:\"2022-01-13T04:34:04Z\"status:SyncingstorageVersion:v1version:v1beta1对于自定义资源来说，同步版本和存储版本是一致的\n接下来 资源同步完成后，便可以访问 Clusterpedia来检索资源\n","categories":"","description":"","excerpt":"Clusterpedia 的主要功能，便是提供对多集群内的资源进行复杂检索。\n通过 PediaCluster 资源来指定该集群中哪些资源需要 …","ref":"/zh-cn/docs/usage/sync-resources/","tags":"","title":"同步集群资源"},{"body":"Clusterpedia has two main components:\n ClusterSynchroManager manages the PediaCluster resource in the master cluster, connects to the specified cluster through the PediaCluster authentication information, and synchronizes the corresponding resources in real time. APIServer also listens to the PediaCluster resource in the master cluster and provides complex search for resources in a compatible Kubernetes OpenAPI manner based on the resources synchronized by the cluster. Controller Manager  Also, the Clusterpedia APIServer will be registered to the master cluster APIServer in the way of Aggregation API, so that we can access Clusterpedia through the same entry as the master cluster.\nResources and Collection Resource Clusterpedia APIServer will provide two different resources to search under Group - clusterpedia.io:\nkubectl api-resources | grep clusterpedia.io # Output: NAME SHORTNAMES APIVERSION NAMESPACED KIND collectionresources clusterpedia.io/v1beta1 false CollectionResource resources clusterpedia.io/v1beta1 false Resources  Resources is used to specify a resource type to search for, compatible with Kubernetes OpenAPI CollectionResource is used to search for new resource aggregated by different types to find multiple resource types at one time   For concepts and usage about Collection Resource, refer to What is Collection Resource and Search for Collection Resource.\n Access the Clusterpedia resources When searching for a resource of a specific type, you can request it according to the Get/List specification of Kubernetes OpenAPI. In this way we can not only use the URL to access Clusterpedia resources, but also directly use kubectl or client-go to search for the resources.\nClusterpedia uses URL Path to distinguish whether the request is a multi-cluster resource or a specific cluster:\nMulti-cluster resource path, directly prefix the Resources path:\n/apis/clusterpedia.io/v1beta1/resources\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/version\" Specific cluster resource path, specify a cluster by setting the resource name based on the Resources path /apis/clusterpedia.io/v1beta1/resources/clusters/\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-1/version\" Regardless of a resource path of multiple clusters or a specific cluster, the path can be spliced and followed by Kubernetes Get/List Path\nConfigure the cluster shortcut for kubectl Although we can use URLs to access Clusterpedia resources, if we want to use kubectl to query more conveniently, we need to configure the kubeconfig cluster.\nClusterpedia provides a simple script to generate cluster config in the kubeconfig.\ncurl -sfL https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/v0.7.0/hack/gen-clusterconfigs.sh | sh - # Output: Current Context: kubernetes-admin@kubernetes Current Cluster: kubernetes Server: https://10.6.100.10:6443 TLS Server Name: Insecure Skip TLS Verify: Certificate Authority: Certificate Authority Data: *** Cluster \"clusterpedia\" set. Cluster \"cluster-1\" set. Cluster \"cluster-2\" set.  Check the script from hack/gen-clusterconfigs.sh\n The script prints the current cluster information and configures the PediaCluster into kubeconfig.\ncat ~/.kube/config # .kube/config- cluster:certificate-authority-data:LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeE1Ea3lOREV3TVRNeU5Gb1hEVE14TURreU1qRXdNVE15TkZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTy9TCnZta1U5bk1uUlRIT3lvK3hjdFRJY0lPYnMzc0F5cTI2djRQYkVtb3ZWM2xPOVQwMTF2cE96S0pyOUFxeVZMRnYKVXFBRHBTakM3WXd3MnZwSld3bDEySlBvUm1xZ1FBSFNkYlJpU3BDTDRudjlvR25VOWI2dllWSy9iRitkUVFCSApnQ1h6NnZoTGY4Wmd2N2tUQ2JBdkFPaE9OSlU3MllYTE8zT0lZQjJva1NCRGFVUjNvNnpwZGVWTkt5V0EyNVA3CkRobk8yTk01QzlpRERqTTRLY2FTa3JPSkJvbUlsSHFZRjRwVXdTTlFvcGVGRVRyZ3ZzcTkwSks2YUJVS0t5ajYKK2NGdjI3S0k4K1ZMUEtaSTE2c25Mbng2RXRTazZtZjJXTHdJZlhyQlgwREsvYXBEQ015R2pEb2dCaGpJSVhoVAp2bjVQZndFWUNsdGZFTEhKSkdVQ0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZJVDhLRHdCbUVvMHladUFEZkhkKzQ1L3ZFYzdNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBT0F5VHQ4S3ZFN0dvREhQT09pdgoyR2I2WWVsUU5KcUMza1dIOXc1NTFNaGZvS3ZiM21VaUV6ZVMwOUNwZUQrTFh5ZnlqQzhZYkJxQjZXSFhNZWMrCnpPdDNPazRYV0FmZVVZTXhOQ1FJblc4cjI4cmZnblErc1NCdHQyeERQN1RZY09oNVZGZkI2K3JtTmFTblZ1NjgKSFFxdlFMNEFXbVhkR09jRWNBRThYdkdiOWhwSjVNckRHdzQ0UTYyOG9YazZ0N01aWTFOMUNQdW9HZ1VmS1N3bgo1MUFWRTFOVVdNV0tEQXhaa2I4bEhvR3VWaDFzWmd3SnJRQjR5clh1cmxGN0Y2bVRlYm4rcDVKM0toT0V4KzlsCjFXdkwwbWkxL1J2bVJKNm11YmtjWUwzN1FJWjI1YXdyaEZMN0Z1ejNRSTFqTTdYMHZET2VUM2VuVUFCZW5SMS8KUnlnPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==server:https://10.6.100.10:6443/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-1name:cluster-1- cluster:certificate-authority-data:LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeE1Ea3lOREV3TVRNeU5Gb1hEVE14TURreU1qRXdNVE15TkZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTy9TCnZta1U5bk1uUlRIT3lvK3hjdFRJY0lPYnMzc0F5cTI2djRQYkVtb3ZWM2xPOVQwMTF2cE96S0pyOUFxeVZMRnYKVXFBRHBTakM3WXd3MnZwSld3bDEySlBvUm1xZ1FBSFNkYlJpU3BDTDRudjlvR25VOWI2dllWSy9iRitkUVFCSApnQ1h6NnZoTGY4Wmd2N2tUQ2JBdkFPaE9OSlU3MllYTE8zT0lZQjJva1NCRGFVUjNvNnpwZGVWTkt5V0EyNVA3CkRobk8yTk01QzlpRERqTTRLY2FTa3JPSkJvbUlsSHFZRjRwVXdTTlFvcGVGRVRyZ3ZzcTkwSks2YUJVS0t5ajYKK2NGdjI3S0k4K1ZMUEtaSTE2c25Mbng2RXRTazZtZjJXTHdJZlhyQlgwREsvYXBEQ015R2pEb2dCaGpJSVhoVAp2bjVQZndFWUNsdGZFTEhKSkdVQ0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZJVDhLRHdCbUVvMHladUFEZkhkKzQ1L3ZFYzdNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBT0F5VHQ4S3ZFN0dvREhQT09pdgoyR2I2WWVsUU5KcUMza1dIOXc1NTFNaGZvS3ZiM21VaUV6ZVMwOUNwZUQrTFh5ZnlqQzhZYkJxQjZXSFhNZWMrCnpPdDNPazRYV0FmZVVZTXhOQ1FJblc4cjI4cmZnblErc1NCdHQyeERQN1RZY09oNVZGZkI2K3JtTmFTblZ1NjgKSFFxdlFMNEFXbVhkR09jRWNBRThYdkdiOWhwSjVNckRHdzQ0UTYyOG9YazZ0N01aWTFOMUNQdW9HZ1VmS1N3bgo1MUFWRTFOVVdNV0tEQXhaa2I4bEhvR3VWaDFzWmd3SnJRQjR5clh1cmxGN0Y2bVRlYm4rcDVKM0toT0V4KzlsCjFXdkwwbWkxL1J2bVJKNm11YmtjWUwzN1FJWjI1YXdyaEZMN0Z1ejNRSTFqTTdYMHZET2VUM2VuVUFCZW5SMS8KUnlnPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==server:https://10.6.100.10:6443/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-2name:cluster-2- cluster:certificate-authority-data:LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeE1Ea3lOREV3TVRNeU5Gb1hEVE14TURreU1qRXdNVE15TkZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTy9TCnZta1U5bk1uUlRIT3lvK3hjdFRJY0lPYnMzc0F5cTI2djRQYkVtb3ZWM2xPOVQwMTF2cE96S0pyOUFxeVZMRnYKVXFBRHBTakM3WXd3MnZwSld3bDEySlBvUm1xZ1FBSFNkYlJpU3BDTDRudjlvR25VOWI2dllWSy9iRitkUVFCSApnQ1h6NnZoTGY4Wmd2N2tUQ2JBdkFPaE9OSlU3MllYTE8zT0lZQjJva1NCRGFVUjNvNnpwZGVWTkt5V0EyNVA3CkRobk8yTk01QzlpRERqTTRLY2FTa3JPSkJvbUlsSHFZRjRwVXdTTlFvcGVGRVRyZ3ZzcTkwSks2YUJVS0t5ajYKK2NGdjI3S0k4K1ZMUEtaSTE2c25Mbng2RXRTazZtZjJXTHdJZlhyQlgwREsvYXBEQ015R2pEb2dCaGpJSVhoVAp2bjVQZndFWUNsdGZFTEhKSkdVQ0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZJVDhLRHdCbUVvMHladUFEZkhkKzQ1L3ZFYzdNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBT0F5VHQ4S3ZFN0dvREhQT09pdgoyR2I2WWVsUU5KcUMza1dIOXc1NTFNaGZvS3ZiM21VaUV6ZVMwOUNwZUQrTFh5ZnlqQzhZYkJxQjZXSFhNZWMrCnpPdDNPazRYV0FmZVVZTXhOQ1FJblc4cjI4cmZnblErc1NCdHQyeERQN1RZY09oNVZGZkI2K3JtTmFTblZ1NjgKSFFxdlFMNEFXbVhkR09jRWNBRThYdkdiOWhwSjVNckRHdzQ0UTYyOG9YazZ0N01aWTFOMUNQdW9HZ1VmS1N3bgo1MUFWRTFOVVdNV0tEQXhaa2I4bEhvR3VWaDFzWmd3SnJRQjR5clh1cmxGN0Y2bVRlYm4rcDVKM0toT0V4KzlsCjFXdkwwbWkxL1J2bVJKNm11YmtjWUwzN1FJWjI1YXdyaEZMN0Z1ejNRSTFqTTdYMHZET2VUM2VuVUFCZW5SMS8KUnlnPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==server:https://10.6.100.10:6443/apis/clusterpedia.io/v1beta1/resourcesname:clusterpedia- cluster:certificate-authority-data:LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeE1Ea3lOREV3TVRNeU5Gb1hEVE14TURreU1qRXdNVE15TkZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTy9TCnZta1U5bk1uUlRIT3lvK3hjdFRJY0lPYnMzc0F5cTI2djRQYkVtb3ZWM2xPOVQwMTF2cE96S0pyOUFxeVZMRnYKVXFBRHBTakM3WXd3MnZwSld3bDEySlBvUm1xZ1FBSFNkYlJpU3BDTDRudjlvR25VOWI2dllWSy9iRitkUVFCSApnQ1h6NnZoTGY4Wmd2N2tUQ2JBdkFPaE9OSlU3MllYTE8zT0lZQjJva1NCRGFVUjNvNnpwZGVWTkt5V0EyNVA3CkRobk8yTk01QzlpRERqTTRLY2FTa3JPSkJvbUlsSHFZRjRwVXdTTlFvcGVGRVRyZ3ZzcTkwSks2YUJVS0t5ajYKK2NGdjI3S0k4K1ZMUEtaSTE2c25Mbng2RXRTazZtZjJXTHdJZlhyQlgwREsvYXBEQ015R2pEb2dCaGpJSVhoVAp2bjVQZndFWUNsdGZFTEhKSkdVQ0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZJVDhLRHdCbUVvMHladUFEZkhkKzQ1L3ZFYzdNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBT0F5VHQ4S3ZFN0dvREhQT09pdgoyR2I2WWVsUU5KcUMza1dIOXc1NTFNaGZvS3ZiM21VaUV6ZVMwOUNwZUQrTFh5ZnlqQzhZYkJxQjZXSFhNZWMrCnpPdDNPazRYV0FmZVVZTXhOQ1FJblc4cjI4cmZnblErc1NCdHQyeERQN1RZY09oNVZGZkI2K3JtTmFTblZ1NjgKSFFxdlFMNEFXbVhkR09jRWNBRThYdkdiOWhwSjVNckRHdzQ0UTYyOG9YazZ0N01aWTFOMUNQdW9HZ1VmS1N3bgo1MUFWRTFOVVdNV0tEQXhaa2I4bEhvR3VWaDFzWmd3SnJRQjR5clh1cmxGN0Y2bVRlYm4rcDVKM0toT0V4KzlsCjFXdkwwbWkxL1J2bVJKNm11YmtjWUwzN1FJWjI1YXdyaEZMN0Z1ejNRSTFqTTdYMHZET2VUM2VuVUFCZW5SMS8KUnlnPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==server:https://10.6.100.10:6443name:kubernetesThe script generates clusterpedia clusters for multi-cluster access and other cluster configs in the name of PediaCluster, and reuses the master cluster’s entry and authentication information when accessing Clusterpedia.\nCompared with the master cluster entry, it only adds Clusterpedia Resources path.\nAfter multi-cluster kubeconfig is generated, you can use kubectl --cluster to specify the cluster access\n# Supported resources for multi-cluster search kubectl --cluster clusterpedia api-resources # Supported resources for cluster-1 search kubectl --cluster cluster-1 api-resources What resources are supported for search We can get the global and specific resource information according to the URL path.\nGlobal resource information is the union of resource types that are synchronized across all clusters\nDiscovery API opened by Clusterpedia is similary compatible with Kubernetes OpenAPI. You can use kubectl, client-go/discovery, client-go/restmapper or controller-runtime/dynamic-restmapper to access it.\nURL kubectl Use URL to get APIGroupList and APIGroup information\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis\" | jq { \"kind\": \"APIGroupList\", \"apiVersion\": \"v1\", \"groups\": [ { \"name\": \"apps\", \"versions\": [ { \"groupVersion\": \"apps/v1\", \"version\": \"v1\" }, { \"groupVersion\": \"apps/v1beta2\", \"version\": \"v1beta2\" }, { \"groupVersion\": \"apps/v1beta1\", \"version\": \"v1beta1\" } ], \"preferredVersion\": { \"groupVersion\": \"apps/v1\", \"version\": \"v1\" } }, { \"name\": \"cert-manager.io\", \"versions\": [ { \"groupVersion\": \"cert-manager.io/v1\", \"version\": \"v1\" } ], \"preferredVersion\": { \"groupVersion\": \"cert-manager.io/v1\", \"version\": \"v1\" } } ] } kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps\" | jq { \"kind\": \"APIGroup\", \"apiVersion\": \"v1\", \"name\": \"apps\", \"versions\": [ { \"groupVersion\": \"apps/v1\", \"version\": \"v1\" }, { \"groupVersion\": \"apps/v1beta2\", \"version\": \"v1beta2\" }, { \"groupVersion\": \"apps/v1beta1\", \"version\": \"v1beta1\" } ], \"preferredVersion\": { \"groupVersion\": \"apps/v1\", \"version\": \"v1\" } }  Use kubectl to get api-resources\nkubectl --cluster clusterpedia api-resources # Output: NAME SHORTNAMES APIVERSION NAMESPACED KIND configmaps cm v1 true ConfigMap namespaces ns v1 false Namespace nodes no v1 false Node pods po v1 true Pod secrets v1 true Secret daemonsets ds apps/v1 true DaemonSet deployments deploy apps/v1 true Deployment replicasets rs apps/v1 true ReplicaSet issuers cert-manager.io/v1 true Issuer  ","categories":"","description":"","excerpt":"Clusterpedia has two main components:\n ClusterSynchroManager manages …","ref":"/docs/usage/access-clusterpedia/","tags":"","title":"Access the Clusterpedia"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/installation/helm/","tags":"","title":"Helm"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh-cn/docs/installation/helm/","tags":"","title":"使用 Helm"},{"body":"Clusterpedia 主要有两个组件：\n ClusterSynchroManager 管理 主集群 内的 PediaCluster 资源，通过 PediaCluster 配置认证信息连接到指定集群，并且实时同步相应的资源。 APIServer 同样会监听 主集群 内的 PediaCluster 资源，并根据集群同步的资源以兼容 Kubernetes OpenAPI的方式来提供对资源的复杂检索。 ControllerManager  并且 Clusterpedia APIServer 会以聚合式 API 的方式注册到 主集群 的 APIServer 中， 这样我们通过和主集群相同的入口便可访问 Clusterpedia\nResources 和聚合资源 Clusterpedia APIServer 会在 Group —— clusterpedia.io 下提供两种检索资源：\nkubectl api-resources | grep clusterpedia.io # 输出： NAME SHORTNAMES APIVERSION NAMESPACED KIND collectionresources clusterpedia.io/v1beta1 false CollectionResource resources clusterpedia.io/v1beta1 false Resources  Resources 用于指定资源类型的方式来检索，在使用上兼容 Kubernetes OpenAPI CollectionResource 用于检索由多个资源类型聚合而成的新的资源类型，以达到同时检索多种资源的目的   对于 Collection Resource 的概念和使用可以查看 什么是聚合资源（Collection Resource），聚合资源（Collection Resource）检索\n 访问 Clusterpedia 资源 在检索指定类型的资源时，可以按照 Kubernetes OpenAPI 的 Get/List 规范来请求， 这样我们不仅仅可以使用 URL 来访问 Clusterpedia Resources，还可以直接使用 kubectl 或者 client-go 来检索资源。\nClusterpedia 通过 URL Path 来区分请求是多集群资源还是指定集群：\n多集群资源路径 直接以 Resources 资源路径为前缀 /apis/clusterpedia.io/v1beta1/resources\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/version\" 指定集群资源路径 在 Resources 资源路径的基础上设置资源名称来指定集群 /apis/clusterpedia.io/v1beta1/resources/clusters/\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-1/version\" 无论是多集群资源路径还是指定集群的资源路径，都可以在路径后拼接 Kubernetes 的 Get/List Path\n为 kubectl 生成集群访问的快捷配置 尽管我们可以使用 URL 来访问 Clusterpedia 资源，但是如果想要更方便的使用 kubectl 来查询的话，就需要配置集群的 kubeconfig cluster 配置。\nClusterpedia 提供了一个简单的脚本来帮助生成 cluster kube config\ncurl -sfL https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/v0.7.0/hack/gen-clusterconfigs.sh | sh - # 输出： Current Context: kubernetes-admin@kubernetes Current Cluster: kubernetes Server: https://10.6.100.10:6443 TLS Server Name: Insecure Skip TLS Verify: Certificate Authority: Certificate Authority Data: *** Cluster \"clusterpedia\" set. Cluster \"cluster-1\" set. Cluster \"cluster-2\" set.  可以在 hack/gen-clusterconfigs.sh 找到该脚本\n 脚本会打印当前的集群信息，并将集群中 PediaCluster 配置到 kubeconfig 中。\ncat ~/.kube/config # .kube/config- cluster:certificate-authority-data:LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeE1Ea3lOREV3TVRNeU5Gb1hEVE14TURreU1qRXdNVE15TkZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTy9TCnZta1U5bk1uUlRIT3lvK3hjdFRJY0lPYnMzc0F5cTI2djRQYkVtb3ZWM2xPOVQwMTF2cE96S0pyOUFxeVZMRnYKVXFBRHBTakM3WXd3MnZwSld3bDEySlBvUm1xZ1FBSFNkYlJpU3BDTDRudjlvR25VOWI2dllWSy9iRitkUVFCSApnQ1h6NnZoTGY4Wmd2N2tUQ2JBdkFPaE9OSlU3MllYTE8zT0lZQjJva1NCRGFVUjNvNnpwZGVWTkt5V0EyNVA3CkRobk8yTk01QzlpRERqTTRLY2FTa3JPSkJvbUlsSHFZRjRwVXdTTlFvcGVGRVRyZ3ZzcTkwSks2YUJVS0t5ajYKK2NGdjI3S0k4K1ZMUEtaSTE2c25Mbng2RXRTazZtZjJXTHdJZlhyQlgwREsvYXBEQ015R2pEb2dCaGpJSVhoVAp2bjVQZndFWUNsdGZFTEhKSkdVQ0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZJVDhLRHdCbUVvMHladUFEZkhkKzQ1L3ZFYzdNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBT0F5VHQ4S3ZFN0dvREhQT09pdgoyR2I2WWVsUU5KcUMza1dIOXc1NTFNaGZvS3ZiM21VaUV6ZVMwOUNwZUQrTFh5ZnlqQzhZYkJxQjZXSFhNZWMrCnpPdDNPazRYV0FmZVVZTXhOQ1FJblc4cjI4cmZnblErc1NCdHQyeERQN1RZY09oNVZGZkI2K3JtTmFTblZ1NjgKSFFxdlFMNEFXbVhkR09jRWNBRThYdkdiOWhwSjVNckRHdzQ0UTYyOG9YazZ0N01aWTFOMUNQdW9HZ1VmS1N3bgo1MUFWRTFOVVdNV0tEQXhaa2I4bEhvR3VWaDFzWmd3SnJRQjR5clh1cmxGN0Y2bVRlYm4rcDVKM0toT0V4KzlsCjFXdkwwbWkxL1J2bVJKNm11YmtjWUwzN1FJWjI1YXdyaEZMN0Z1ejNRSTFqTTdYMHZET2VUM2VuVUFCZW5SMS8KUnlnPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==server:https://10.6.100.10:6443/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-1name:cluster-1- cluster:certificate-authority-data:LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeE1Ea3lOREV3TVRNeU5Gb1hEVE14TURreU1qRXdNVE15TkZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTy9TCnZta1U5bk1uUlRIT3lvK3hjdFRJY0lPYnMzc0F5cTI2djRQYkVtb3ZWM2xPOVQwMTF2cE96S0pyOUFxeVZMRnYKVXFBRHBTakM3WXd3MnZwSld3bDEySlBvUm1xZ1FBSFNkYlJpU3BDTDRudjlvR25VOWI2dllWSy9iRitkUVFCSApnQ1h6NnZoTGY4Wmd2N2tUQ2JBdkFPaE9OSlU3MllYTE8zT0lZQjJva1NCRGFVUjNvNnpwZGVWTkt5V0EyNVA3CkRobk8yTk01QzlpRERqTTRLY2FTa3JPSkJvbUlsSHFZRjRwVXdTTlFvcGVGRVRyZ3ZzcTkwSks2YUJVS0t5ajYKK2NGdjI3S0k4K1ZMUEtaSTE2c25Mbng2RXRTazZtZjJXTHdJZlhyQlgwREsvYXBEQ015R2pEb2dCaGpJSVhoVAp2bjVQZndFWUNsdGZFTEhKSkdVQ0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZJVDhLRHdCbUVvMHladUFEZkhkKzQ1L3ZFYzdNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBT0F5VHQ4S3ZFN0dvREhQT09pdgoyR2I2WWVsUU5KcUMza1dIOXc1NTFNaGZvS3ZiM21VaUV6ZVMwOUNwZUQrTFh5ZnlqQzhZYkJxQjZXSFhNZWMrCnpPdDNPazRYV0FmZVVZTXhOQ1FJblc4cjI4cmZnblErc1NCdHQyeERQN1RZY09oNVZGZkI2K3JtTmFTblZ1NjgKSFFxdlFMNEFXbVhkR09jRWNBRThYdkdiOWhwSjVNckRHdzQ0UTYyOG9YazZ0N01aWTFOMUNQdW9HZ1VmS1N3bgo1MUFWRTFOVVdNV0tEQXhaa2I4bEhvR3VWaDFzWmd3SnJRQjR5clh1cmxGN0Y2bVRlYm4rcDVKM0toT0V4KzlsCjFXdkwwbWkxL1J2bVJKNm11YmtjWUwzN1FJWjI1YXdyaEZMN0Z1ejNRSTFqTTdYMHZET2VUM2VuVUFCZW5SMS8KUnlnPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==server:https://10.6.100.10:6443/apis/clusterpedia.io/v1beta1/resources/clusters/cluster-2name:cluster-2- cluster:certificate-authority-data:LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeE1Ea3lOREV3TVRNeU5Gb1hEVE14TURreU1qRXdNVE15TkZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTy9TCnZta1U5bk1uUlRIT3lvK3hjdFRJY0lPYnMzc0F5cTI2djRQYkVtb3ZWM2xPOVQwMTF2cE96S0pyOUFxeVZMRnYKVXFBRHBTakM3WXd3MnZwSld3bDEySlBvUm1xZ1FBSFNkYlJpU3BDTDRudjlvR25VOWI2dllWSy9iRitkUVFCSApnQ1h6NnZoTGY4Wmd2N2tUQ2JBdkFPaE9OSlU3MllYTE8zT0lZQjJva1NCRGFVUjNvNnpwZGVWTkt5V0EyNVA3CkRobk8yTk01QzlpRERqTTRLY2FTa3JPSkJvbUlsSHFZRjRwVXdTTlFvcGVGRVRyZ3ZzcTkwSks2YUJVS0t5ajYKK2NGdjI3S0k4K1ZMUEtaSTE2c25Mbng2RXRTazZtZjJXTHdJZlhyQlgwREsvYXBEQ015R2pEb2dCaGpJSVhoVAp2bjVQZndFWUNsdGZFTEhKSkdVQ0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZJVDhLRHdCbUVvMHladUFEZkhkKzQ1L3ZFYzdNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBT0F5VHQ4S3ZFN0dvREhQT09pdgoyR2I2WWVsUU5KcUMza1dIOXc1NTFNaGZvS3ZiM21VaUV6ZVMwOUNwZUQrTFh5ZnlqQzhZYkJxQjZXSFhNZWMrCnpPdDNPazRYV0FmZVVZTXhOQ1FJblc4cjI4cmZnblErc1NCdHQyeERQN1RZY09oNVZGZkI2K3JtTmFTblZ1NjgKSFFxdlFMNEFXbVhkR09jRWNBRThYdkdiOWhwSjVNckRHdzQ0UTYyOG9YazZ0N01aWTFOMUNQdW9HZ1VmS1N3bgo1MUFWRTFOVVdNV0tEQXhaa2I4bEhvR3VWaDFzWmd3SnJRQjR5clh1cmxGN0Y2bVRlYm4rcDVKM0toT0V4KzlsCjFXdkwwbWkxL1J2bVJKNm11YmtjWUwzN1FJWjI1YXdyaEZMN0Z1ejNRSTFqTTdYMHZET2VUM2VuVUFCZW5SMS8KUnlnPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==server:https://10.6.100.10:6443/apis/clusterpedia.io/v1beta1/resourcesname:clusterpedia- cluster:certificate-authority-data:LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeE1Ea3lOREV3TVRNeU5Gb1hEVE14TURreU1qRXdNVE15TkZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTy9TCnZta1U5bk1uUlRIT3lvK3hjdFRJY0lPYnMzc0F5cTI2djRQYkVtb3ZWM2xPOVQwMTF2cE96S0pyOUFxeVZMRnYKVXFBRHBTakM3WXd3MnZwSld3bDEySlBvUm1xZ1FBSFNkYlJpU3BDTDRudjlvR25VOWI2dllWSy9iRitkUVFCSApnQ1h6NnZoTGY4Wmd2N2tUQ2JBdkFPaE9OSlU3MllYTE8zT0lZQjJva1NCRGFVUjNvNnpwZGVWTkt5V0EyNVA3CkRobk8yTk01QzlpRERqTTRLY2FTa3JPSkJvbUlsSHFZRjRwVXdTTlFvcGVGRVRyZ3ZzcTkwSks2YUJVS0t5ajYKK2NGdjI3S0k4K1ZMUEtaSTE2c25Mbng2RXRTazZtZjJXTHdJZlhyQlgwREsvYXBEQ015R2pEb2dCaGpJSVhoVAp2bjVQZndFWUNsdGZFTEhKSkdVQ0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZJVDhLRHdCbUVvMHladUFEZkhkKzQ1L3ZFYzdNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBT0F5VHQ4S3ZFN0dvREhQT09pdgoyR2I2WWVsUU5KcUMza1dIOXc1NTFNaGZvS3ZiM21VaUV6ZVMwOUNwZUQrTFh5ZnlqQzhZYkJxQjZXSFhNZWMrCnpPdDNPazRYV0FmZVVZTXhOQ1FJblc4cjI4cmZnblErc1NCdHQyeERQN1RZY09oNVZGZkI2K3JtTmFTblZ1NjgKSFFxdlFMNEFXbVhkR09jRWNBRThYdkdiOWhwSjVNckRHdzQ0UTYyOG9YazZ0N01aWTFOMUNQdW9HZ1VmS1N3bgo1MUFWRTFOVVdNV0tEQXhaa2I4bEhvR3VWaDFzWmd3SnJRQjR5clh1cmxGN0Y2bVRlYm4rcDVKM0toT0V4KzlsCjFXdkwwbWkxL1J2bVJKNm11YmtjWUwzN1FJWjI1YXdyaEZMN0Z1ejNRSTFqTTdYMHZET2VUM2VuVUFCZW5SMS8KUnlnPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==server:https://10.6.100.10:6443name:kubernetes脚本生成了用于多集群访问的 clusterpedia cluster 以及其他 PediaCluster Name 命名的 cluster config， 而且在访问 Clusterpedia 时会复用主集群的入口以及认证信息，相比主集群入口只是增加了 Clusterpedia Resources 的 path。\n多集群的 kubeconfig 信息生成完成后，就可以使用 kubectl --cluster 来指定集群访问了\n# 多集群检索时支持的资源 kubectl --cluster clusterpedia api-resources # cluster-1 支持检索的资源 kubectl --cluster cluster-1 api-resources 查看支持检索的资源类型 我们可以根据 URL 路径来分别获取全局资源信息和指定集群的资源信息。\n全局资源信息是所有集群同步的资源类型的并集。\nClusterpedia 开放的 Discovery API 同样兼容 Kubernetes OpenAPI，可以使用 kubectl，client-go/discovery，client-go/restmapper 或者 controller-runtime/dynamic-restmapper 来访问。\nURL kubectl 使用 URL 来获取 APIGroupList 以及 APIGroup 信息\nkubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis\" | jq { \"kind\": \"APIGroupList\", \"apiVersion\": \"v1\", \"groups\": [ { \"name\": \"apps\", \"versions\": [ { \"groupVersion\": \"apps/v1\", \"version\": \"v1\" }, { \"groupVersion\": \"apps/v1beta2\", \"version\": \"v1beta2\" }, { \"groupVersion\": \"apps/v1beta1\", \"version\": \"v1beta1\" } ], \"preferredVersion\": { \"groupVersion\": \"apps/v1\", \"version\": \"v1\" } }, { \"name\": \"cert-manager.io\", \"versions\": [ { \"groupVersion\": \"cert-manager.io/v1\", \"version\": \"v1\" } ], \"preferredVersion\": { \"groupVersion\": \"cert-manager.io/v1\", \"version\": \"v1\" } } ] } kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps\" | jq { \"kind\": \"APIGroup\", \"apiVersion\": \"v1\", \"name\": \"apps\", \"versions\": [ { \"groupVersion\": \"apps/v1\", \"version\": \"v1\" }, { \"groupVersion\": \"apps/v1beta2\", \"version\": \"v1beta2\" }, { \"groupVersion\": \"apps/v1beta1\", \"version\": \"v1beta1\" } ], \"preferredVersion\": { \"groupVersion\": \"apps/v1\", \"version\": \"v1\" } }  使用 kubectl 来获取 api-resources\nkubectl --cluster clusterpedia api-resources # 输出： NAME SHORTNAMES APIVERSION NAMESPACED KIND configmaps cm v1 true ConfigMap namespaces ns v1 false Namespace nodes no v1 false Node pods po v1 true Pod secrets v1 true Secret daemonsets ds apps/v1 true DaemonSet deployments deploy apps/v1 true Deployment replicasets rs apps/v1 true ReplicaSet issuers cert-manager.io/v1 true Issuer  ","categories":"","description":"","excerpt":"Clusterpedia 主要有两个组件：\n ClusterSynchroManager 管理 主集群 内的 PediaCluster 资 …","ref":"/zh-cn/docs/usage/access-clusterpedia/","tags":"","title":"访问 Clusterpedia"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/usage/","tags":"","title":"Usage"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh-cn/docs/usage/","tags":"","title":"使用"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/advanced-features/","tags":"","title":"Advanced Features"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh-cn/docs/advanced-features/","tags":"","title":"高级功能"},{"body":"When using feature functionality, users need to enabled the corresponding feature gates.\nFor example, enable SyncAllResources of clustersynchro manager to allow the user of All-resources Wildcard\n# ignore other flags ./bin/clustersynchro-manager --feature-gates=SyncAllResources=true Clusterpedia APIServer and Clusterpedia ClusterSynchro Manager have different feature gates.\nAPIServer    desc feature gate default     Set the default to return the number of resources remaining RemainingItemCount false   Raw SQl Query AllowRawSQLQuery false    ClusterSynchro Manager    desc feature gate default     Prune metadata.managedFields PruneManagedFields true   Prune metadata.annotations['lastAppliedConfiguration'] PruneLastAppliedConfiguration true   Allows synchronization of all types of custom resources AllowSyncCustomResources false   Allows synchronization of all types of resources AllowSyncAllResources false   Use standalone tcp for health checker HealthCheckerWithStandaloneTCP false    ","categories":"","description":"","excerpt":"When using feature functionality, users need to enabled the …","ref":"/docs/features/","tags":"","title":"Features"},{"body":"用户在使用特性功能时，需要开启相应的特性门控。 例如开启 clustersynchro manager 的 SyncAllResources 来允许使用 全资源通配符\n# 忽略其他参数 ./bin/clustersynchro-manager --feature-gates=SyncAllResources=true Clusterpedia APIServer 和 Clusterpedia ClusterSynchro Manager 分别具有不同的特性门控\nAPIServer    作用 feature gate 默认值     设置默认返回剩余的资源数量 RemainingItemCount false   原生 SQL 查询 AllowRawSQLQuery false    ClusterSynchro Manager    作用 feature gate 默认值     裁剪 metadata.managedFields 字段 PruneManagedFields true   裁剪 metadata.annotations['lastAppliedConfiguration'] 字段 PruneLastAppliedConfiguration true   允许同步所有类型的自定义资源 AllowSyncCustomResources false   允许同步所有类型的资源 AllowSyncAllResources false   集群健康检查使用独立 TCP 连接 HealthCheckerWithStandaloneTCP false    ","categories":"","description":"","excerpt":"用户在使用特性功能时，需要开启相应的特性门控。 例如开启 clustersynchro manager 的 SyncAllResources …","ref":"/zh-cn/docs/features/","tags":"","title":"特性功能"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/","tags":"","title":"Blog"},{"body":"After 0.4.0, Clusterpedia provides a more friendly way to interface to multi-cloud platforms, Users simply create or join clusters in the multi-cloud platform and then use Clusterpedia to retrieve the resources within those clusters directly .\n We maintain ClusterImportPolicy for each multi-cloud platform in the Clusterpedia repository. You are very welcome to submit ClusterImportPolicy to Clusterpedia for interfacing to other multi-cloud platforms.\nAfter installing Clusterpedia, you can create the appropriate ClusterImportPolicy, or you can create a new ClusterImportPolicy according to your needs (multi-cloud platform).\n The ClusterImportPolicy for the Cluster API has been submitted in clusterpedia#288. After creating clusters in the Cluster API, you can use Clusterpedia directly to do complex searches of resources within these clusters.\n$ kubectl get cluster NAME PHASE AGE VERSION capi-quickstart Provisioned 10m v1.24.2 capi-quickstart-2 Provisioned 118s v1.24.2 $ kubectl get kubeadmcontrolplane NAME CLUSTER INITIALIZED API SERVER AVAILABLE REPLICAS READY UPDATED UNAVAILABLE AGE VERSION capi-quickstart-2-ctm9k capi-quickstart-2 true 1 1 1 10m v1.24.2 capi-quickstart-2xcsz capi-quickstart true 1 1 1 19m v1.24.2 $ # the pediacluster resources will automatically create, updates or delete based on cluster resources $ kubectl get pediacluster -o wide NAME READY VERSION APISERVER VALIDATED SYNCHRORUNNING CLUSTERHEALTHY default-capi-quickstart True v1.24.2 Validated Running Healthy default-capi-quickstart-2 True v1.24.2 Validated Running Healthy $ kubectl --cluster clusterpedia get no CLUSTER NAME STATUS ROLES AGE VERSION default-capi-quickstart-2 capi-quickstart-2-ctm9k-g2m87 NotReady control-plane 12m v1.24.2 default-capi-quickstart-2 capi-quickstart-2-md-0-s8hbx-7bd44554b5-kzcb6 NotReady \u003cnone\u003e 11m v1.24.2 default-capi-quickstart capi-quickstart-2xcsz-fxrrk NotReady control-plane 21m v1.24.2 default-capi-quickstart capi-quickstart-md-0-9tw2g-b8b4f46cf-gggvq NotReady \u003cnone\u003e 20m v1.24.2 Quickly deploy a sample environment for Cluster API and Clusterpedia Prerequisites  Install and setup kubectl in your local environment Install Kind and Docker Install clusterctl   Minimum kind supported version: v0.14.0\n Create a management cluster and deploy the Cluster API  Deploying the Cluster API can also be found in https://cluster-api.sigs.k8s.io/user/quick-start.html\n $ cat \u003e kind-cluster-with-extramounts.yaml \u003c\u003cEOF kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 nodes: - role: control-plane extraMounts: - hostPath: /var/run/docker.sock containerPath: /var/run/docker.sock EOF $ kind create cluster --name capi-sample --config kind-cluster-with-extramounts.yaml $ export CLUSTER_TOPOLOGY=true $ clusterctl init --infrastructure docker Deploy Clusterpedia $ git clone https://github.com/clusterpedia-io/clusterpedia.git \u0026\u0026 cd clusterpedia/charts $ helm install clusterpedia . \\  --namespace clusterpedia-system \\  --create-namespace \\  --set installCRDs=true \\  # --set persistenceMatchNode={{ LOCAL_PV_NODE }} --set persistenceMatchNode=capi-sample-control-plane  The Clusterpedia Chart creates a local pv for the storage component, but you need to specify the node using the persistenceMatchNode option, eg. –set persistenceMatchNode=master-1.\nIf you don’t need to create a local pv, add the –set persistenceMatchNode=None flag. Lean More\n Create ClusterImportPolicy for interfacing to the Cluster API\n$ kubectl apply -f https://raw.githubusercontent.com/Iceber/clusterpedia/add_cluster_api_clusterimportpolicy/deploy/clusterimportpolicy/cluster_api.yaml  Clusterpedia can be integrated into any multi-cloud management platform, Lean More\n Gen cluster shortcut for kubectl, If you use client-go or OpenAPI to access, you can omit this step\n$ curl -sfL https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/main/hack/gen-clusterconfigs.sh | sh - $ # Using kubectl to retrieve multicluster resources, the current Cluster API does not create a cluster, so it returns null $ kubectl --cluster clusterpedia api-resources Create a cluster using the Cluster API  When using the sample environments' Docker Provider to create a cluster, you need to add --flavor development flag.\n $ clusterctl generate cluster capi-quickstart --flavor development \\  --kubernetes-version v1.24.2 \\  --control-plane-machine-count=1 \\  --worker-machine-count=1 \\  \u003e capi-quickstart.yaml $ kubectl apply -f ./capi-quickstart.yaml View cluster creation status $ kubectl get cluster NAME PHASE AGE VERSION capi-quickstart Provisioned 8s v1.24.2 $ kubectl get kubeadmcontrolplane -w NAME CLUSTER INITIALIZED API SERVER AVAILABLE REPLICAS READY UPDATED UNAVAILABLE AGE VERSION capi-quickstart-2xcsz capi-quickstart true 1 1 1 86s v1.24.2 when kubeadmcontrolplane’s Initialized is true, lusterpedia will automatically synchronize the resources in the cluster, you can use kubectl --cluster clusterpedia get to search the resources.\n$ kubectl get pediacluster NAME READY VERSION APISERVER default-capi-quickstart True v1.24.2 $ kubectl --cluster clusterpedia get pod -A NAMESPACE CLUSTER NAME READY STATUS RESTARTS AGE kube-system default-capi-quickstart kube-apiserver-capi-quickstart-2xcsz-fxrrk 1/1 Running 0 2m32s kube-system default-capi-quickstart kube-scheduler-capi-quickstart-2xcsz-fxrrk 1/1 Running 0 2m31s kube-system default-capi-quickstart coredns-6d4b75cb6d-lrwj4 0/1 Pending 0 2m20s kube-system default-capi-quickstart kube-proxy-p8v9m 1/1 Running 0 2m20s kube-system default-capi-quickstart kube-controller-manager-capi-quickstart-2xcsz-fxrrk 1/1 Running 0 2m32s kube-system default-capi-quickstart etcd-capi-quickstart-2xcsz-fxrrk 1/1 Running 0 2m32s kube-system default-capi-quickstart kube-proxy-2ln2w 1/1 Running 0 105s kube-system default-capi-quickstart coredns-6d4b75cb6d-2hcmz 0/1 Pending 0 2m20s The cluster-api clusterimportpolicy sets the resources to be synchronized by default in the cluster.\nUsers can also manually modify the configuration of synchronization in pediacluster, Synchronize Cluster Resources\nWhen the cluster is deleted in the Cluster API, Clusterpedia also deletes PeidaCluster at the same time.\nResources retrieval for multiple clusters Use the above steps to create multiple clusters\n$ kubectl get cluster NAME PHASE AGE VERSION capi-quickstart Provisioned 10m v1.24.2 capi-quickstart-2 Provisioned 118s v1.24.2 $ kubectl get kubeadmcontrolplane NAME CLUSTER INITIALIZED API SERVER AVAILABLE REPLICAS READY UPDATED UNAVAILABLE AGE VERSION capi-quickstart-2-ctm9k capi-quickstart-2 true 1 1 1 10m v1.24.2 capi-quickstart-2xcsz capi-quickstart true 1 1 1 19m v1.24.2 $ # the pediacluster resources will automatically create, updates or delete based on cluster resources $ kubectl get pediacluster -o wide NAME READY VERSION APISERVER VALIDATED SYNCHRORUNNING CLUSTERHEALTHY default-capi-quickstart True v1.24.2 Validated Running Healthy default-capi-quickstart-2 True v1.24.2 Validated Running Healthy $ kubectl --cluster clusterpedia get no CLUSTER NAME STATUS ROLES AGE VERSION default-capi-quickstart-2 capi-quickstart-2-ctm9k-g2m87 NotReady control-plane 12m v1.24.2 default-capi-quickstart-2 capi-quickstart-2-md-0-s8hbx-7bd44554b5-kzcb6 NotReady \u003cnone\u003e 11m v1.24.2 default-capi-quickstart capi-quickstart-2xcsz-fxrrk NotReady control-plane 21m v1.24.2 default-capi-quickstart capi-quickstart-md-0-9tw2g-b8b4f46cf-gggvq NotReady \u003cnone\u003e 20m v1.24.2 Clusterpedia supports two types of resource search:\n$ kubectl api-resources | grep clusterpedia.io collectionresources clusterpedia.io/v1beta1 false CollectionResource resources clusterpedia.io/v1beta1 false Resources  Resources that are compatible with Kubernetes OpenAPI  $ kubectl --cluster clusterpedia get cm -A NAMESPACE CLUSTER NAME DATA AGE kube-system default-capi-quickstart extension-apiserver-authentication 6 19m kube-system default-capi-quickstart kubeadm-config 1 19m kube-public default-capi-quickstart cluster-info 2 19m kube-system default-capi-quickstart kube-proxy 2 19m kube-node-lease default-capi-quickstart kube-root-ca.crt 1 19m kube-system default-capi-quickstart-2 extension-apiserver-authentication 6 10m kube-system default-capi-quickstart kubelet-config 1 19m kube-system default-capi-quickstart coredns 1 19m kube-system default-capi-quickstart kube-root-ca.crt 1 19m kube-public default-capi-quickstart kube-root-ca.crt 1 19m kube-system default-capi-quickstart-2 coredns 1 10m default default-capi-quickstart kube-root-ca.crt 1 19m kube-system default-capi-quickstart-2 kube-proxy 2 10m kube-system default-capi-quickstart-2 kubeadm-config 1 10m kube-system default-capi-quickstart-2 kubelet-config 1 10m kube-system default-capi-quickstart-2 kube-root-ca.crt 1 10m kube-node-lease default-capi-quickstart-2 kube-root-ca.crt 1 10m kube-public default-capi-quickstart-2 cluster-info 3 10m kube-public default-capi-quickstart-2 kube-root-ca.crt 1 10m default default-capi-quickstart-2 kube-root-ca.crt 1 10m $ # gen cluster shortcuts $ curl -sfL https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/main/hack/gen-clusterconfigs.sh | sh - $ kubectl --cluster default-capi-quickstart get cm -n kube-system  Collection Resource  Clusterpedia can also perform more advanced aggregation of resources. For example, you can use Collection Resource to get a set of different resources at once.\n$ kubectl get collectionresources NAME RESOURCES any * workloads apps.deployments,apps.daemonsets,apps.statefulsets kuberesources .*,admission.k8s.io.*,admissionregistration.k8s.io.*,apiextensions.k8s.io.*,apps.*,authentication.k8s.io.*,authorization.k8s.io.*,autoscaling.*,batch.*,certificates.k8s.io.*,coordination.k8s.io.*,discovery.k8s.io.*,events.k8s.io.*,extensions.*,flowcontrol.apiserver.k8s.io.*,imagepolicy.k8s.io.*,internal.apiserver.k8s.io.*,networking.k8s.io.*,node.k8s.io.*,policy.*,rbac.authorization.k8s.io.*,scheduling.k8s.io.*,storage.k8s.io.* $ kubectl get collectionresources workloads Search  Search by metadata(clusters, namespaces, resource names, creation time interval  $ kubectl --cluster clusterpedia get cm -A -l \\  \"search.clusterpedia.io/clusters in (default-capi-quickstart,default-capi-quickstart-2),\\ search.clusterpedia.io/namespaces in (kube-system,default)\" NAMESPACE CLUSTER NAME DATA AGE kube-system default-capi-quickstart extension-apiserver-authentication 6 23m kube-system default-capi-quickstart kubeadm-config 1 23m kube-system default-capi-quickstart kube-proxy 2 23m kube-system default-capi-quickstart-2 extension-apiserver-authentication 6 14m kube-system default-capi-quickstart kubelet-config 1 23m kube-system default-capi-quickstart coredns 1 23m kube-system default-capi-quickstart kube-root-ca.crt 1 23m kube-system default-capi-quickstart-2 coredns 1 14m default default-capi-quickstart kube-root-ca.crt 1 23m kube-system default-capi-quickstart-2 kube-proxy 2 14m kube-system default-capi-quickstart-2 kubeadm-config 1 14m kube-system default-capi-quickstart-2 kubelet-config 1 14m kube-system default-capi-quickstart-2 kube-root-ca.crt 1 14m default default-capi-quickstart-2 kube-root-ca.crt 1 14m  Fuzzy Search Enhanced Field Selector Search by Parent or Ancestor Owner Paging and Sorting Advanced Search  ","categories":"","description":"","excerpt":"After 0.4.0, Clusterpedia provides a more friendly way to interface to …","ref":"/blog/2022/08/04/cluster-api-searching-has-never-been-easier/","tags":"","title":"Cluster API Searching Has Never Been Easier"},{"body":"0.4.0 后，Clusterpedia 提供了更加友好的接入多云平台的方式，用户在多云平台创建或者纳管集群后，便可以直接使用 kubectl 来检索这些集群内的资源。\n 我们在 Clusterpedia 仓库 中维护了各个多云平台的 ClusterImportPolicy。 非常欢迎大家提交用于对接其他多云平台的 ClusterImportPolicy。\n用户在安装 Clusterpedia 后，创建合适的 ClusterImportPolicy 即可，用户也可以根据自己的需求来创建新的 ClusterImportPolicy\n Cluster API 的 ClusterImportPolicy 已经在 clusterpedia#288 中提交, 在 Cluster API 中创建集群后，可以直接使用 Clusterpedia 来对这些集群内的资源进行复杂检索。\n$ kubectl get cluster NAME PHASE AGE VERSION capi-quickstart Provisioned 10m v1.24.2 capi-quickstart-2 Provisioned 118s v1.24.2 $ kubectl get kubeadmcontrolplane NAME CLUSTER INITIALIZED API SERVER AVAILABLE REPLICAS READY UPDATED UNAVAILABLE AGE VERSION capi-quickstart-2-ctm9k capi-quickstart-2 true 1 1 1 10m v1.24.2 capi-quickstart-2xcsz capi-quickstart true 1 1 1 19m v1.24.2 $ # pediacluster 会根据 cluster 资源自动创建，更新和删除 $ kubectl get pediacluster -o wide NAME READY VERSION APISERVER VALIDATED SYNCHRORUNNING CLUSTERHEALTHY default-capi-quickstart True v1.24.2 Validated Running Healthy default-capi-quickstart-2 True v1.24.2 Validated Running Healthy $ kubectl --cluster clusterpedia get no CLUSTER NAME STATUS ROLES AGE VERSION default-capi-quickstart-2 capi-quickstart-2-ctm9k-g2m87 NotReady control-plane 12m v1.24.2 default-capi-quickstart-2 capi-quickstart-2-md-0-s8hbx-7bd44554b5-kzcb6 NotReady \u003cnone\u003e 11m v1.24.2 default-capi-quickstart capi-quickstart-2xcsz-fxrrk NotReady control-plane 21m v1.24.2 default-capi-quickstart capi-quickstart-md-0-9tw2g-b8b4f46cf-gggvq NotReady \u003cnone\u003e 20m v1.24.2 快速部署一套 Cluster API And Clusterpedia 的示例环境 预备条件  安装 kubectl 到本地环境 安装 Kind and Docker 安装 clusterctl   Minimum kind supported version: v0.14.0\n 创键管理集群并部署 Cluster API  部署 Cluster API 也可以参考 https://cluster-api.sigs.k8s.io/user/quick-start.html\n $ cat \u003e kind-cluster-with-extramounts.yaml \u003c\u003cEOF kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 nodes: - role: control-plane extraMounts: - hostPath: /var/run/docker.sock containerPath: /var/run/docker.sock EOF $ kind create cluster --name capi-sample --config kind-cluster-with-extramounts.yaml $ export CLUSTER_TOPOLOGY=true $ clusterctl init --infrastructure docker 部署 Clusterpedia $ git clone https://github.com/clusterpedia-io/clusterpedia.git \u0026\u0026 cd clusterpedia/charts $ helm install clusterpedia . \\  --namespace clusterpedia-system \\  --create-namespace \\  --set installCRDs=true \\  # --set persistenceMatchNode={{ LOCAL_PV_NODE }} --set persistenceMatchNode=capi-sample-control-plane  clusterpedia charts 提供了 Local PV，需要创建 LOCAL PV 绑定的节点. 如果不需要 charts 来创建 LOCAL PV，可以使用 --set persistenceMatchNode=None. 详见\n 创建用于接入 Cluster API 的集群自动导入策略\n$ kubectl apply -f https://raw.githubusercontent.com/Iceber/clusterpedia/add_cluster_api_clusterimportpolicy/deploy/clusterimportpolicy/cluster_api.yaml  Clusterpedia 可以接入任何的多云管理平台，接入方式可以参考 Interfacing to Multi-Cloud Platforms\n 生成 kubectl cluster shortcut，如果使用 client-go 或者 OpenAPI 来访问，可以省略该步骤\n$ curl -sfL https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/main/hack/gen-clusterconfigs.sh | sh - $ # 使用 kubectl 检索多集群资源，当前 Cluster API 未创建集群，所以返回空 $ kubectl --cluster clusterpedia api-resources 使用 Cluster API 创建集群 使用示例环境的 Docker Provider 来创建集群时，需要添加 --flavor development\n$ clusterctl generate cluster capi-quickstart --flavor development \\  --kubernetes-version v1.24.2 \\  --control-plane-machine-count=1 \\  --worker-machine-count=1 \\  \u003e capi-quickstart.yaml $ kubectl apply -f ./capi-quickstart.yaml 观察集群创建情况 $ kubectl get cluster NAME PHASE AGE VERSION capi-quickstart Provisioned 8s v1.24.2 $ kubectl get kubeadmcontrolplane -w NAME CLUSTER INITIALIZED API SERVER AVAILABLE REPLICAS READY UPDATED UNAVAILABLE AGE VERSION capi-quickstart-2xcsz capi-quickstart true 1 1 1 86s v1.24.2 当 kubeadmcontrolplane 的 Initialized 为 True 后，clusterpedia 会自动同步该集群内的资源，可以使用 kubectl --cluster clusterpedia get po -A 来查看资源\n$ kubectl get pediacluster NAME READY VERSION APISERVER default-capi-quickstart True v1.24.2 $ kubectl --cluster clusterpedia get pod -A NAMESPACE CLUSTER NAME READY STATUS RESTARTS AGE kube-system default-capi-quickstart kube-apiserver-capi-quickstart-2xcsz-fxrrk 1/1 Running 0 2m32s kube-system default-capi-quickstart kube-scheduler-capi-quickstart-2xcsz-fxrrk 1/1 Running 0 2m31s kube-system default-capi-quickstart coredns-6d4b75cb6d-lrwj4 0/1 Pending 0 2m20s kube-system default-capi-quickstart kube-proxy-p8v9m 1/1 Running 0 2m20s kube-system default-capi-quickstart kube-controller-manager-capi-quickstart-2xcsz-fxrrk 1/1 Running 0 2m32s kube-system default-capi-quickstart etcd-capi-quickstart-2xcsz-fxrrk 1/1 Running 0 2m32s kube-system default-capi-quickstart kube-proxy-2ln2w 1/1 Running 0 105s kube-system default-capi-quickstart coredns-6d4b75cb6d-2hcmz 0/1 Pending 0 2m20s 自动创建的 pediacluster 默认的同步资源在 cluster-api clusterimportpolicy 中设置，\n用户也可以手动修改 pediacluster 中同步的配置, Synchronize Cluster Resources\n在 Cluster API 中删除集群时，Clusterpedia 也同步删除 PeidaCluster，不会继续同步该集群\n对多个集群的资源检索 使用上述步骤创建多个集群\n$ kubectl get cluster NAME PHASE AGE VERSION capi-quickstart Provisioned 10m v1.24.2 capi-quickstart-2 Provisioned 118s v1.24.2 $ kubectl get kubeadmcontrolplane NAME CLUSTER INITIALIZED API SERVER AVAILABLE REPLICAS READY UPDATED UNAVAILABLE AGE VERSION capi-quickstart-2-ctm9k capi-quickstart-2 true 1 1 1 10m v1.24.2 capi-quickstart-2xcsz capi-quickstart true 1 1 1 19m v1.24.2 $ # pediacluster 会根据 cluster 资源自动创建 $ kubectl get pediacluster -o wide NAME READY VERSION APISERVER VALIDATED SYNCHRORUNNING CLUSTERHEALTHY default-capi-quickstart True v1.24.2 Validated Running Healthy default-capi-quickstart-2 True v1.24.2 Validated Running Healthy $ kubectl --cluster clusterpedia get no CLUSTER NAME STATUS ROLES AGE VERSION default-capi-quickstart-2 capi-quickstart-2-ctm9k-g2m87 NotReady control-plane 12m v1.24.2 default-capi-quickstart-2 capi-quickstart-2-md-0-s8hbx-7bd44554b5-kzcb6 NotReady \u003cnone\u003e 11m v1.24.2 default-capi-quickstart capi-quickstart-2xcsz-fxrrk NotReady control-plane 21m v1.24.2 default-capi-quickstart capi-quickstart-md-0-9tw2g-b8b4f46cf-gggvq NotReady \u003cnone\u003e 20m v1.24.2 clusterpedia 提供了两种资源检索方式\n 兼容 Kubernetes OpenAPI 的资源检索  $ kubectl --cluster clusterpedia get cm -A NAMESPACE CLUSTER NAME DATA AGE kube-system default-capi-quickstart extension-apiserver-authentication 6 19m kube-system default-capi-quickstart kubeadm-config 1 19m kube-public default-capi-quickstart cluster-info 2 19m kube-system default-capi-quickstart kube-proxy 2 19m kube-node-lease default-capi-quickstart kube-root-ca.crt 1 19m kube-system default-capi-quickstart-2 extension-apiserver-authentication 6 10m kube-system default-capi-quickstart kubelet-config 1 19m kube-system default-capi-quickstart coredns 1 19m kube-system default-capi-quickstart kube-root-ca.crt 1 19m kube-public default-capi-quickstart kube-root-ca.crt 1 19m kube-system default-capi-quickstart-2 coredns 1 10m default default-capi-quickstart kube-root-ca.crt 1 19m kube-system default-capi-quickstart-2 kube-proxy 2 10m kube-system default-capi-quickstart-2 kubeadm-config 1 10m kube-system default-capi-quickstart-2 kubelet-config 1 10m kube-system default-capi-quickstart-2 kube-root-ca.crt 1 10m kube-node-lease default-capi-quickstart-2 kube-root-ca.crt 1 10m kube-public default-capi-quickstart-2 cluster-info 3 10m kube-public default-capi-quickstart-2 kube-root-ca.crt 1 10m default default-capi-quickstart-2 kube-root-ca.crt 1 10m $ # gen cluster shortcuts $ curl -sfL https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/main/hack/gen-clusterconfigs.sh | sh - $ kubectl --cluster default-capi-quickstart get cm -n kube-system  Collection Resource  $ kubectl get collectionresources NAME RESOURCES any * workloads apps.deployments,apps.daemonsets,apps.statefulsets kuberesources .*,admission.k8s.io.*,admissionregistration.k8s.io.*,apiextensions.k8s.io.*,apps.*,authentication.k8s.io.*,authorization.k8s.io.*,autoscaling.*,batch.*,certificates.k8s.io.*,coordination.k8s.io.*,discovery.k8s.io.*,events.k8s.io.*,extensions.*,flowcontrol.apiserver.k8s.io.*,imagepolicy.k8s.io.*,internal.apiserver.k8s.io.*,networking.k8s.io.*,node.k8s.io.*,policy.*,rbac.authorization.k8s.io.*,scheduling.k8s.io.*,storage.k8s.io.* $ kubectl get collectionresources workloads 检索条件  元信息过滤(资源名称，命名空间，集群，创建时间区间)  $ kubectl --cluster clusterpedia get cm -A -l \\  \"search.clusterpedia.io/clusters in (default-capi-quickstart,default-capi-quickstart-2),\\ search.clusterpedia.io/namespaces in (kube-system,default)\" NAMESPACE CLUSTER NAME DATA AGE kube-system default-capi-quickstart extension-apiserver-authentication 6 23m kube-system default-capi-quickstart kubeadm-config 1 23m kube-system default-capi-quickstart kube-proxy 2 23m kube-system default-capi-quickstart-2 extension-apiserver-authentication 6 14m kube-system default-capi-quickstart kubelet-config 1 23m kube-system default-capi-quickstart coredns 1 23m kube-system default-capi-quickstart kube-root-ca.crt 1 23m kube-system default-capi-quickstart-2 coredns 1 14m default default-capi-quickstart kube-root-ca.crt 1 23m kube-system default-capi-quickstart-2 kube-proxy 2 14m kube-system default-capi-quickstart-2 kubeadm-config 1 14m kube-system default-capi-quickstart-2 kubelet-config 1 14m kube-system default-capi-quickstart-2 kube-root-ca.crt 1 14m default default-capi-quickstart-2 kube-root-ca.crt 1 14m  模糊搜索 增强的 Field Selector 根据父辈或者祖辈 Owner 检索 分页和排序 自定义条件搜索  ","categories":"","description":"","excerpt":"0.4.0 后，Clusterpedia 提供了更加友好的接入多云平台的方式，用户在多云平台创建或者纳管集群后， …","ref":"/zh-cn/blog/2022/08/04/cluster-api-searching-has-never-been-easier/","tags":"","title":"Cluster API Searching Has Never Been Easier"},{"body":"  #td-cover-block-0 { background-image: url(/featured-background_hu629dc54e681a6f98b3ff241b67cb80fe_677037_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/featured-background_hu629dc54e681a6f98b3ff241b67cb80fe_677037_1920x1080_fill_q75_catmullrom_top.jpg); } }  Welcome to Clusterpedia Lean More   Source Code   The Encyclopedia of Kubernetes clusters           Synchronize and search for multi-cluster resources   Clusterpedia can synchronize resources with multiple clusters and provide more powerful search features     Support for extensive resources  Clusterpedia can search for multi-cluster resources by different types such as Pod or Deployment,\nand support combining multiple resources (such as Workload) into a Collection Resource to search for.\nSearch for Custom Resource\n     Compatible with Kubernetes OpenAPI  Clusterpedia can leverage existing tools such as kubectl or client-go to search for multi-cluster resources without additional frameworks or tools\n     Support complex search  Based on compatibility with Kubernetes OpenAPI, in addition to supporting Label Selector,\nit also supports more complex and useful search conditions, for example:\n Specify multiple clusters and namespaces\n Use more powerfule Field Selector to filter resources by any fileds  Query descendant resources via a parent or even ancestor Owner  Sort by multiple resource fields\n Support pagination and remaining items count\n      Join us on Slack Join the community on Slack\n Join us …\n   Welcome to join Clusterpedia! We do a Pull Request contributions workflow on GitHub. New users are always welcome!\n Contribute to Clusterpedia …\n     Clusterpedia is a Cloud Native Computing Foundation sandbox project    ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/","tags":"","title":"Clusterpedia"},{"body":"  #td-cover-block-0 { background-image: url(/zh-cn/featured-background_hu629dc54e681a6f98b3ff241b67cb80fe_677037_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/zh-cn/featured-background_hu629dc54e681a6f98b3ff241b67cb80fe_677037_1920x1080_fill_q75_catmullrom_top.jpg); } }  欢迎来到 Clusterpedia Lean More   Source Code   The Encyclopedia of Kubernetes clusters           混合检索多集群的资源   通过 Clusterpedia 可以一次获取多个集群内的资源，并且支持强大的检索条件     丰富的资源支持  Clusterpedia 不仅仅支持以 Pods, Deployments 等资源类型来检索多个集群中资源，\n还支持将多个资源组合成集合资源（Collection Resource）来聚合检索多个类型的资源，例如 Workloads。\n支持检索自定义资源\n     兼容 Kubernetes OpenAPI  可以利用已有的工具，例如 kubectl 或者 client-go 来检索多集群资源，无需额外框架或者工具\n     强大的检索条件支持  在兼容 Kubernetes OpenAPI 的基础上，除了支持 Label Selector 外，还支持更加复杂和使用的检索条件，例如\n 支持检索多个集群以及命名空间下的资源，\n 更加强大的 Field Selector, 支持筛选资源的任意字段，\n 可以通过父辈甚至祖辈 Owner 来查询后代资源，  基于多个资源字段的排序，\n 分页以及 remaining items count 支持\n      Join us on Slack Join the community on Slack\n Join us …\n   欢迎加入 Clusterpedia! We do a Pull Request contributions workflow on GitHub. New users are always welcome!\n Contribute to Clusterpedia …\n     Clusterpedia is a Cloud Native Computing Foundation sandbox project    ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/zh-cn/","tags":"","title":"Clusterpedia"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh-cn/blog/","tags":"","title":"博客"},{"body":"In the updated CNCF Cloud Native Landscape, Clusterpedia was listed into the Scheduling \u0026 Orchestration quadrant of the Orchestration \u0026 Management layer, becoming a cloud-native multi-cluster complex retrieval tool recommended by CNCF.\n\n Cloud Native Computing Foundation (CNCF) belongs to the Linux Foundation and was established in December 2015. It is a non-profit organization dedicated to fostering and maintaining a vendor-neutral open source ecosystem to promote cloud native technologies and make cloud native universal and sustainable.\nThe Cloud Native Landscape has been maintained by CNCF since December 2016. It is intended as a map to list popular projects with best practices in the community, and categorizes them in the cloud native space to provide reference for enterprises to build a cloud native ecosystem. It has extensive influence on the development, operation, and maintenance of cloud native technologies.\n","categories":"","description":"","excerpt":"In the updated CNCF Cloud Native Landscape, Clusterpedia was listed …","ref":"/blog/2022/04/29/clusterpedia-is-listed-in-the-cncf-cloud-native-landscape/","tags":"","title":"Clusterpedia is Listed in the CNCF Cloud Native Landscape"},{"body":"在 CNCF 最新发布的云原生全景图 (Cloud Native Landscape) 中，Clusterpedia入选Orchestration \u0026 Management (编排与管理) 层的 Scheduling \u0026 Orchestration (调度与编排) 象限，成为 CNCF 推荐的云原生多集群复杂检索工具。\n\n CNCF 全称 Cloud Native Computing Foundation (云原生计算基金会)，隶属于 Linux 基金会，成立于 2015 年 12 月，是非营利性组织，致力于培育和维护一个厂商中立的开源生态系统，来推广云原生技术，普及云原生应用。\n云原生全景图由 CNCF 从 2016 年 12 月开始维护，汇总了社区成熟和使用范围较广、具有最佳实践的产品和方案，并加以分类，为企业构建云原生体系提供参考，在云生态研发、运维领域具有广泛影响力。\n","categories":"","description":"","excerpt":"在 CNCF 最新发布的云原生全景图 (Cloud Native Landscape) 中，Clusterpedia入 …","ref":"/zh-cn/blog/2022/04/29/clusterpedia-%E5%85%A5%E9%80%89%E4%BA%91%E5%8E%9F%E7%94%9F%E5%85%A8%E6%99%AF%E5%9B%BE/","tags":"","title":"Clusterpedia 入选云原生全景图"},{"body":"Use helm to install Users can already use Helm to install Clusterpedia:\n$ helm install clusterpedia . \\ --namespace clusterpedia-system \\ --create-namespace \\ --set persistenceMatchNode={{ LOCAL_PV_NODE }} \\ # --set installCRDs=true  Lean More\nUse the Kube Config to import a cluster For v0.1.0, users need to Configure the address for the imported cluster and the authentication information.\napiVersion: cluster.clusterpedia.io/v1alpha2 kind: PediaCluster metadata: name: cluster-example spec: apiserver: \"https://10.30.43.43:6443\" caData: tokenData: certData: keyData: syncResources: []  In v0.2.0, the PediaCluster added the spec.kubeconfig field so that users can use kube config to import the cluster directly.\nFirst you need to base64 encode the kube config for the imported cluster.\n$ base64 ./kubeconfig.yaml  Set the content after the base64 to PediaCluster spec.kubeconfig, in addition spec.apiserver and other authentication fields don’t need to set.\napiVersion: cluster.clusterpedia.io/v1alpha2 kind: PediaCluster metadata: name: cluster-example spec: kubeconfig: **base64 kubeconfig** syncResources: []  However, since the cluster address is configured in kube config, the APIServer is empty when you use kubectl get pediacluster.\n$ kubectl get pediacluster NAME APISERVER VERSION STATUS cluster-example v1.22.2 Healthy  Mutating addmission webhooks will be added in the future to automatically set spec.apiserver, currently if you want to show the cluster apiserver address when kubectl get pediacluster, then you need to manually configure the spec.apiserver field additionally.\nNew Search Feature Search by creation time interval    Description Search Label Key URL Query     Since search.clusterpedia.io/since since   Before search.clusterpedia.io/before before    The creation time interval used for the search is left closed and right open, since \u003c= creation time \u003c before.\nThere are four formats for creation time:\n Unix Timestamp for ease of use will distinguish between units of s or ms based on the length of the timestamp. The 10-bit timestamp is in seconds, the 13-bit timestamp is in milliseconds. RFC3339 2006-01-02T15:04:05Z or 2006-01-02T15:04:05+08:00 UTC Date 2006-01-02 UTC Datetime 2006-01-02 15:04:05   Because of the limitation of the kube label selector, the search label only supports Unix Timestamp and UTC Date.\nAll formats are available using the url query method.\n Look at what resources are under the default namespace\n$ kubectl --cluster clusterpedia get pods CLUSTER NAME READY STATUS RESTARTS AGE cluster-example quickstart-ingress-nginx-admission-create--1-kxlnn 0/1 Completed 0 171d cluster-example fake-pod-698dfbbd5b-wvtvw 1/1 Running 0 8d cluster-example fake-pod-698dfbbd5b-74cjx 1/1 Running 0 21d cluster-example fake-pod-698dfbbd5b-tmcw7 1/1 Running 0 8d  We use the creation time to filter the resources.\n$ kubectl --cluster clusterpedia get pods -l \"search.clusterpedia.io/since=2022-03-20\" CLUSTER NAME READY STATUS RESTARTS AGE cluster-example fake-pod-698dfbbd5b-wvtvw 1/1 Running 0 8d cluster-example fake-pod-698dfbbd5b-tmcw7 1/1 Running 0 8d $ kubectl --cluster clusterpedia get pods -l \"search.clusterpedia.io/before=2022-03-20\" CLUSTER NAME READY STATUS RESTARTS AGE cluster-example quickstart-ingress-nginx-admission-create--1-kxlnn 0/1 Completed 0 171d cluster-example fake-pod-698dfbbd5b-74cjx 1/1 Running 0 21d  Search by Owner Name As of v0.1.0, we can specify ancestor or parent Owner UID to query resources, but Owner UID is not convenient to use, after all, you still need to know the UID of the Owner resource in advance.\nIn v0.2.0, we support querying directly with Owner Name, and the Owner query has been moved from experimental to released functionality, the prefix of Search Label has been upgraded from internalstorage.c lusterpedia.io to *search.clusterpedia.io *, and URL Query is provided.\n   Role search label key url query     Specified Owner UID search.clusterpedia.io/owner-uid ownerUID   Specified Owner Name search.clusterpedia.io/owner-name ownerName   SPecified Owner Group Resource search.clusterpedia.io/owner-gr ownerGR   Specified Owner Seniority internalstorage.clusterpedia.io/owner-seniority ownerSeniority     Note that when specifying Owner UID, Owner Name and Owner Group Resource will be ignored.\n $ kubectl --cluster cluster-example get pods -l \\ \"search.clusterpedia.io/owner-name=fake-pod, \\ search.clusterpedia.io/owner-seniority=1\" CLUSTER NAME READY STATUS RESTARTS AGE cluster-example fake-pod-698dfbbd5b-wvtvw 1/1 Running 0 8d cluster-example fake-pod-698dfbbd5b-74cjx 1/1 Running 0 21d cluster-example fake-pod-698dfbbd5b-tmcw7 1/1 Running 0 8d  In addition, to avoid multiple types of owner resources in some cases, we can use the Owner Group Resource to restrict the type of owner.\n$ kubectl --cluster cluster-example get pods -l \\ \"search.clusterpedia.io/owner-name=fake-pod,\\ search.clusterpedia.io/owner-gr=deployments.apps,\\ search.clusterpedia.io/owner-seniority=1\" ... some output  Fuzzy Search base on resource names Since fuzzy search needs to be discussed further, it is temporarily provided as an experimental feature.\nOnly the Search Label method is supported, URL Query isn’t supported. |Role| search label key|url query| | – | ————— | ——- | |Fuzzy Search for resource name|internalstorage.clusterpedia.io/fuzzy-name|-|\n$ kubectl --cluster clusterpedia get deployments -l \"internalstorage.clusterpedia.io/fuzzy-name=fake\" CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE cluster-example fake-pod 3/3 3 3 113d  You can use the in operator to pass multiple fuzzy arguments, so that you can filter out resources that have all strings in their names.\nOther Features In v0.1.0, searching the resources allow the number of remaining resources to be returned so that the user can calculate the total number of resources.\nThis feature has been enhanced in v0.2.0. When offset is too large, remainingItemCount may be negative, ensuring that the total number of resources can always be calculated.\nLean More\nRelease Notes  Support of using Helm Charts for installation (#53, #125, @calvin0327, @wzshiming) PediaCluster supports for importing a cluster using the kubeconfig (#115, @wzshiming)  APIServer  Support for filtering resources by a period of creation (#113, @cleverhu) Support for searching for resources by an Owner name. Now, the feature of Search by Owner is officially released. (#91, @Iceber)  Default Storage Layer  Support for fuzzy search by a resource name (#117, @cleverhu) RemainingItemCount can be a negative number. We can still use offset + len(items) + remainingItemCount to calculate the total amount of resources if the Offset is too large. (#123, @cleverhu)  Bug Fixes  Fixed unnecessary json.Unmarshal and improved performance when searching (#89, #92, @Iceber)  Deprecation  Search by Owner has been released as an official feature. internalstorage.clusterpedia.io/owner-name and internalstorage.clusterpedia.io/owner-seniority will be removed in the next release. (#91, @Iceber)  Other  golangci-lint is used as a static checking tool (#86, #88, @Iceber) Added CI Workloads such as static checking and unit testing for code #87, @Iceber)  ","categories":"","description":"","excerpt":"Use helm to install Users can already use Helm to install …","ref":"/blog/2022/04/12/clusterpedia-v0.2.0-release/","tags":"","title":"Clusterpedia v0.2.0 Release"},{"body":"使用 kube config 来接入集群 v0.1.0 时，用户需要分别填写被接入集群的 apiserver 地址，以及访问集群时的认证信息\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:cluster-examplespec:apiserver:\"https://10.30.43.43:6443\"caData:tokenData:certData:keyData:syncResources:[]在 v0.2.0 中 PediaCluster 增加了 spec.kubeconfig 字段，用户可以直接使用 kube config 来接入集群。\n首先 base64 集群的 kube config:\n$ base64 ./kubeconfig.yaml 然后填充到 PediaCluster 的 spec.kubeconfig 字段中\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:cluster-examplespec:kubeconfig:**base64kubeconfig**syncResources:[]在使用 kube config 时，不需要填写 spec.apiserver 以及其他认证字段。\n需要注意，使用 kubectl get pediacluster 查看接入的集群列表时，APISERVER 不会显示集群地址\n$ kubectl get pediacluster NAME APISERVER VERSION STATUS cluster-example v1.22.2 Healthy 如果需要显示，那么需要额外手动设置 spec.kubeconfig，未来会添加 Mutating Admission Webhook 来解析 kubeconfig 并自动填充 spec.apiserver 字段。\n新增的检索功能 通过资源的创建时间来过滤资源    作用 Search Label Key URL Query     Since search.clusterpedia.io/since since   Before search.clusterpedia.io/before before    创建时间的区间采用左闭右开的规则，since \u003c= creation time \u003c before。\n时间格式支持 4 种：\n Unix 时间戳格式 为了方便使用会根据时间戳的长度来区分单位为 s 还是 ms。 10 位时间戳单位为秒，13 位时间戳单位为毫秒。 RFC3339 2006-01-02T15:04:05Z or 2006-01-02T15:04:05+08:00 UTC Date 2006-01-02 UTC Datetime 2006-01-02 15:04:05   由于 Kube Label Selector 的限制，Search Label 只支持使用 Unix 时间戳和 UTC Data 的格式 URL Query 可以使用四种格式\n 首先查看一下当前都有哪些资源\n$ kubectl --cluster clusterpedia get pods CLUSTER NAME READY STATUS RESTARTS AGE cluster-example quickstart-ingress-nginx-admission-create--1-kxlnn 0/1 Completed 0 171d cluster-example fake-pod-698dfbbd5b-wvtvw 1/1 Running 0 8d cluster-example fake-pod-698dfbbd5b-74cjx 1/1 Running 0 21d cluster-example fake-pod-698dfbbd5b-tmcw7 1/1 Running 0 8d 我们使用创建时间来过滤资源\n$ kubectl --cluster clusterpedia get pods -l \"search.clusterpedia.io/since=2022-03-20\" CLUSTER NAME READY STATUS RESTARTS AGE cluster-example fake-pod-698dfbbd5b-wvtvw 1/1 Running 0 8d cluster-example fake-pod-698dfbbd5b-tmcw7 1/1 Running 0 8d $ kubectl --cluster clusterpedia get pods -l \"search.clusterpedia.io/before=2022-03-20\" CLUSTER NAME READY STATUS RESTARTS AGE cluster-example quickstart-ingress-nginx-admission-create--1-kxlnn 0/1 Completed 0 171d cluster-example fake-pod-698dfbbd5b-74cjx 1/1 Running 0 21d 使用 Owner Name 检索 在 v0.1.0 时，我们可以指定祖辈或者父辈 Owner UID 来查询资源，不过 Owner UID 使用起来并不方便，毕竟还需要提前得知 Owner 资源的 UID。\n在 v0.2.0 版本中，支持直接使用 Owner Name 来查询，并且 Owner 查询由实验性功能进入到正式功能，Search Label 的前缀也由 internalstorage.clusterpedia.io 升级为 search.clusterpedia.io，并且提供了 URL Query。\n   作用 Search Label Key URL Query     指定 Owner UID search.clusterpedia.io/owner-uid ownerUID   指定 Owner Name search.clusterpedia.io/owner-name ownerName   指定 Owner Group Resource search.clusterpedia.io/owner-gr ownerGR   指定 Owner 辈分 internalstorage.clusterpedia.io/owner-seniority ownerSeniority     如果用户同时指定了 Owner UID 和 Owner Name，那么 Owner Name 会被忽略。\n $ kubectl --cluster cluster-example get pods -l \\  \"search.clusterpedia.io/owner-name=fake-pod, \\ search.clusterpedia.io/owner-seniority=1\" CLUSTER NAME READY STATUS RESTARTS AGE cluster-example fake-pod-698dfbbd5b-wvtvw 1/1 Running 0 8d cluster-example fake-pod-698dfbbd5b-74cjx 1/1 Running 0 21d cluster-example fake-pod-698dfbbd5b-tmcw7 1/1 Running 0 8d 另外为了避免某些情况下，owner 资源存在多种类型，我们可以使用 Owner Group Resource 来限制 Owner 的类型。\n$ kubectl --cluster cluster-example get pods -l \\  \"search.clusterpedia.io/owner-name=fake-pod,\\ search.clusterpedia.io/owner-gr=deployments.apps,\\ search.clusterpedia.io/owner-seniority=1\" ... some output 根据资源名称的模糊搜索 模糊搜索是一个非常常用的功能，当前暂时只提供了资源名称上的模糊搜索，由于还需要更多功能上的讨论，暂时作为试验性功能\n   作用 Search Label Key URL Query     根据资源名称进行模糊搜索 internalstorage.clusterpedia.io/fuzzy-name -    $ kubectl --cluster clusterpedia get deployments -l \"internalstorage.clusterpedia.io/fuzzy-name=fake\" CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE cluster-example fake-pod 3/3 3 3 113d 可以使用 in 操作符来指定多个参数，这样可以过滤出名字包含所有模糊字符串的资源。\n其他功能 在 v0.1.0 中，查询资源列表时，允许返回的剩余的资源数量，这样用户可以通过计算就能得知当前检索添加下的资源总量。\n在 v0.2.0 中对该功能进行了强化， 当分页查询的 Offset 参数过大时，ReaminingItemCount 可以为负数， 这样可以保证通过 offset + len(list.items) + list.metadata.remainingItemCount 总是可以计算出正确的资源总量。\n发布日志 What’s New  支持使用 Helm 部署 (#53, #125, @calvin0327, @wzshiming) PediaCluster 支持使用 kube config 来接入集群 (#115, @wzshiming)  APIServer  支持通过创建时间的区间来过滤资源 (#113, @cleverhu) 支持根据 Owner 的名字来检索资源，并且 Owner 查询成为 clusterpedia 的正式功能，同时支持 Search Label 和 URL Query (#91, @Iceber)  Default Storage Layer  支持根据资源名称的模糊搜索 (#117, @cleverhu) RemainingItemCount 可以为负数，在 Offset 过大时依然可以使用 offset + len(items) + remainingItemCount 来计算资源总量。(#123, @cleverhu)  Bug Fixes  修复由于不必要的反序列化导致的 cpu 损耗，提升了查询时的性能 (#89, #92, @Iceber)  Deprecation  Owner 查询已移动到正式功能，用于 Owner 查询的试验性 Search Label —— internalstorage.clusterpedia.io/owner-name 和 internalstorage.clusterpedia.io/owner-seniority 会在下一个版本被移除 (#91, @Iceber)  ","categories":"","description":"","excerpt":"使用 kube config 来接入集群 v0.1.0 时，用户需要分别填写被接入集群的 apiserver 地址， …","ref":"/zh-cn/blog/2022/04/12/clusterpedia-v0.2.0-%E5%8F%91%E5%B8%83/","tags":"","title":"Clusterpedia v0.2.0 发布"},{"body":"Currently Clusterpedia has supported a rapid deployment with Helm.\nAll of first, you need to check if helm v3 is installed in your current environment.\n当前暂时还未将 chart 上传至 charts 公共仓库。 -- Preparation Pull the Clusterpedia repository.\n Currently, the chart has not been uploaded to the public charts repository.\n git clone https://github.com/clusterpedia-io/clusterpedia.git cd clusterpedia/charts Since Clusterpedia uses bitnami/postgresql and bitnami/mysql as subcharts of storage components, it is necessary to add the bitnami repository and update the dependencies of the clusterpedia chart.\nhelm repo add bitnami https://charts.bitnami.com/bitnami helm dependency build Choose storage components The Clusterpedia chart provides two storage components such as bitnami/postgresql and bitnami/mysql to choose from as sub-charts.\npostgresql is the default storage component. IF you want to use MySQL, you can add --set postgresql.enabled=false --set mysql.enabled=true in the subsequent installation command.\nFor specific configuration about storage components, see bitnami/postgresql and bitnami/mysql.\nYou can also choose not to install any storage component, but use external components. For related settings, see charts/values.yaml\nChoose a installation or management mode for CRDs Clusterpedia requires proper CRD resources to be created in the retrieval environment. You can choose to manually deploy CRDs by using YAML, or you can manage it with Helm.\nManage manually kubectl apply -f ./_crds ` 来指定 Local PV 所在节点。** 如果用户不需要创建 Local PV，那么需要使用 `--set persistenceMatchNode=None` 显式声明。 ## 安装 Clusterpedia 经过上述决策后，用户可以进行安装： -- Manage with Helm Manually add --set installCRDs=true in the subsequent installation command.\nCheck if you need to create a local PV Through the Clusterpedia chart, you can create storage components to use a local PV.\nYou need to specify the node where the local PV is located through --set persistenceMatchNode=\u003cselected node name\u003e during installation.\nIf you need not to create the local PV, you can use --set persistenceMatchNode=None to declare it explicitly.\nInstall Clusterpedia After the above procedure is completed, you can run the following command to install Clusterpedia:\nhelm install clusterpedia . \\ --namespace clusterpedia-system \\ --create-namespace \\ --set persistenceMatchNode={{ LOCAL_PV_NODE }} \\ --set installCRDs=true Uninstall Clusterpedia Before uninstallation, you shall manually clear all PediaCluster resources.\nkubectl get pediacluster You can run the command to uninstall it after the PediaCluster resources are cleared.\nhelm -n clusterpedia-system uninstall clusterpedia If you use any CRD resource that is manually created, you also need to manually clear the CRDs.\nkubectl delete -f ./_crds Note that PVC and PV will not be deleted. You need to manually delete them.\nIf you created a local PV, you need log in to the node and remove all remained data about the local PV.\n# Log in to the node with Local PV rm -rf /var/local/clusterpedia/internalstorage/\u003cstorage type\u003e ","categories":"","description":"","excerpt":"Currently Clusterpedia has supported a rapid deployment with Helm.\nAll …","ref":"/blog/2022/04/11/quickly-deploy-clusterpedia-with-helm/","tags":"","title":"Quickly Deploy Clusterpedia with Helm"},{"body":"当前 Clusterpedia 已经支持通过 Helm 来快速部署。\n首先需要保证当前环境已经安装 helm v3。\n准备阶段 拉取 Clusterpedia 仓库代码。\n 当前暂时还未将 chart 上传至 charts 公共仓库。\n $ git clone https://github.com/clusterpedia-io/clusterpedia.git $ cd clusterpedia/charts 由于 clusterpedia 使用 bitnami/postgresql 和 bitnami/mysql 作为存储组件子 chart， 所以需要添加 bitnami 仓库，并更新 clusterpedia chart 的依赖。\n$ helm repo add bitnami https://charts.bitnami.com/bitnami $ helm dependency build 选择存储组件 Clusterpedia Chart 通过子 chart 的方式，提供了 bitnami/postgresql 和 bitnami/mysql 两款存储组件可供选择。\npostgresql 为默认的存储组件，如果想要使用 MySQL，那么在后续安装命令中添加 --set postgresql.enabled=false --set mysql.enabled=true\n更多关于存储组件的配置，可以参考 bitnami/postgresql 和 bitnami/mysql。\n用户也可以选择不安装存储组件，而是使用外部组件，相关设置可以参考 charts/values.yaml\n选择 CRD 的安装/管理方式 clusterpedia 要求环境中创建相应的 CRD 资源，可以选择手动部署 CRD YAML，也可以在 Helm 中管理。\n手动管理 $ kubectl apply -f ./_crds 使用 Helm 管理 在后续安装命令中需要手动添加 --set installCRDs=true 即可。\n决定是否需要创建 Local PV Clusterpedia Chart 可以为用户创建存储组件使用 Local PV。\n用户在安装时需要通过 --set persistenceMatchNode=\u003cselected node name\u003e 来指定 Local PV 所在节点。\n如果用户不需要创建 Local PV，那么需要使用 --set persistenceMatchNode=None 显式声明。\n安装 Clusterpedia 经过上述决策后，用户可以进行安装：\n$ helm install clusterpedia . \\  --namespace clusterpedia-system \\  --create-namespace \\  --set persistenceMatchNode={{ LOCAL_PV_NODE }} \\  # --set installCRDs=true 卸载 Clusterpedia 在卸载 Clusterpedia 前需要手动清理所有 PediaCluster 资源。\n$ kubectl get pediacluster PediaCluster 清理完成后就可以执行卸载命令。\n$ helm -n clusterpedia-system uninstall clusterpedia 如果用户使用手动创建的 CRD 资源，那么同样也需要手动清理 CRD。\n$ kubectl delete -f ./_crds 注意 PVC 和 PV 并不会删除，用户需要手动删除。\n如果创建了 Local PV，那么还需要进入相应节点，清理 Local PV 的遗留数据。\n# 登录 Local PV 绑定的节点 $ rm -rf /var/local/clusterpedia/internalstorage/\u003cstorage type\u003e ","categories":"","description":"","excerpt":"当前 Clusterpedia 已经支持通过 Helm 来快速部署。\n首先需要保证当前环境已经安装 helm v3。 …","ref":"/zh-cn/blog/2022/04/11/%E4%BD%BF%E7%94%A8-helm-%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2-clusterpedia/","tags":"","title":"使用 Helm 快速部署 Clusterpedia"},{"body":"  On March 30, CSDN officially announced the selection list of IT technology influence stars, and Clusterpedia was selected as a “Cloud Native Technology Product in 2021”.\nIn the multi-cloud era, it is more and more complex and becomes a problem for resource management and retrieval in a multi-cluster environment.\nIn a single cluster, we usually use kubectl to view resources, directly access Kubernetes OpenAPI, or use client-go to retrieve resources in the code.\nNow, in a multi-cluster environment, Clusterpedia provides compatibility with Kubernetes OpenAPI, so you can still perform complex retrieval or search for multi-cluster resources like a single cluster without pulling data from each cluster to the local for filtering.\n ","categories":"","description":"","excerpt":"  On March 30, CSDN officially announced the selection list of IT …","ref":"/blog/2022/04/01/clusterpedia-awarded-one-of-it-technology-influcence-stars-selected-by-csdn/","tags":"","title":"Clusterpedia Awarded | One of IT Technology Influcence Stars Selected by CSDN"},{"body":"  3 月 30 日，CSDN 正式公布 IT 技术影响力之星评选结果，Clusterpedia 入选「2021 年度云原生技术产品」。\n在多云时代，多集群内部资源管理和检索越来越复杂，成为多云管理的一大难题。\n在单集群中，我们通常使用 kubectl 来查看资源，或者直接访问 Kubernetes 的 OpenAPI，在代码中也可以借助 client-go 来对资源进行检索。\n而在多集群环境下，Clusterpedia 通过兼容 Kubernetes OpenAPI ，用户可以依然使用单集群的方式，来对多集群资源进行复杂检索，无需从每个集群中拉取数据到本地进行过滤。\n ","categories":"","description":"","excerpt":"  3 月 30 日，CSDN 正式公布 IT 技术影响力之星评选结果，Clusterpedia 入选「2021 年度云原生技术产品」。\n在 …","ref":"/zh-cn/blog/2022/04/01/clusterpedia-%E4%B8%8A%E6%A6%9C-csdn-it-%E6%8A%80%E6%9C%AF%E5%BD%B1%E5%93%8D%E5%8A%9B%E4%B9%8B%E6%98%9F/","tags":"","title":"Clusterpedia 上榜| CSDN IT 技术影响力之星"},{"body":"Iceber, the sponsor of Clusterpedia and a cloud native senior engineer of Daocloud, introduced the functions provided by Clusterpedia about resource retrieval in detail. This video step-by-step demonstrated what issues can be solved by using Clusterepdia.\n Clusterpedia is an artifact for multi-cluster resource retrieval With the increase of services you provide and the continuous expansion of the cluster scale, a single Kubernetes cluster may no longer meet the needs of many enterprises. As the cloud-native technologies develop, a multi-cloud era is coming. It is more complex and difficult to manage and retrieve resources in multiple clusters.\nAs a result, many excellent open source projects have emerged in the community, such as cluster api for cluster lifecycle management, karmada and clusternet for multi-cloud application management. Clusterpedia is built on these cloud management platforms to provide you with complex search for multi-cluster resources.\nIn a single cluster, we often use kubectl to view resources, directly access Kubernetes OpenAPI, or use client-go to retrieve resources in the code.\nNow, in a multi-cluster environment, Clusterpedia provides compatibility with Kubernetes OpenAPI, so you can still perform complex retrieval or search for multi-cluster resources like a single cluster without pulling data from each cluster to the local for filtering.\nIn addition, the capabilities of Clusterpedia are not only for searching and viewing. It also supports simple control of resources in the future, just like wiki that also supports to edit entries. Clusterpedia provides the following features now:\n Support for search with complex conditions, filters, sorting, and paging Support for requesting attached resources when querying resources Use a unified retrieval portal for master cluster and multi-cluster resources Compatible with kubernetes OpenAPI, through which you can directly use kubectl for multi-cluster retrieval and need not any third-party plugins or tools Compatible with collecting different versions of cluster resources and not constrained by the version of master cluster High performance and low memory consumption in the process of resource collection Automatically start and stop resource collection based on to the health status of clusters Support for the pluggable storage layer that indicates you can use other storage components to customize the storage layer High availability  What’s Next In addition to supporting complex retrieval of multiple clusters, Clusterpedia can provide more benefits, such as a unified portal to the master cluster and multi-cluster resources through an aggregated API, low memory usage and weak network optimization when synchronizing sub-cluster resources in real time. It can also provide a pluggable storage layer to decouple the dependencies of storage components.\nIn the next topic, we will introduce the specific design and implementation principles, and explain more benefits offered by Clusterpedia, so stay tuned.\n","categories":"","description":"","excerpt":"Iceber, the sponsor of Clusterpedia and a cloud native senior engineer …","ref":"/blog/2022/03/01/demo-video-clusterpedia-complex-retrieval-of-resources-in-a-multi-cloud-environment/","tags":"","title":"Demo Video ｜Clusterpedia - Complex Retrieval of Resources in a Multi-Cloud Environment"},{"body":"Clusterpedia 的发起人 –「Daocloud 道客」的云原生研发工程师蔡威，为大家详细介绍 Clusterpedia 在资源检索上提供的功能，让大家可以直观的了解到使用 Clusterepdia 可以解决哪些问题。\n Clusterpedia 多集群资源检索神器 随着云原生技术的发展、承载业务量的增加以及集群规模的不断扩大，单个 Kubernetes 集群已经无法满足很多企业的需求，我们在逐渐的步入多云时代，多集群内部资源管理和检索变得越发复杂和困难。\n由此，社区不断出现了很多优秀的的开源项目，例如用于集群生命周期管理的 cluster api，以及多云应用管理的 karmada， clusternet 等。而 Clusterpedia 便是建立在这些云管平台之上，为用户提供多集群资源的复杂检索。\n在单集群中，我们通常使用 kubectl 来查看资源，或者直接访问 Kubernetes 的 OpenAPI，在代码中也可以借助 client-go 来对资源进行检索。\n而在多集群环境下，Clusterpedia 通过兼容 Kubernetes OpenAPI ，用户可以依然使用单集群的方式，来对多集群资源进行复杂检索，无需从每个集群中拉取数据到本地进行过滤。\n当然 Clusterpedia 的能力并不仅仅只是检索查看，未来还会支持对资源的简单控制，就像 wiki 同样支持编辑词条一样。Clusterpedia 具有许多特性和功能：\n 支持复杂的检索条件，过滤条件，排序，分页等等 支持查询资源时请求附带关系资源 统一主集群和多集群资源检索入口 兼容 kubernetes OpenAPI, 可以直接使用 kubectl 进行多集群检索, 而无需第三方插件或者工具 兼容收集不同版本的集群资源，不受主集群版本约束， 资源收集高性能，低内存 根据集群当前的健康状态，自动启停资源收集 插件化存储层，用户可以根据自己需求使用其他存储组件来自定义存储层 高可用  下期内容 除了支持多集群的复杂检索，Clusterpedia 还有很多其他优点，例如通过聚合式 API 来统一主集群和多集群资源的访问入口，在实时同步子集群资源时的低内存占用以及弱网优化，另外还有通过插件化存储层来解耦对存储组件的依赖。\n下一期将为大家介绍具体设计和实现原理，详细解读 Clusterpedia 的优点，敬请期待。\n","categories":"","description":"","excerpt":"Clusterpedia 的发起人 –「Daocloud 道客」的云原生研发工程师蔡威，为大家详细介绍 Clusterpedia 在资源检索 …","ref":"/zh-cn/blog/2022/03/01/%E8%A7%86%E9%A2%91%E8%AE%B2%E8%A7%A3clusterpedia-%E5%A4%9A%E4%BA%91%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84%E8%B5%84%E6%BA%90%E5%A4%8D%E6%9D%82%E6%A3%80%E7%B4%A2/","tags":"","title":"视频讲解｜Clusterpedia -- 多云环境下的资源复杂检索"},{"body":"This is the first release of Clusterpedia 🥳🥳🥳, and it also means that it is officially in the iteration phase.\nCompared to the initial v0.0.8 and v0.0.9-alpha, v0.1.0 add a lot of features and makes some incompatible updates.\n If upgrading from v0.0.9-alpha or v0.0.8, you can refer to Upgrade to Clusterpedia 0.1.0\n Features Preview    Role Search Label Key URL Query     Filter cluster names search.clusterpedia.io/clusters clusters   Filter namespaces search.clusterpedia.io/namespaces namespaces   Filter resource names search.clusterpedia.io/names names   Specified Owner UID internalstorage.clusterpedia.io/owner-uid -   Specified Owner Seniority internalstorage.clusterpedia.io/owner-seniority ownerSeniority   Order by fields search.clusterpedia.io/orderby orderby   Set page size search.clusterpedia.io/size limit   Set page offset search.clusterpedia.io/offset continue   Response include Continue search.clusterpedia.io/with-continue withContinue   Response include remaining count search.clusterpedia.io/with-remaining-count withRemainingCount    Native Label Selector and enhanced Field Selector supported in addition to search label.\nImportant Features Let’s start with the more important features that have been added in 0.1.0\n The number of remaining items carried in response data Added warnning when searching for resources in a Not Ready cluster Enhancements to the native FieldSelector Search by Parent or Ancestor Owner  Warnning alert on resource search When a cluster is not ready for some reason, resources are often not synchronised properly either.\nWarnning alerts are used to alert users of cluster exceptions when searching for resources within the cluster, and the resources searched may not be accurate in real time.\n$ kubectl get pediacluster NAME APISERVER VERSION STATUS cluster-1 https://10.6.100.10:6443 v1.22.2 ClusterSynchroStop $ kubectl --cluster cluster-1 get pods Warning: cluster-1 is not ready and the resources obtained may be inaccurate, reason: ClusterSynchroStop CLUSTER NAME READY STATUS RESTARTS AGE cluster-1 fake-pod-698dfbbd5b-64fsx 1/1 Running 0 68d cluster-1 fake-pod-698dfbbd5b-9ftzh 1/1 Running 0 39d cluster-1 fake-pod-698dfbbd5b-rk74p 1/1 Running 0 39d cluster-1 quickstart-ingress-nginx-admission-create--1-kxlnn 0/1 Completed 0 126d  Field Selector Native Kubernetes currently only supports field filtering on metadata.name and metadata.namespace, and the operators only support =, !=, ==`, which is very limited.\nAlthough some specific resources will support some special fields, the use is still rather limited\n# kubernetes/pkg $ grep AddFieldLabelConversionFunc . -r ./apis/core/v1/conversion.go: err := scheme.AddFieldLabelConversionFunc(SchemeGroupVersion.WithKind(\"Pod\"), ./apis/core/v1/conversion.go: err = scheme.AddFieldLabelConversionFunc(SchemeGroupVersion.WithKind(\"Node\"), ./apis/core/v1/conversion.go: err = scheme.AddFieldLabelConversionFunc(SchemeGroupVersion.WithKind(\"ReplicationController\"), ./apis/core/v1/conversion.go: return scheme.AddFieldLabelConversionFunc(SchemeGroupVersion.WithKind(\"Event\"), ./apis/core/v1/conversion.go: return scheme.AddFieldLabelConversionFunc(SchemeGroupVersion.WithKind(\"Namespace\"), ./apis/core/v1/conversion.go: return scheme.AddFieldLabelConversionFunc(SchemeGroupVersion.WithKind(\"Secret\"), ./apis/certificates/v1/conversion.go: return scheme.AddFieldLabelConversionFunc(SchemeGroupVersion.WithKind(\"CertificateSigningRequest\"), ./apis/certificates/v1beta1/conversion.go: return scheme.AddFieldLabelConversionFunc(SchemeGroupVersion.WithKind(\"CertificateSigningRequest\"), ./apis/batch/v1/conversion.go: return scheme.AddFieldLabelConversionFunc(SchemeGroupVersion.WithKind(\"Job\"), ./apis/batch/v1beta1/conversion.go: err = scheme.AddFieldLabelConversionFunc(SchemeGroupVersion.WithKind(kind), ./apis/events/v1/conversion.go: return scheme.AddFieldLabelConversionFunc(SchemeGroupVersion.WithKind(\"Event\"), ./apis/events/v1beta1/conversion.go: return scheme.AddFieldLabelConversionFunc(SchemeGroupVersion.WithKind(\"Event\"), ./apis/apps/v1beta2/conversion.go: if err := scheme.AddFieldLabelConversionFunc(SchemeGroupVersion.WithKind(\"StatefulSet\"), ./apis/apps/v1beta1/conversion.go: if err := scheme.AddFieldLabelConversionFunc(SchemeGroupVersion.WithKind(\"StatefulSet\"),  Clusterpedia provides more powerful features based on the compatibility with existing Field Selector features, and supports the same operators as Label Selector: !, =, !=, ==, in, notin.\nFor example, we can filter by annotations, like label selector\nkubectl get deploy --field-selector=\"metadata.annotations['test.io'] in (value1, value2)\"  Lean More\nSearch by Parent or Ancestor Owner There will usually be an Owner relationship between Kubernetes resources.\napiVersion: v1 kind: Pod metadata: ownerReferences: - apiVersion: apps/v1 blockOwnerDeletion: true controller: true kind: ReplicaSet name: fake-pod-698dfbbd5b uid: d5bf2bdd-47d2-4932-84fb-98bde486d244  Searching by Owner is a very useful search function, and Clusterpedia also supports the seniority advancement of Owner to search for grandparents and even higher seniority.\nBy searching by Owner, we can query all Pods under Deployment at once, without having to query ReplicaSet in between\n Currently only supports query by Owner UID. The feature of using Owner Name for queries is still under discussion, we can join the discussion in the issue: Support for searching resources by owner\n $ DEPLOY_UID=$(kubectl --cluster cluster-1 get deploy fake-deploy -o jsonpath=\"{.metadata.uid}\") $ kubectl --cluster cluster-1 get pods -l \\ \"internalstorage.clusterpedia.io/owner-uid=$DEPLOY_UID,\\ internalstorage.clusterpedia.io/owner-seniority=1\"  Lean More\nThe number of remaining items carried in response data In some UI cases, it is often necessary to get the total number of resources in the current search condition.\nThe RemainingItemCount field exists in the ListMeta of the Kubernetes List response.\ntype ListMeta struct { ... // remainingItemCount is the number of subsequent items in the list which are not included in this // list response. If the list request contained label or field selectors, then the number of // remaining items is unknown and the field will be left unset and omitted during serialization. // If the list is complete (either because it is not chunking or because this is the last chunk), // then there are no more remaining items and this field will be left unset and omitted during // serialization. // Servers older than v1.15 do not set this field. // The intended use of the remainingItemCount is *estimating* the size of a collection. Clients // should not rely on the remainingItemCount to be set or to be exact. // +optional RemainingItemCount *int64 `json:\"remainingItemCount,omitempty\" protobuf:\"bytes,4,opt,name=remainingItemCount\"` }  By reusing this field, the total number of resources can be returned in a Kubernetes OpenAPI-compatible manner:\noffset + len(list.items) + list.metadata.remainingItemCount\n Use with Paging\n $ kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?withRemainingCount\u0026limit=1\" | jq { \"kind\": \"DeploymentList\", \"apiVersion\": \"apps/v1\", \"metadata\": { \"remainingItemCount\": 23 }, \"items\": [ ... ] }  Lean More\nRealease v0.1.0 ","categories":"","description":"","excerpt":"This is the first release of Clusterpedia 🥳🥳🥳, and it also means that …","ref":"/blog/2022/02/16/clusterpedia-v0.1.0-release-four-important-functions/","tags":"","title":"Clusterpedia v0.1.0 Release — four important functions"},{"body":"Clusterpedia 第一个版本 – Clusterpedia 0.1.0 正式发布，即日起进入版本迭代阶段。相比于初期的 0.0.8 和 0.0.9-alpha，0.1.0 添加了很多功能，并且做了一些不兼容的更新。\n如果由 0.0.9-alpha 升级的话，可以参考 Upgrade to Clusterpedia 0.1.0\n重要功能 我们先介绍一下在 0.1.0 中增加的四大重要的功能：\n 对 Not Ready 的集群进行资源检索时，增加了 Warning 提醒 增强了原生 Field Selector 的能力 根据父辈或者祖辈的 Owner 来进行查询 响应数据携带 remaining item count  v0.1.0 Release Notes\n资源检索时的 Warning 提醒 集群由于某些原因处于非 Ready 的状态时，资源通常也无法正常同步，在获取到该集群内的资源时，会通过 Warnning 提醒来告知用户集群异常，并且获取到的资源可能并不是实时准确的。\n$ kubectl get pediacluster NAME APISERVER VERSION STATUS cluster-1 https://10.6.100.10:6443 v1.22.2 ClusterSynchroStop $ kubectl --cluster cluster-1 get pods Warning: cluster-1 is not ready and the resources obtained may be inaccurate, reason: ClusterSynchroStop CLUSTER NAME READY STATUS RESTARTS AGE cluster-1 fake-pod-698dfbbd5b-64fsx 1/1 Running 0 68d cluster-1 fake-pod-698dfbbd5b-9ftzh 1/1 Running 0 39d cluster-1 fake-pod-698dfbbd5b-rk74p 1/1 Running 0 39d cluster-1 quickstart-ingress-nginx-admission-create--1-kxlnn 0/1 Completed 0 126d 强化 Field Selector 原生 kubernetes 对于 Field Selector 的支持非常有限，默认只支持 metadata.namespace 和 metadata.name 字段的过滤，尽管一些特定的资源会支持一些特殊的字段，但是使用起来还是比较局限，操作符只能支持 =, ==, !=。\nClusterpedia 在兼容原生 Field Selector 的基础上，不仅仅支持了更加灵活的字段过滤，还支持和 Label Selector 相同的操作符：!, =, !=, ==, in, notin。\n例如我们可以像 label selector 一样，通过 annotations 过滤资源。\nkubectl get deploy --field-selector=\"metadata.annotations['test.io'] in (value1, value2)\" Lean More\n根据父辈或者祖辈 Owner 进行查询 Kubernetes 资源之间通常会存在一种 Owner 关系, 例如：\napiVersion:v1kind:Podmetadata:ownerReferences:- apiVersion:apps/v1blockOwnerDeletion:truecontroller:truekind:ReplicaSetname:fake-pod-698dfbbd5buid:d5bf2bdd-47d2-4932-84fb-98bde486d244Clusterpedia 不仅支持根据 Owner 查询，还支持对 Owner 进行辈分提升来根据祖辈或者更高辈分的 Owner 来检索资源。\n例如可以通过 Deployment 获取相应的所有 pods。\n 当前暂时只支持通过Owner UID 来查询资源, 使用 Owner Name 来进行查询的功能尚在讨论中，可以在 issue: Support for searching resources by owner 参与讨论。 v0.2.0 中已经支持通过 Owner name 进行查询\n $ DEPLOY_UID=$(kubectl --cluster cluster-1 get deploy fake-deploy -o jsonpath=\"{.metadata.uid}\") $ kubectl --cluster cluster-1 get pods -l \\  \"internalstorage.clusterpedia.io/owner-uid=$DEPLOY_UID,\\ internalstorage.clusterpedia.io/owner-seniority=1\" Lean More\n响应数据内携带剩余资源数量 在一些 UI 场景下，往往需要获取当前检索条件下的资源总量。\nKubernetes 响应的 ListMeta 中 RemainingItemCount 字段表示剩余的资源数量。\ntype ListMeta struct { ... // remainingItemCount is the number of subsequent items in the list which are not included in this  // list response. If the list request contained label or field selectors, then the number of  // remaining items is unknown and the field will be left unset and omitted during serialization.  // If the list is complete (either because it is not chunking or because this is the last chunk),  // then there are no more remaining items and this field will be left unset and omitted during  // serialization.  // Servers older than v1.15 do not set this field.  // The intended use of the remainingItemCount is *estimating* the size of a collection. Clients  // should not rely on the remainingItemCount to be set or to be exact.  // +optional  RemainingItemCount *int64 `json:\"remainingItemCount,omitempty\" protobuf:\"bytes,4,opt,name=remainingItemCount\"` } 复用 ListMeta.RemainingItemCount，通过简单计算便可以获取当前检索条件下的资源总量: total = offset + len(list.items) + list.metadata.remainingItemCount\n 该功能需要搭配分页功能一起使用\n $ kubectl get --raw=\"/apis/clusterpedia.io/v1beta1/resources/apis/apps/v1/deployments?withRemainingCount\u0026limit=1\" | jq { \"kind\": \"DeploymentList\", \"apiVersion\": \"apps/v1\", \"metadata\": { \"remainingItemCount\": 24 }, \"items\": [ ... ] } Lean More\n","categories":"","description":"","excerpt":"Clusterpedia 第一个版本 – Clusterpedia 0.1.0 正式发布，即日起进入版本迭代阶段。相比于初期的 0.0.8  …","ref":"/zh-cn/blog/2022/02/16/%E9%A6%96%E5%8F%91clusterpedia-0.1.0-%E5%9B%9B%E5%A4%A7%E9%87%8D%E8%A6%81%E5%8A%9F%E8%83%BD/","tags":"","title":"首发｜Clusterpedia 0.1.0 四大重要功能"},{"body":"With the release of Clusterpedia 0.1.0, we can now update the earlier 0.0.9-alpha or 0.0.8 to 0.1.0\nClean Resources Since the url path to search resources has been modified(#73), we need to use cealn-clusterconfigs.sh in 0.0.9-alpha to clean up the cluster shortcut in the .kube/config\ncurl -sfL https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/v0.0.9-alpha/hack/clean-clusterconfigs.sh | sh - Backup and delete the PediaCluster resources.\nkubectl get pediacluster -o yaml \u003e clusters.yaml.bak kubectl delete pediacluster --all After all PediaCluster resources have been deleted, remove the PediaCluster CRD\nkubectl delete crd pediaclusters.clusters.clusterpedia.io Remove the APIServices used to register the Aggregated API\nkubectl delete apiservices v1alpha1.pedia.clusterpedia.io Upgrade Clusterpedia Create PediaCluster CRD, and upgrade Clusterpedia APIServer and Clustersynchro Manager.\nDEPLOY_YAML_PATH=https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/v0.1.0/deploy CRD_YAML_PATH=$DEPLOY_YAML_PATH/crds kubectl apply -f \\  $CRD_YAML_PATH/cluster.clusterpedia.io_pediaclusters.yaml,\\  $DEPLOY_YAML_PATH/clusterpedia_clustersynchro_manager_deployment.yaml,\\  $DEPLOY_YAML_PATH/clusterpedia_apiserver_deployment.yaml,\\  $DEPLOY_YAML_PATH/clusterpedia_apiserver_apiservice.yaml We can also download the YAML locally, or pull the clusterpedia locally and go to ./deploy directory and run kubectl apply\nRe-import the clusters Since the APIVersion and schema of PediaCluster have been optimized for incompatibility, it it necessary to recreate PediaCluster based on the backed up clusters.yaml.bak.\nThe current example of PediaCluster:\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:cluster-examplespec:apiserver:\"https://10.30.43.43:6443\"caData:tokenData:certData:keyData:syncResources:- group:appsresources:- deployments- group:\"\"resources:- podsThere are three main changes compared to 0.0.9-alpha:\n apiVersion: clusters.clusterpedia.io/v1alpha1 -\u003e cluster.clusterpedia.io/v1alpha2 spec.apiserverURL -\u003e spec.apiserver spec.resources -\u003e spec.syncResources   The specific changes can be viewed: #70 #67 #76 #77\n Create new pediaclusters based on the old pediaclusters in clusters.yaml.bak\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:cluster-1spec:{}---apiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:cluster-2spec:{}View clusters status\nkubectl get pediacluster Configure the cluster shortcut for kubectl\ncurl -sfL https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/v0.1.0/hack/gen-clusterconfigs.sh | sh - ","categories":"","description":"","excerpt":"With the release of Clusterpedia 0.1.0, we can now update the earlier …","ref":"/blog/2022/02/15/upgrade-to-clusterpedia-0.1.0/","tags":"","title":"Upgrade to Clusterpedia 0.1.0"},{"body":"随着 Clusterpedia 0.1.0 版本的发布，我们可以将早期的 0.0.9-alpha 或者 0.0.8 更新到 0.1.0 了。\n旧版本资源清理 由于资源检索的路径发生了修改(#73)，所以需要使用 0.0.9-alpha 的 clean-clusterconfigs.sh 来清理 .kube/config 中的 Clusterpedia 集群访问配置\ncurl -sfL https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/v0.0.9-alpha/hack/clean-clusterconfigs.sh | sh - 备份并删除 PediaCluster 资源\nkubectl get pediacluster -o yaml \u003e clusters.yaml.bak kubectl delete pediacluster --all 所有的 PediaCluster 资源都删除后，删除 PediaCluster CRD\nkubectl delete crd pediaclusters.clusters.clusterpedia.io 删除用于注册聚合式 API 的 APIServices\nkubectl delete apiservices v1alpha1.pedia.clusterpedia.io 更新 Clusterpedia 新建 PediaCluster CRD, 并且更新 Clusterpedia APIServer 和 Clustersynchro Manager\nDEPLOY_YAML_PATH=https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/v0.1.0/deploy CRD_YAML_PATH=$DEPLOY_YAML_PATH/crds kubectl apply -f \\  $CRD_YAML_PATH/cluster.clusterpedia.io_pediaclusters.yaml,\\  $DEPLOY_YAML_PATH/clusterpedia_clustersynchro_manager_deployment.yaml,\\  $DEPLOY_YAML_PATH/clusterpedia_apiserver_deployment.yaml,\\  $DEPLOY_YAML_PATH/clusterpedia_apiserver_apiservice.yaml 可以将 YAML 下载到本地，或者拉取项目到本地，进入 ./deploy 目录下执行 kubectl apply。\n重新接入集群 由于 PediaCluster 的 APIVersion 和结构都进行了一些不兼容的优化，所以需要重新根据备份的 clusters.yaml.bak 来重新创建 PediaCluster。\n当前 PediaCluster 的示例为：\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:cluster-examplespec:apiserver:\"https://10.30.43.43:6443\"caData:tokenData:certData:keyData:syncResources:- group:appsresources:- deployments- group:\"\"resources:- pods相比 0.0.9-alpha 主要有三个修改：\n apiVersion 由 clusters.clusterpedia.io/v1alpha1 -\u003e cluster.clusterpedia.io/v1alpha2 spec.apiserverURL -\u003e spec.apiserver spec.resources -\u003e spec.syncResources   具体的修改可以查看: #70 #67 #76 #77\n 根据 clusters.yaml.bak 内旧的 PediaCluster 来创建新的 PediaCluster。\napiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:cluster-1spec:{}---apiVersion:cluster.clusterpedia.io/v1alpha2kind:PediaClustermetadata:name:cluster-2spec:{}查看集群接入状态\nkubectl get pediacluster 为多集群检索生成快捷访问配置\ncurl -sfL https://raw.githubusercontent.com/clusterpedia-io/clusterpedia/v0.1.0/hack/gen-clusterconfigs.sh | sh - ","categories":"","description":"","excerpt":"随着 Clusterpedia 0.1.0 版本的发布，我们可以将早期的 0.0.9-alpha 或者 0.0.8 更新到 0.1.0 了。 …","ref":"/zh-cn/blog/2022/02/15/%E5%8D%87%E7%BA%A7%E5%88%B0-clusterpedia-0.1.0/","tags":"","title":"升级到 Clusterpedia 0.1.0"},{"body":"This name Clusterpedia is inspired by Wikipedia. It is an encyclopedia of multi-cluster to synchronize, search for, and simply control multi-cluster resources. Clusterpedia can synchronize resources with multiple clusters and provide more powerful search features on the basis of compatibility with Kubernetes OpenAPI to help you effectively get any multi-cluster resource that you are looking for in a quick and easy way.\n The capability of Clusterpedia is not only to search for and view but also simply control resources in the future, just like Wikipedia that supports for editing entries.\n Architecture  The architecture diagram of Clusterpedia is as follows:\n The architecture consists of four parts:  Clusterpedia APIServer: Register to Kube APIServer by the means of Aggregated API and provide services through a unified entrance ClusterSynchro Manager: Manage the Cluster Synchro that is used to synchronize cluster resources Storage Layer: Connect with a specific storage component and then register to Clusterpedia APIServer and ClusterSynchro Manager via a storage interface Storage component: A specific storage facility such as MySQL, postgres, redis or other graph databases  In addition, Clusterpedia will use the custom resource PediaCluster to implement cluster authentication and synchronize the resource configuration.\nClusterpedia also provides a default storage layer that can connect with MySQL and postgres.\n Clusterpedia does not care about the specific storage settings used by users, you can choose or implement the storage layer according to your own needs and then register the storage layer in Clusterpedia as a plug-in\n Features  Support for complex search, filters, sorting, paging, and more Support for requesting relevant resources when you query resources Unify the search entry for master clusters and multi-cluster resources Compatible with kubernetes OpenAPI, where you can directly use kubectl for multi-cluster search without any third-party plug-ins or tools Compatible with synchronizing different versions of cluster resources, not restricted by the version of master cluster High performance and low memory consumption for resource synchronization Automatically start/stop resource synchronization according to the current health status of the cluster -Support for plug-in storage layer. You can use other storage components to customize the storage layer according to your needs. High availability   The above unimplemented features are already in the Roadmap\n Deployment For details on the deployment process, see Instaling Clusterpedia, which highlights how to use clusterpedia.\nSynchronize cluster resources After deploying clusterpedia crds, you can use kubectl to operate PediaCluster resources.\n$ kubectl get pediaclusters In the examples directory, you can check examples of PediaCluster:\napiVersion:clusters.clusterpedia.io/v1alpha1kind:PediaClustermetadata:name:cluster-examplespec:apiserverURL:\"https://10.30.43.43:6443\"caData:\"\"tokenData:\"\"certData:\"\"keyData:\"\"resources:- group:appsresources:- deployments- group:\"\"resources:- podsThe configuration of PediaCluster can be divided into two parts:\n Cluster authentication Synchronize a specific resource .spec.resources  Cluster authentication The fields of caData, tokenData, certData, and keyData can be used for cluster verification.\n Currently it does not support for getting the relevant verification information from ConfigMap or Secret. However, the information is already in the Roadmap.\n When setting the verification field, you shall use the strings encoded by base64.\nThe . /examples directory provides the rbac yaml clusterpedia_synchro_rbac.yaml, which can be used to easily obtain the permission token for a subcluster.\nDeploy the yaml in the subcluster and get the proper token and CA certificate.\n$ # Switch to the sub-cluster to create rbac related resources $ kubectl apply -f examples/clusterpedia_synchro_rbac.yaml $ SYNCHRO_TOKEN=$(kubectl get secret $(kubectl get serviceaccount clusterpedia-synchro -o jsonpath='{.secrets[0].name}') -o jsonpath='{.data.token}') $ SYNCHRO_CA=$(kubectl get secret $(kubectl get serviceaccount clusterpedia-synchro -o jsonpath='{.secrets[0].name}') -o jsonpath='{.data.ca\\.crt}') Copy ./examples/pediacluster.yaml, modify .spec.apiserverURL and .metadata.name fields, and fill $SYNCHRO_TOKEN and $SYNCHRO_CA into tokenData and caData.\n$ kubectl apply -f cluster-1.yaml pediacluster.clusters.clusterpedia.io/cluster-1 created Synchronize resources You can specify the synchronized resources by setting group in the spec.resources field and the resources section under group.\nYou can also view the resource synchronization status in the status section:\nstatus: conditions: - lastTransitionTime: \"2021-12-02T04:00:45Z\" message: \"\" reason: Healthy status: \"True\" type: Ready resources: - group: \"\" resources: - kind: Pod namespaced: true resource: pods syncConditions: - lastTransitionTime: \"2021-12-02T04:00:45Z\" status: Syncing storageVersion: v1 version: v1 - group: apps resources: - kind: Deployment namespaced: true resource: deployments syncConditions: - lastTransitionTime: \"2021-12-02T04:00:45Z\" status: Syncing storageVersion: v1 version: v1 version: v1.22.2 Search for resources After configuring the resources to be synchronized, you can search for the cluster resources. Clusterpedia supports two types of resource search:\n Search for resources that are compatible with Kubernetes OpenAPI Search for Collection Resource  $ kubectl api-resources | grep pedia.clusterpedia.io collectionresources pedia.clusterpedia.io/v1alpha1 false CollectionResource resources pedia.clusterpedia.io/v1alpha1 false Resources In order to facilitate and well use kubectl for searching, you’d better create a ‘shortcut’ for searching the sub-cluster through make gen-clusterconfig:\n$ make gen-clusterconfigs ./hack/gen-clusterconfigs.sh Current Context: kubernetes-admin@kubernetes Current Cluster: kubernetes Server: https://10.6.11.11:6443 TLS Server Name: Insecure Skip TLS Verify: Certificate Authority: Certificate Authority Data: *** Cluster \"clusterpedia\" set. Cluster \"cluster-1\" set. Use the kubectl config get-clusters command to view the currently supported clusters.\nIn this case, Clusterpedia is a special cluster used to search for multi-clusters by using kubectl --cluster clusterpedia.\nMulti-cluster resource search First check which resources are synchronized. You cannot find a resource until it is properly synchronized:\n$ kubectl --cluster clusterpedia api-resources NAME SHORTNAMES APIVERSION NAMESPACED KIND pods po v1 true Pod deployments deploy apps/v1 true Deployment You can check the currently synchronized resources including pods and deployments.apps.\nGet deployments in the kube-system namespace of all clusters:\n$ kubectl --cluster clusterpedia get deployments -n kube-system CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE cluster-1 coredns 2/2 2 2 68d cluster-2 calico-kube-controllers 1/1 1 1 64d cluster-2 coredns 2/2 2 2 64d Get deployments in the two namespaces kube-system and default of all clusters:\n$ kubectl --cluster clusterpedia get deployments -A -l \"search.clusterpedia.io/namespaces in (kube-system, default)\" NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kube-system cluster-1 coredns 2/2 2 2 68d kube-system cluster-2 calico-kube-controllers 1/1 1 1 64d kube-system cluster-2 coredns 2/2 2 2 64d default cluster-2 dd-airflow-scheduler 0/1 1 0 54d default cluster-2 dd-airflow-web 0/1 1 0 54d default cluster-2 hello-world-server 1/1 1 1 27d default cluster-2 keycloak 1/1 1 1 52d default cluster-2 keycloak-02 1/1 1 1 41d default cluster-2 my-nginx 1/1 1 1 40d default cluster-2 nginx-dev 1/1 1 1 15d default cluster-2 openldap 1/1 1 1 41d default cluster-2 phpldapadmin 1/1 1 1 41d Get deployments in the kube-system and default namespaces in cluster-1 and cluster-2:\n$ kubectl --cluster clusterpedia get deployments -A -l \"search.clusterpedia.io/clusters in (cluster-1, cluster-2),\\ search.clusterpedia.io/namespaces in (kube-system,default)\" NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kube-system cluster-1 coredns 2/2 2 2 68d kube-system cluster-2 calico-kube-controllers 1/1 1 1 64d kube-system cluster-2 coredns 2/2 2 2 64d default cluster-2 dd-airflow-scheduler 0/1 1 0 54d default cluster-2 dd-airflow-web 0/1 1 0 54d default cluster-2 hello-world-server 1/1 1 1 27d default cluster-2 keycloak 1/1 1 1 52d default cluster-2 keycloak-02 1/1 1 1 41d default cluster-2 my-nginx 1/1 1 1 40d default cluster-2 nginx-dev 1/1 1 1 15d default cluster-2 openldap 1/1 1 1 41d default cluster-2 phpldapadmin 1/1 1 1 41d Get deployments in the kube-system and default namespaces in cluster-1 and cluster-2:\n$ kubectl --cluster clusterpedia get deployments -A -l \"search.clusterpedia.io/clusters in (cluster-1, cluster-2),\\ search.clusterpedia.io/namespaces in (kube-system,default),\\ search.clusterpedia.io/orderby=name\" NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kube-system cluster-2 calico-kube-controllers 1/1 1 1 64d kube-system cluster-1 coredns 2/2 2 2 68d kube-system cluster-2 coredns 2/2 2 2 64d default cluster-2 dao-2048-2048 1/1 1 1 21d default cluster-2 dd-airflow-scheduler 0/1 1 0 54d default cluster-2 dd-airflow-web 0/1 1 0 54d default cluster-2 hello-world-server 1/1 1 1 27d default cluster-2 keycloak 1/1 1 1 52d default cluster-2 keycloak-02 1/1 1 1 41d default cluster-2 my-nginx 1/1 1 1 40d default cluster-2 nginx-dev 1/1 1 1 15d default cluster-2 openldap 1/1 1 1 41d default cluster-2 phpldapadmin 1/1 1 1 41d Search a specific cluster If you want to search a specific cluster for any resource therein, you can add –cluster to specify the cluster name:\n$ kubectl --cluster cluster-1 get deployments -A NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE calico-apiserver cluster-1 calico-apiserver 1/1 1 1 68d calico-system cluster-1 calico-kube-controllers 1/1 1 1 68d calico-system cluster-1 calico-typha 1/1 1 1 68d capi-system cluster-1 capi-controller-manager 1/1 1 1 42d capi-kubeadm-bootstrap-system cluster-1 capi-kubeadm-bootstrap-controller-manager 1/1 1 1 42d capi-kubeadm-control-plane-system cluster-1 capi-kubeadm-control-plane-controller-manager 1/1 1 1 42d capv-system cluster-1 capv-controller-manager 1/1 1 1 42d cert-manager cluster-1 cert-manager 1/1 1 1 42d cert-manager cluster-1 cert-manager-cainjector 1/1 1 1 42d cert-manager cluster-1 cert-manager-webhook 1/1 1 1 42d clusterpedia-system cluster-1 clusterpedia-apiserver 1/1 1 1 27m clusterpedia-system cluster-1 clusterpedia-clustersynchro-manager 1/1 1 1 27m clusterpedia-system cluster-1 clusterpedia-internalstorage-mysql 1/1 1 1 29m kube-system cluster-1 coredns 2/2 2 2 68d tigera-operator cluster-1 tigera-operator 1/1 1 1 68d Except for search.clusterpedia.io/clusters, the support for other complex queries is same as that for multi-cluster search.\nIf you want to learn about the details of a resource, you need to specify which cluster it is:\n$ kubectl --cluster cluster-1 -n kube-system get deployments coredns -o wide CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR cluster-1 coredns 2/2 2 2 68d coredns registry.aliyuncs.com/google_containers/coredns:v1.8.4 k8s-app=kube-dns Complex search Clusterpedia supports for the following complex search:\n Specify one or more cluster names Specify one or more namespaces Specify one or more resource names Specify how to sort multiple fields Paging function, by which you can specify its size and offset filter by labels  The actual effect of field sorting depends on the storage layer. By default, the storage layer supports for sorting according to cluster, name, namespace, created_at, and resource_version in a normal or reverse order.\nHow search conditions are applied The above example demonstrates how you can use kubectl to search for resources. Where, complex search conditions are applied via a label. Clusterpedia also supports for using these search conditions directly through url query.\n   role label key url query example     Specified resource name search.clusterpedia.io/names names ?names=pod-1,pod-2   Specified namespace search.clusterpedia.io/namespaces namespaces ?namespaces=kube-system,default   Specified cluster name search.clusterpedia.io/clusters clusters ?clusters=cluster-1,cluster-2   Sort by specified fileds search.clusterpedia.io/orderby orderby ?orderby=name desc,namespace   Specified size search.clusterpedia.io/size size ?size=100   Specified offset search.clsuterpedia.io/offset offset ?offset=10    The operators of label key include ==, =, !=, in, not in. For the size condition, kubectl can specify a size by --chunk-size instead of the label key.\nCollection Resource Clusterpedia can also perform more advanced aggregation of resources. For example, you can use Collection Resource to get a set of different resources at once.\nLet’s first check which Collection Resource currently Clusterpedia supports:\n$ kubectl get collectionresources NAME RESOURCES workloads deployments.apps,daemonsets.apps,statefulsets.apps By getting workloads, you can get a set of resources aggregated by deployment, daemonset, and statefulset, and Collection Resource also supports for all complex queries.\nkubectl get collectionresources workloads will get the corresponding resources of all namespaces in all clusters by default:\n$ kubectl get collectionresources workloads CLUSTER GROUP VERSION KIND NAMESPACE NAME AGE cluster-1 apps v1 DaemonSet kube-system vsphere-cloud-controller-manager 63d cluster-2 apps v1 Deployment kube-system calico-kube-controllers 109d cluster-2 apps v1 Deployment kube-system coredns-coredns 109d  Add the collection of Daemonset in cluster-1 and some of the above output is cut out\n Due to the limitation of kubectl, you cannot use complex queries in kubectl and can only be queried by url query.\nProposal Perform more complex control over resources In addition to resource search, similar to Wikipedia, Clusterpedia should also have simple capability of resource control, such as watch, create, delete, update, and more.\nIn fact, a write action is implemented by double write + response.\nWe will discuss this feature and decide whether we should implement it according to the community needs\nAutomatic discovery and resource synchronization The resource used to represent the cluster in Clusterpedia is called PediaCluster, not a simple Cluster.\n**This is because Clusterpedia was originally designed to build on the existing multi-cluster management platform. **\nIn order to keep the original intention, the first issue is that Clusterpedia should not conflict with the resources in the existing multi-cluster platform. Cluster is a very common resource name that represents a cluster.\nIn addition, in order to better connect with the existing multi-cluster platform and enable the connected clusters automatically complete resource synchronization, we need a new mechanism to discover clusters. This discovery mechanism needs to solve the following issues:\n Get the authentication info to access the cluster Configure conditions that trigger the lifecycle of PediaCluster Set the default policy and prefix name for resource synchronization  This feature will be discussed and implemented in detail in Q1 or Q2 2022.\nRoadmap Currently, it is only a tentative roadmap and the specific schedule depends on the community needs.\nAbout some features not added to Roadmap, you can discuss in issues.\nQ4 2021  Support for cropping field Synchronize custom resources  Q1 2022  Support for the plug-in storage layer Implement automatic discovery and resource synchronization  Q2 2022  Support for more control over cluster resources, such as watch/create/update/delete operations The storage layer supports for custom Collection Resource by default Support for requests with relevant resources  Remarks Multi-cluster network connectivity Clusterpedia does not actually solve the problem of network connectivity in a multi-cluster environment. You can use tools such as tower to connect and access sub-clusters, or use submariner or skupper to solve cross-cluster network problems.\n","categories":"","description":"","excerpt":"This name Clusterpedia is inspired by Wikipedia. It is an encyclopedia …","ref":"/blog/2021/12/03/clusterpedia-with-kubectl-support-to-retrieve-multicluster-resources/","tags":"","title":"Clusterpedia with kubectl support to retrieve multicluster resources"},{"body":"在多集群时代，我们可以通过 cluster-api 来批量创建管理集群，使用 Karmada/Clusternet 来分发部署应用。\n不过我们貌似还是缺少了什么功能，我们要如何去统一的查看多个集群中的资源呢？\n对于单个集群的资源，我们可以使用 kubectl 来查看搜索资源，但是在想要检索多集群的资源时，貌似没有什么趁手的产品可以使用。\n不过从今天开始，这个问题不会再困扰你，因为在 Clusterpedia 的加持下，你手上的 kubectl 已经可以用来检索多集群资源啦。\n例如，使用 kubectl 来获取多个集群下 kube-system 命名空间内的 deployments。\n$ kubectl get deployments -n kube-system CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE cluster-1 calico-kube-controllers 1/1 1 1 63d cluster-1 coredns 2/2 2 2 63d cluster-2 calico-kube-controllers 1/1 1 1 109d cluster-2 coredns-coredns 2/2 2 2 109d cluster-2 dce-chart-manager 1/1 1 1 109d cluster-2 dce-clair 1/1 1 1 109d Clusterpedia 介绍 Clusterpedia，名字借鉴自 Wikipedia，同样也展现了 Clusterpedia 的核心理念 —— 多集群的百科全书。\n通过聚合多集群资源，在兼容 Kubernetes OpenAPI 的基础上额外提供了更加强大的检索功能，让用户更快更方便的在多集群中获取到想要的任何资源。\n当然 Clusterpedia 的能力并不仅仅只是检索查看，未来还会支持对资源的简单控制，就像 wiki 同样支持编辑词条一样。\n架构设计  Clusterpedia 在架构上分为四个部分：  Clusterpedia APIServer：以 Aggregated API 的方式注册到 Kube APIServer，通过统一的入口来提供服务。 ClusterSynchro Manager：管理用于同步集群资源的 Cluster Synchro。 Storage Layer (存储层)：用来连接操作具体的存储组件，然后通过存储层接口注册到 Clusterpedia APIServer 和 ClusterSynchro Manager 中。 存储组件：具体的存储设施，例如 mysql， postgres，redis 或者其他图数据库。 另外，Clusterpedia 会使用 PediaCluster 这个自定义资源来实现集群认证和资源收集配置  Clusterpedia 还提供了可以接入 mysql 和 postgres 的默认存储层。\nClusterpedia 并不关心用户所使用的具体存储设置是什么，用户可以根据自己的需求来选择或者实现存储层，然后将存储层以插件的形式注册到 Clusterpedia 中来使用。\n特性和功能  支持复杂的检索条件，过滤条件，排序，分页等等 支持查询资源时请求附带关系资源 统一主集群和多集群资源检索入口 兼容 kubernetes OpenAPI, 可以直接使用 kubectl 进行多集群检索, 而无需第三方插件或者工具 兼容收集不同版本的集群资源，不受主集群版本约束， 资源收集高性能，低内存 根据集群当前的健康状态，自动启停资源收集 插件化存储层，用户可以根据自己需求使用其他存储组件来自定义存储层 高可用  部署 关于部署的详细流程，可以查看 安装 Clusterpedia，这里着重介绍了如何使用 clusterpedia。\n集群资源收集 clusterpedia 部署完成后，我们可以通过 kubectl 来操作 PediaCluster 资源。\n$ kubectl get pediaclusters 在 examples 目录下，可以看到 PediaCluster 的示例\napiVersion:clusters.clusterpedia.io/v1alpha1kind:PediaClustermetadata:name:cluster-examplespec:apiserverURL:\"https://172.30.43.41:6443\"caData:\"\"tokenData:\"\"certData:\"\"keyData:\"\"resources:- group:appsresources:- deployments- group:\"\"resources:- podsPediaCluster 在配置上可以分成两部分\n 集群认证 指定资源收集 .spec.resources  集群认证 caData , tokenData , certData , keyData 字段用于集群的验证。\n当前暂时不支持从 ConfigMap 或者 Secret 中获取验证相关的信息，不过已经在 Roadmap 中了。\n在设置验证字段时，注意要使用 base64 后的字符串\n在 examples 目录下提供了生成用于访问子集群的 rbac yaml clusterpedia_synchro_rbac.yaml，来方便的获取子集群的权限 token。\n在子集群中部署该 yaml，然后获取对应的 token 和 ca 证书。\n$ # 当前 kubectl 连接到子集群中 $ kubectl apply -f examples/clusterpedia_synchro_rbac.yaml clusterrole.rbac.authorization.k8s.io/clusterpedia-synchro created serviceaccount/clusterpedia-synchro created clusterrolebinding.rbac.authorization.k8s.io/clusterpedia-synchro created $ SYNCHRO_TOKEN=$(kubectl get secret $(kubectl get serviceaccount clusterpedia-synchro -o jsonpath='{.secrets[0].name}') -o jsonpath='{.data.token}') $ SYNCHRO_CA=$(kubectl get secret $(kubectl get serviceaccount clusterpedia-synchro -o jsonpath='{.secrets[0].name}') -o jsonpath='{.data.ca\\.crt}') 复制 ./examples/pediacluster.yaml, 并修改 .spec.apiserverURL 和 .metadata.name 字段，并且将 $SYNCHRO_TOKEN 和 $SYNCHRO_CA 填写到 tokenData 和 caData 中。\n使用 kubectl apply 创建。\n$ kubectl apply -f cluster-1.yaml pediacluster.clusters.clusterpedia.io/cluster-1 created 为了方便后续使用，建议再创建一个 cluster-2\n集群收集 可以通过设置 spec.resources 字段的 group 和 group 下的 resources 来进行指定收集的资源。\n在 status 中我们也可以看到资源的收集状态。\nstatus:conditions:- lastTransitionTime:\"2021-12-02T04:00:45Z\"message:\"\"reason:Healthystatus:\"True\"type:Readyresources:- group:\"\"resources:- kind:Podnamespaced:trueresource:podssyncConditions:- lastTransitionTime:\"2021-12-02T04:00:45Z\"status:SyncingstorageVersion:v1version:v1- group:appsresources:- kind:Deploymentnamespaced:trueresource:deploymentssyncConditions:- lastTransitionTime:\"2021-12-02T04:00:45Z\"status:SyncingstorageVersion:v1version:v1version:v1.22.2资源检索 配置好我们需要收集的资源后，我们就可以进行重头戏了 —— 集群检索\nclusterpedia 支持两种资源检索:\n 兼容 Kubernetes OpenAPI 的资源检索 集合资源 (Collection Resource) 的检索  $ kubectl api-resources | grep pedia.clusterpedia.io collectionresources pedia.clusterpedia.io/v1alpha1 false CollectionResource resources pedia.clusterpedia.io/v1alpha1 false Resources 为了方便我们更好的使用 kubectl 来进行检索，我们可以先通过 make gen-clusterconfig 来为子集群创建用于检索的 ‘快捷方式’。\n$ make gen-clusterconfigs ./hack/gen-clusterconfigs.sh Current Context: kubernetes-admin@kubernetes Current Cluster: kubernetes Server: https://10.9.11.11:6443 TLS Server Name: Insecure Skip TLS Verify: Certificate Authority: Certificate Authority Data: *** Cluster \"clusterpedia\" set. Cluster \"cluster-1\" set. 使用 kubectl config get-clusters 可以查看当前支持的集群。\n其中 clusterpedia 是一个特殊的 cluster，用于多集群检索，以 kubectl –cluster clusterpedia 的方式来检索多个集群的资源。\n多集群资源检索 我们先看一下我们都收集了哪些资源，只有被收集的资源才可以进行检索。\n$ kubectl --cluster clusterpedia api-resources NAME SHORTNAMES APIVERSION NAMESPACED KIND pods po v1 true Pod deployments deploy apps/v1 true Deployment 可以看到当前收集并支持 pods 和 deployments.apps 两种资源\n查看所有集群的 kube-system 命名空间下的 deployments\n$ kubectl --cluster clusterpedia get deployments -n kube-system CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE cluster-1 calico-kube-controllers 1/1 1 1 63d cluster-1 coredns 2/2 2 2 63d cluster-2 calico-kube-controllers 1/1 1 1 109d cluster-2 coredns-coredns 2/2 2 2 109d cluster-2 dce-chart-manager 1/1 1 1 109d cluster-2 dce-clair 1/1 1 1 109d 查看所有集群的 kube-system, default 命名空间下的 deployments\n$ kubectl --cluster clusterpedia get deployments -A -l \"search.clusterpedia.io/namespaces in (kube-system, default)\" 查看 cluster-1, cluster-2 两个集群下的 kube-system, default 命名空间下中的 deployments\n$ kubectl --cluster clusterpedia get deployments -A -l \"search.clusterpedia.io/clusters in (cluster-1, cluster-2),\\ search.clusterpedia.io/namespaces in (kube-system,default)\" NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kube-system cluster-1 calico-kube-controllers 1/1 1 1 63d kube-system cluster-1 coredns 2/2 2 2 63d default cluster-1 dao-2048-2048 1/1 1 1 20d default cluster-1 hello-world-server 1/1 1 1 26d default cluster-1 my-nginx 1/1 1 1 39d default cluster-1 phpldapadmin 1/1 1 1 40d kube-system cluster-2 calico-kube-controllers 1/1 1 1 109d kube-system cluster-2 coredns-coredns 2/2 2 2 109d kube-system cluster-2 dce-chart-manager 1/1 1 1 109d kube-system cluster-2 dce-clair 1/1 1 1 109d 显示数据有删减，略多\n查看 cluster-1, cluster-2 两个集群下的 kube-system, default 命名空间下中的 deployments，并根据资源的名字排序\n$ kubectl --cluster clusterpedia get deployments -A -l \"search.clusterpedia.io/clusters in (cluster-1, cluster-2),\\ search.clusterpedia.io/namespaces in (kube-system,default),\\ search.clusterpedia.io/orderby=name\" kube-system cluster-1 calico-kube-controllers 1/1 1 1 63d kube-system cluster-2 calico-kube-controllers 1/1 1 1 109d kube-system cluster-1 coredns 2/2 2 2 63d kube-system cluster-2 coredns-coredns 2/2 2 2 109d default cluster-1 dao-2048-2048 1/1 1 1 20d kube-system cluster-2 dce-chart-manager 1/1 1 1 109d kube-system cluster-2 dce-clair 1/1 1 1 109d kube-system cluster-2 dce-registry 1/1 1 1 109d kube-system cluster-2 dce-uds-storage-server 1/1 1 1 109d default cluster-1 dd-airflow-scheduler 0/1 1 0 53d default cluster-1 dd-airflow-web 0/1 1 0 53d kube-system cluster-2 metrics-server 1/1 1 1 109d default cluster-1 my-nginx 1/1 1 1 39d default cluster-1 nginx-dev 1/1 1 1 14d default cluster-1 openldap 1/1 1 1 40d default cluster-1 phpldapadmin 1/1 1 1 40d 显示数据有删减，略多\n指定集群检索 我们如果想要检索指定集群的资源的话，我们可以使用 –cluster 来指定具体的集群名称\n$ kubectl --cluster cluster-1 get deployments -A NAMESPACE CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE kubeapps-oidc cluster-1 apach2-apache 1/1 1 1 35d kube-system cluster-1 calico-kube-controllers 1/1 1 1 63d cert-manager cluster-1 cert-manager 1/1 1 1 42d cert-manager cluster-1 cert-manager-cainjector 1/1 1 1 42d cert-manager cluster-1 cert-manager-webhook 1/1 1 1 42d kube-system cluster-1 coredns 2/2 2 2 63d default cluster-1 dao-2048-2048 1/1 1 1 20d kubernetes-dashboard cluster-1 dashboard-metrics-scraper 1/1 1 1 54d default cluster-1 dd-airflow-scheduler 0/1 1 0 53d default cluster-1 dd-airflow-web 0/1 1 0 53d 显示数据有删减，略多\n除了 http://search.clusterpedia.io/clusters 外其余的复杂查询的支持和多集群检索相同。\n如果我们要获取一个资源的详情，那么也是需要指定集群才可以。\n$ kubectl --cluster cluster-1 -n kube-system get deployments coredns CLUSTER NAME READY UP-TO-DATE AVAILABLE AGE cluster-1 apach2-apache 1/1 1 1 35d 复杂检索clusterpedia 支持以下复杂检索：\n 指定一个或者多个集群名称 指定一个或者多个命名空间 指定一个或者多个资源名称 指定多个字段的排序 分页功能，可以指定 size 和 offset labels 过滤  对于字段的排序，实际的效果是根据存储层来决定的，默认存储层支持根据 cluster , name , namespace , created_at , resource_version 进行正序或者倒序的排序。\n检索条件的传递方式 上面实例中，演示了使用 kubectl 来进行检索，而这些复杂的检索条件通过 label 来传递的。实际上 clusterpedia 还支持直接通过 url query 的传递这些检索条件。\n   功能 label key url query example     Specified resource name search.clusterpedia.io/names names ?names=pod-1,pod-2   Specified namespace search.clusterpedia.io/namespaces namespaces ?namespaces=kube-system,default   Specified cluster name search.clusterpedia.io/clusters clusters ?clusters=cluster-1,cluster-2   Sort by specified fileds search.clusterpedia.io/orderby orderby ?orderby=name desc,namespace   Specified size search.clusterpedia.io/size size ?size=100   Specified offset search.clsuterpedia.io/offset offset ?offset=10    search label key 的操作符支持 ==, =, !=, in, not in 对于 size 这个条件，实际上 kubectl 可以通过 –chunk-size 来指定，而不需要通过 label key。\n聚合资源(Collection Resource) 在 clusterpedia 还有对资源更加高级的聚合，使用 Collection Resource 可以一次性获取到一组不同类型的资源。\n可以先查看一下当前 clusterpedia 支持哪些 Collection Resource。\n$ kubectl get collectionresources NAME RESOURCES workloads deployments.apps,daemonsets.apps,statefulsets.apps 通过获取 workloads 便可获取到一组 deployment, daemonset, statefulset 聚合在一起的资源 而且 Collection Resource 同样支持所有的复杂查询。\nkubectl get collectionresources workloads 会默认获取所有集群下所有命名空间的相应资源。\n$ kubectl get collectionresources workloads CLUSTER GROUP VERSION KIND NAMESPACE NAME AGE cluster-1 apps v1 DaemonSet kube-system vsphere-cloud-controller-manager 63d cluster-2 apps v1 Deployment kube-system calico-kube-controllers 109d cluster-2 apps v1 Deployment kube-system coredns-coredns 109d cluster-2 apps v1 Deployment dce-acm-agent dce-acm-agent 84d 在 cluster-1 中增加收集 Daemonset, 输出有删减，太多\n由于 kubectl 的限制所以无法在 kubectl 来使用复杂查询，只能通过 url query 的方式来查询。\n自定义 Collection Resource Collection Resource 支持哪些资源是由存储层来提供，而默认存储层未来会支持自定义组合 Collection Resource。\n新特性议题 对资源进行更复杂的操作 clusterpedia 不仅仅只是用来做资源检索，和 wiki 一样，它也应该具有对资源简单的控制能力，例如 watch, create, delete, update 等操作。\n对于写操作，实际会采用双写 + 响应 warning 的方式来完成。\n感兴趣的话可以在 issue 中一起讨论。\n集群的自动发现与收集 clusterpedia 中用来表示集群的资源叫做 PediaCluster, 而不是简单的 Cluster，最主要的原因便是 clusterpedia 设计初衷便是让 clusterpedia 可以建立在已有的多集群管理平台之上。\n为了遵循初衷，第一个问题便是不能和已有的多集群平台中的资源冲突， Cluster 便是一个最通用的代表集群的资源名称。\n另外为了更好的去接入到已有的多集群平台上，让已经接入的集群可以自动的完成资源收集，我们需要另外的一个集群发现机制。这个发现机制需要解决以下问题：\n 能够获取到访问集群的认证信息 可以配置触发 PediaCluster 生命周期的 Condition 条件 设置默认的资源收集策略，以及名称前缀等  这个功能会在 Q1 或者 Q2 中开始详细讨论实现。\n当前进展 clusterpedia 当前处于比较早期的阶段 (v0.0.9-alpha)，核心功能刚刚完成，还有很多可以优化的地方，对于这些优化点也都提了对应的 issues，欢迎大家一起讨论\n这里简单说一些进入 v0.1.0 版本前的优化点:\n 从具有 Server-Side Apply 特性的集群中收集到的资源会带有很臃肿的 managedFields 字段， clustersynchro manager 模块会增加相应 feature gate，来允许用户在收集时裁减掉这个字段 同样的臃肿字段 annotations 中的 http://kubectl.kubernetes.io/last-applied-configuration，也要允许裁剪这个字段 在指定集群获取资源时，如果集群处于异常状态时，应该在响应中添加 warning 来提醒用户 对 PediaCluster 的状态信息有更准确的更新 弱网环境下，资源收集的优化  更多的优化项，大家可以在 issue 中提出新的想法。\nRoadmap 当前只是暂定的 Roadmap，具体的排期还要看社区的需求程度\n2021 Q4 在 2021 的 Q4 阶段会完成上述的优化项，并且完成对自定义资源的收集\n 详细化资源收集状态 自定义资源的收集  2022 Q1  支持插件化存储层 实现集群的自动发现和收集  2022 Q3  支持对集群资源更多的控制，例如 watch/create/update/delete 等操作 默认存储层支持自定义 Collection Resource 支持请求附带关系资源  使用注意 多集群网络连通 clusterpedia 实际并不会解决多集群环境下的网络连通问题，用户可以使用tower等工具来连接访问子集群，也可以借助 submariner 或者 skupper 来解决跨集群网络问题。\n","categories":"","description":"","excerpt":"在多集群时代，我们可以通过 cluster-api 来批量创建管理集群，使用 Karmada/Clusternet 来分发部署应用。\n不过我 …","ref":"/zh-cn/blog/2021/12/03/clusterpedia-%E5%8A%A0%E6%8C%81-kubectl%E6%A3%80%E7%B4%A2%E5%A4%9A%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90/","tags":"","title":"Clusterpedia 加持 kubectl，检索多集群资源"},{"body":" About Clusterpedia The Encyclopedia of Kubernetes clusters        This name Clusterpedia is inspired by Wikipedia.\nIt is an encyclopedia of multi-cluster to synchronize, search for, and simply control multi-cluster resources.\nClusterpedia can synchronize resources with multiple clusters and provide more powerful search features on the basis of compatibility with Kubernetes OpenAPI to help you effectively get any multi-cluster resource that you are looking for in a quick and easy way.\n    Features Support for complex search, filters, sorting, paging, and more Support for requesting relevant resources when you query resources Unify the search entry for master clusters and multi-cluster resources Compatible with kubernetes OpenAPI, where you can directly use kubectl for multi-cluster search without any third-party plug-ins or tools Compatible with synchronizing different versions of cluster resources, not restricted by the version of master cluster High performance and low memory consumption for resource synchronization Automatically start/stop resource synchronization according to the current health status of the cluster Support for plug-in storage layer. You can use other storage components to customize the storage layer according to your needs. High availability     ","categories":"","description":"","excerpt":" About Clusterpedia The Encyclopedia of Kubernetes clusters …","ref":"/about/","tags":"","title":"About Clusterpedia"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh-cn/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/installation/configuration/","tags":"","title":"Configuration"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/","tags":"","title":"Documentation"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/release-notes/","tags":"","title":"Release notes"},{"body":"Clusterpedia supports complex search for multi-cluster resources, specified cluster resoruces, and Collection Resources.\nAnd these complex search conditions can be passed to Clusterpedia APIServer in two ways:\n URL Query: directly pass query conditions as Query Search Labels: to keep compatible with Kubernetes OpenAPI, the search conditions can be set via Label Selector  Both Search Labels and URL Query support same operators as Label Selector:\n exist, not exist =, ==, != in, notin  In addition to conditional retrieval, Clusterpedia also enhances Field Selector to meet the filtering requirements by fields such as metadata.annotation or status.*.\nSearch by metadata  Supported Operators: ==, =, in.\n    Role search label key url query     Filter cluster names search.clusterpedia.io/clusters clusters   Filter namespaces search.clusterpedia.io/namespaces namespaces   Filter resource names search.clusterpedia.io/names names     Current, we don’t support operators such as !=, notin operators, if you have these needs or scenarios, you can discuss them in the issue.\n Fuzzy Search  Supported Operators: ==, =, in.\n This feature is expermental and only search label are available for now\n   Role search label key url query     Fuzzy Search for resource name internalstorage.clusterpedia.io/fuzzy-name -    Search by creation time interval  Supported Operators: ==, =.\n The search is based on the creation time interval of the resource, using a left-closed, right-open internval.\n   Role search label key url query     Search search.clusterpedia.io/since since   Before search.clusterpedia.io/before before    There are four formats for creation time:\n Unix Timestamp for ease of use will distinguish between units of s or ms based on the length of the timestamp. The 10-bit timestamp is in seconds, the 13-bit timestamp is in milliseconds. RFC3339 2006-01-02T15:04:05Z or 2006-01-02T15:04:05+08:00 UTC Date 2006-01-02 UTC Datetime 2006-01-02 15:04:05  Because of the limitation of the kube label selector, the search label only supports Unix Timestamp and UTC Date.\nAll formats are available using the url query method.\nSearch by Owner  Supported Operators: ==, =.\n    Role search label key url query     Specified Owner UID search.clusterpedia.io/owner-uid ownerUID   Specified Owner Name search.clusterpedia.io/owner-name ownerName   SPecified Owner Group Resource search.clusterpedia.io/owner-gr ownerGR   Specified Owner Seniority internalstorage.clusterpedia.io/owner-seniority ownerSeniority    Note that when specifying Owner UID, Owner Name and Owner Group Resource will be ignored.\nThe format of the Owner Group Resource is resource.group, for example deployments.apps or nodes.\nOrderBy  Supported Operators: =, ==, in.\n    Role search label key url query     Order by fields search.clusterpedia.io/orderby orderby    Paging  Supported Operators: =, ==.\n    Role search label key url query     Set page size search.clusterpedia.io/size limit   Set page offset search.clusterpedia.io/offset continue   Response required with Continue search.clusterpedia.io/with-continue withContinue   Response required with remaining count search.clusterpedia.io/with-remaining-count withRemainingCount     When you perform operations with kubectl, the page size can only be set via kubectl --chunk-size, because kubectl will set the default limit to 500.\n Label Selector Regardless of kubectl or URL, all Label Selectors that do not contain clusterpedia.io in the Key will be used as Label Selectors to filter resources.\nAll behaviors are consistent with those provided by Kubernetes.\n   Role kubectl url query     Filter by labels kubectl -l or kubectl --label-selector labelSelector    Field Selector Field Selector is consistent with Label Selector in terms of operators, and Clusterpedia also supports:\nexist, not exist, ==, =, !=, in, notin.\nAll command parameters for URL and kubectl are same as those for Field Selector.\n   Role kubectl url query     Filter by fields kubectl --field-selector fieldSelector    For details refer to:\n search for resources by filtering fields support field selector issue: support list field filtering  Advanced Search(Custom Conditional Search) Custom search is a feature provided by the default storage layer to meet more flexible and variable search needs of users.\n   Feature search label key url query     custom SQL used for filter - whereSQL    Custom search is not supported by search label, only url query can be used to pass custom search SQL.\nIn addition, this feature is still in alpha stage, you need to open the corresponding Feature Gate in clusterpedia apiserver, for details, please refer to Raw SQL Query\nCollectionResource URL Query The following URL Query belongs exclusively to Collection Resource.\n   Role url query example     get only the metadata of the resource onlyMetadata onlyMetadata=true   specify the groups of any collectionresource groups groups=apps,cert-manager.io/v1   specify the resources of any collectionresource resources resources=apps/deployments,batch/v1/cronjobs    ","categories":"","description":"","excerpt":"Clusterpedia supports complex search for multi-cluster resources, …","ref":"/docs/usage/search/","tags":"","title":"Search"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh-cn/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh-cn/tags/","tags":"","title":"Tags"},{"body":" 关于 Clusterpedia The Encyclopedia of Kubernetes clusters        Clusterpedia 这个名称借鉴自 Wikipedia，是多集群的百科全书，其核心理念是收集、检索和简单控制多集群资源。\n通过聚合收集多集群资源，在兼容 Kubernetes OpenAPI 的基础上额外提供更加强大的检索功能，让用户更方便快捷地在多集群中获取想要的任何资源。\n    支持的功能  支持复杂的检索条件、过滤条件、排序、分页等等 支持查询资源时请求附带关系资源 统一主集群和多集群资源检索入口 兼容 kubernetes OpenAPI，可以直接使用 kubectl 进行多集群检索，而无需第三方插件或者工具 兼容收集不同版本的集群资源，不受主集群版本约束 资源收集高性能，低内存 根据集群当前的健康状态，自动开始/停止资源收集 插件化存储层，用户可以根据自己需求使用其他存储组件自定义存储层 高可用      ","categories":"","description":"","excerpt":" 关于 Clusterpedia The Encyclopedia of Kubernetes clusters …","ref":"/zh-cn/about/","tags":"","title":"关于 Clusterpedia"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh-cn/docs/","tags":"","title":"文档"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh-cn/docs/release-notes/","tags":"","title":"版本日志"},{"body":"Clusterpedia 支持对 多个集群内资源，指定集群的资源 以及聚合资源 的复杂检索，\n并且这些复杂检索的条件可以通过两种方式传递给 Clusterpedia APIServer：\n URL Query：直接将查询条件作为 Query 来传递 Search Labels：为了兼容 Kubernetes OpenAPI，可以将查询条件设置在 Label Selector。  Search Labels 和 URL Query 都支持与 Label Selector 相同的操作符：\n exist，not exist =，==，!= in，notin  除了条件检索，Clusterpedia 还增强了 Field Selector ，满足我们通过 metadata.annotation 或者 status.* 等字段的过滤需求。\n元信息检索  支持的操作符：==，=，in。\n    作用 search label key url query     过滤集群名称 search.clusterpedia.io/clusters clusters   过滤命名空间 search.clusterpedia.io/namespaces namespaces   过滤资源名称 search.clusterpedia.io/names names     暂时不支持例如 !=，notin 操作符，如果有这些需求或者场景，可以在 issue 中讨论\n 模糊搜索  支持的操作符：==，=，in。\n 该功能暂时为试验性功能，暂时只提供 search label\n   作用 search label key url query     模糊搜索资源名称 internalstorage.clusterpedia.io/fuzzy-name -    创建时间区间检索  支持的操作符：==，=。\n 基于资源的创建时间区间进行检索，采用的是左闭右开的区间\n   作用 search label key url query     指定 Since search.clusterpedia.io/since since   指定 Before search.clusterpedia.io/before before    创建时间的格式有四种：\n Unix 时间戳格式 为了方便使用会根据时间戳的长度来区分单位为 s 还是 ms。 10 位时间戳单位为秒，13 位时间戳单位为毫秒。 RFC3339 2006-01-02T15:04:05Z or 2006-01-02T15:04:05+08:00 UTC Date 2006-01-02 UTC Datetime 2006-01-02 15:04:05  由于 kube label selector 的限制，search label 只支持 Unix 时间戳，UTC Date.\n使用 url query 的方式可以所有的格式\nOwner 检索  只支持操作符：==，=。\n    作用 search label key url query     指定 Owner UID search.clusterpedia.io/owner-uid ownerUID   指定 Owner Name search.clusterpedia.io/owner-name ownerName   指定 Owner Group Resource search.clusterpedia.io/owner-gr ownerGR   指定 Owner 辈分 internalstorage.clusterpedia.io/owner-seniority ownerSeniority    需要注意指定 Owner UID 时，Owner Name 和 Owner Group Resource 会被忽略\nOwner Group 的格式为 resource.group，例如 deployments.apps 或者 nodes\n排序  只支持操作符：=，==，in。\n    作用 search label key url query     多字段排序 search.clusterpedia.io/orderby orderby    分页  只支持操作符 =，==。\n    作用 search label key url query     设置分页 size search.clusterpedia.io/size limit   设置分页 offset search.clusterpedia.io/offset continue   要求响应携带 Continue search.clusterpedia.io/with-continue withContinue   要求响应携带资源剩余数量 search.clusterpedia.io/with-remaining-count withRemainingCount     在使用 kubectl 操作时，分页 size 只能通过 kubectl --chunk-size 来设置，因为 kubectl 会将 limit 默认设置为 500。\n Label 过滤 无论使用 kubectl 还是 URL，所有 Key 中不包含 clusterpedia.io 的 Label Selector 都会作为 Label Selector 来过滤资源。\n所有行为和原生 Kubernetes 一致。\n   作用 kubectl url query     Label 过滤 kubectl -l or kubectl --label-selector labelSelector    字段过滤 Clusterpedia 的 Field Selector 在操作符上与 Label Selector 保持一致，同样支持：\nexist，not exist，==，=，!=，in，notin。\n无论是 URL 还是 kubectl 上的命令参数都原生 Field Selector 一致\n   作用 kubectl url query     字段过滤 kubectl --field-selector fieldSelector    详细可以查看：\n 使用字段过滤来检索资源 support field selector issue: support list field filtering  高级检索(自定义条件检索) 自定义检索为 默认存储层 提供的功能，目的是为了满足用户更加灵活多变的检索需求\n   作用 search label key url query     自定义检索语句 - whereSQL    自定义检索并不支持通过 search lable，只能使用 url query 来传递自定义搜素的语句。\n另外该功能暂时还是处于 alpha 阶段，需要用户在 clusterpedia apiserver 中开启相应的 Feature Gate，详细可以参考 自定义条件检索\nCollectionResource URL Query 以下 URL Query 专属于 Collection Resource。\n   作用 url query example     只获取资源的 metadata onlyMetadata onlyMetadata=true   指定 any collectionresource 的 groups groups groups=apps,cert-manager.io/v1   指定 any collectionresource 的 resources resources resources=apps/deployments,batch/v1/cronjobs    ","categories":"","description":"","excerpt":"Clusterpedia 支持对 多个集群内资源，指定集群的资源 以及聚合资源 的复杂检索， …","ref":"/zh-cn/docs/usage/search/","tags":"","title":"资源检索"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh-cn/docs/installation/configurate/","tags":"","title":"配置"}]